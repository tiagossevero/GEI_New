# ============================================================
# COLE ESTE C√ìDIGO NO IN√çCIO DE CADA ARQUIVO .PY
# ============================================================
import streamlit as st
import hashlib

# DEFINA A SENHA AQUI
SENHA = "tsevero654"  # ‚Üê TROQUE para cada projeto

def check_password():
    if "authenticated" not in st.session_state:
        st.session_state.authenticated = False
    
    if not st.session_state.authenticated:
        st.markdown("<div style='text-align: center; padding: 50px;'><h1>üîê Acesso Restrito</h1></div>", unsafe_allow_html=True)
        
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            senha_input = st.text_input("Digite a senha:", type="password", key="pwd_input")
            if st.button("Entrar", use_container_width=True):
                if senha_input == SENHA:
                    st.session_state.authenticated = True
                    st.rerun()
                else:
                    st.error("‚ùå Senha incorreta")
        st.stop()

check_password()

"""
Sistema GEI - Dashboard de Monitoramento Fiscal v3.0
Vers√£o Completa com An√°lises Avan√ßadas
Receita Estadual de Santa Catarina
"""

# =============================================================================
# IMPORTS E CONFIGURA√á√ïES INICIAIS
# =============================================================================

import pandas as pd
import numpy as np
import plotly.express as px
import folium
from streamlit_folium import st_folium
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from scipy import stats
from datetime import datetime
from sqlalchemy import create_engine
import warnings
import ssl
import openpyxl
from io import BytesIO
from reportlab.lib.pagesizes import A4, letter
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.lib.units import inch
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle, PageBreak, Image
from reportlab.lib import colors
from reportlab.lib.enums import TA_CENTER, TA_LEFT
import os
from sklearn.cluster import KMeans, DBSCAN
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score
from sklearn.ensemble import IsolationForest
import numpy as np

os.environ['PYTHONWARNINGS'] = 'ignore::DeprecationWarning'

warnings.filterwarnings('ignore')

# Configura√ß√£o SSL - CORRIGIDO
try:
    _create_unverified_https_context = ssl._create_unverified_context
except AttributeError:
    pass
else:
    ssl._create_default_https_context = _create_unverified_https_context

# Configura√ß√£o Streamlit
st.set_page_config(
    page_title="GEI - Monitoramento Fiscal",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# CSS Customizado
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }

    /* ESTILO DOS GR√ÅFICOS (PLOTLY) */
    div[data-testid="stPlotlyChart"] {
        border: 2px solid #e0e0e0;       /* Borda: 2px, s√≥lida, cor cinza-claro */
        border-radius: 10px;             /* Cantos arredondados (mesmo dos KPIs) */
        padding: 10px;                   /* Espa√ßamento interno (ajuste conforme gosto) */
        box-shadow: 0 2px 4px rgba(0,0,0,0.05); /* Sombra suave */
        background-color: #ffffff;       /* Fundo branco (opcional) */
    }
    
    /* ESTILO DOS KPIs - BORDA PRETA */
    div[data-testid="stMetric"] {
        background-color: #ffffff;        /* Fundo branco */
        border: 2px solid #2c3e50;        /* Borda: 2px de largura, s√≥lida, cor cinza-escuro */
        border-radius: 10px;              /* Cantos arredondados (10 pixels de raio) */
        padding: 15px;                    /* Espa√ßamento interno (15px em todos os lados) */
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);  /* Sombra: horizontal=0, vertical=2px, blur=4px, cor preta 10% opacidade */
    }
    
    /* T√≠tulo do m√©trica */
    div[data-testid="stMetric"] > label {
        font-weight: 600;                 /* Negrito m√©dio */
        color: #2c3e50;                   /* Cor do texto */
    }
    
    /* Valor do m√©trica */
    div[data-testid="stMetricValue"] {
        font-size: 1.8rem;                /* Tamanho da fonte do valor */
        font-weight: bold;                /* Negrito */
        color: #1f77b4;                   /* Cor azul */
    }
    
    /* Delta (varia√ß√£o) */
    div[data-testid="stMetricDelta"] {
        font-size: 0.9rem;                /* Tamanho menor para delta */
    }
    
    .metric-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #1f77b4;
    }

    /* =========================================================================
       SIDEBAR SEMPRE COLAPSADO - EXPANDE AO PASSAR O MOUSE
       ========================================================================= */

    /* Sidebar sempre colapsado por padr√£o */
    section[data-testid="stSidebar"] {
        width: 0px !important;
        min-width: 0px !important;
        transform: translateX(-100%);
        transition: transform 0.3s ease-in-out, width 0.3s ease-in-out;
    }

    /* Expande ao passar o mouse ou focar */
    section[data-testid="stSidebar"]:hover,
    section[data-testid="stSidebar"]:focus-within {
        width: 300px !important;
        min-width: 300px !important;
        transform: translateX(0);
    }

    /* Indicador visual para expandir (hamb√∫rguer) */
    section[data-testid="stSidebar"]::before {
        content: "‚ò∞";
        position: absolute;
        right: -30px;
        top: 50%;
        transform: translateY(-50%);
        font-size: 24px;
        color: #1565C0;
        cursor: pointer;
        z-index: 1000;
    }
</style>
""", unsafe_allow_html=True)

# =============================================================================
# CONFIGURA√á√ïES DE CONEX√ÉO
# =============================================================================

IMPALA_HOST = 'bdaworkernode02.sef.sc.gov.br'
IMPALA_PORT = 21050
DATABASE = 'gessimples'

try:
    IMPALA_USER = st.secrets["impala_credentials"]["user"]
    IMPALA_PASSWORD = st.secrets["impala_credentials"]["password"]
except:
    st.error("Configure as credenciais no arquivo .streamlit/secrets.toml")
    st.stop()

# =============================================================================
# FUN√á√ïES DE CONEX√ÉO E CARREGAMENTO
# =============================================================================

@st.cache_resource
def get_impala_engine():
    """Cria engine de conex√£o com Impala"""
    try:
        engine = create_engine(
            f'impala://{IMPALA_HOST}:{IMPALA_PORT}/{DATABASE}',
            connect_args={
                'user': IMPALA_USER,
                'password': IMPALA_PASSWORD,
                'auth_mechanism': 'LDAP',
                'use_ssl': True
            }
        )
        connection = engine.connect()
        connection.close()
        return engine
    except Exception as e:
        st.error(f"Erro ao conectar ao Impala: {e}")
        return None

@st.cache_data(ttl=3600, show_spinner="Carregando dados principais...")
def carregar_todos_os_dados(_engine):
    """Carrega datasets principais do Sistema GEI"""
    dados = {}
    
    if _engine is None:
        return dados
    
    tabelas_principais = {
        'percent': ('gei_percent', None),
        'cnpj': ('gei_cnpj', 50000),
        'cadastro': ('gei_cadastro', 50000),
        'contador': ('gei_contador', None),
        'socios_compartilhados': ('gei_socios_compartilhados', 30000),
        'c115_ranking': ('gei_c115_ranking_risco_grupo_economico', None),
        'funcionarios_metricas': ('gei_funcionarios_metricas_grupo', None),
        'pagamentos_metricas': ('gei_pagamentos_metricas_grupo', None),
        'c115_metricas': ('gei_c115_metricas_grupos', None),
        'ccs_metricas': ('gei_ccs_metricas_grupo', None),
        'ccs_ranking': ('gei_ccs_ranking_risco', None)
    }
    
    st.sidebar.write("**Status do Carregamento:**")
    
    for key, (tablename, limit) in tabelas_principais.items():
        try:
            st.sidebar.write(f"‚è≥ {tablename}...")
            
            if limit:
                query = f"SELECT * FROM {DATABASE}.{tablename} LIMIT {limit}"
            else:
                query = f"SELECT * FROM {DATABASE}.{tablename}"
            
            df = pd.read_sql(query, _engine)
            df.columns = [col.lower() for col in df.columns]
            dados[key] = df
            st.sidebar.success(f"‚úîÔ∏è {tablename} ({len(df):,})")
        except Exception as e:
            st.sidebar.warning(f"‚ö†Ô∏è {tablename}: {str(e)[:50]}")
            dados[key] = pd.DataFrame()
    
    return dados

@st.cache_data(ttl=3600)
def executar_query_analise(_engine, query_name, query_sql):
    """Executa uma query de an√°lise e retorna o resultado"""
    try:
        df = pd.read_sql(query_sql, _engine)
        df.columns = [col.lower() for col in df.columns]
        return df
    except Exception as e:
        st.error(f"Erro ao executar {query_name}: {e}")
        return pd.DataFrame()

@st.cache_data(ttl=300)
def carregar_dossie_completo(_engine, num_grupo):
    """Carrega todos os dados de um grupo para o dossi√™ - VERS√ÉO CORRIGIDA"""
    dossie = {}
    
    # Garantir que num_grupo seja string para as compara√ß√µes
    num_grupo_str = str(num_grupo)
    
    # =========================================================================
    # 1. DADOS PRINCIPAIS DO GRUPO (gei_percent)
    # =========================================================================
    try:
        query_principal = f"""
        SELECT *
        FROM {DATABASE}.gei_percent
        WHERE num_grupo = '{num_grupo_str}'
        """
        dossie['principal'] = pd.read_sql(query_principal, _engine)
    except Exception as e:
        print(f"Erro ao carregar dados principais: {e}")
        dossie['principal'] = pd.DataFrame()
    
    # =========================================================================
    # 2. CNPJs DO GRUPO
    # =========================================================================
    try:
        query_cnpjs = f"""
        SELECT 
            g.cnpj,
            c.nm_razao_social,
            c.nm_fantasia,
            c.cd_cnae,
            c.nm_reg_apuracao,
            c.dt_constituicao_empresa,
            c.nm_munic as nm_municipio,
            c.nm_contador
        FROM {DATABASE}.gei_cnpj g
        LEFT JOIN usr_sat_ods.vw_ods_contrib c ON g.cnpj = c.nu_cnpj
        WHERE g.num_grupo = '{num_grupo_str}'
        """
        dossie['cnpjs'] = pd.read_sql(query_cnpjs, _engine)
        
        if dossie['cnpjs'].empty:
            # Fallback: buscar apenas CNPJs sem JOIN
            query_cnpjs_simples = f"""
            SELECT cnpj
            FROM {DATABASE}.gei_cnpj
            WHERE num_grupo = '{num_grupo_str}'
            """
            dossie['cnpjs'] = pd.read_sql(query_cnpjs_simples, _engine)
    except Exception as e:
        print(f"Erro ao carregar CNPJs: {e}")
        dossie['cnpjs'] = pd.DataFrame()
    
    # =========================================================================
    # 3. S√ìCIOS COMPARTILHADOS
    # =========================================================================
    try:
        query_socios = f"""
        SELECT 
            cpf_socio,
            qtd_empresas
        FROM {DATABASE}.gei_socios_compartilhados
        WHERE num_grupo = '{num_grupo_str}'
        ORDER BY qtd_empresas DESC
        """
        dossie['socios'] = pd.read_sql(query_socios, _engine)
    except Exception as e:
        print(f"Erro ao carregar s√≥cios: {e}")
        dossie['socios'] = pd.DataFrame()
    
    # =========================================================================
    # 4. IND√çCIOS FISCAIS
    # =========================================================================
    try:
        query_indicios = f"""
        SELECT 
            tx_descricao_indicio,
            cnpj,
            tx_descricao_complemento
        FROM {DATABASE}.gei_indicios
        WHERE num_grupo = '{num_grupo_str}'
        """
        dossie['indicios'] = pd.read_sql(query_indicios, _engine)
    except Exception as e:
        print(f"Erro ao carregar ind√≠cios: {e}")
        dossie['indicios'] = pd.DataFrame()
    
    # =========================================================================
    # 5. FUNCION√ÅRIOS - BUSCAR DE gei_funcionarios_metricas_grupo
    # =========================================================================
    try:
        query_func = f"""
        SELECT 
            num_grupo,
            total_funcionarios,
            cnpjs_com_funcionarios
        FROM {DATABASE}.gei_funcionarios_metricas_grupo
        WHERE num_grupo = '{num_grupo_str}'
        """
        dossie['funcionarios'] = pd.read_sql(query_func, _engine)
    except Exception as e:
        print(f"Erro ao carregar funcion√°rios: {e}")
        dossie['funcionarios'] = pd.DataFrame()
    
    # =========================================================================
    # 6. MEIOS DE PAGAMENTO - BUSCAR DE gei_pagamentos_metricas_grupo
    # =========================================================================
    try:
        query_pag = f"""
        SELECT 
            num_grupo,
            valor_meios_pagamento_empresas,
            valor_meios_pagamento_socios
        FROM {DATABASE}.gei_pagamentos_metricas_grupo
        WHERE num_grupo = '{num_grupo_str}'
        """
        dossie['pagamentos'] = pd.read_sql(query_pag, _engine)
    except Exception as e:
        print(f"Erro ao carregar pagamentos: {e}")
        dossie['pagamentos'] = pd.DataFrame()
    
    # =========================================================================
    # 7. CONV√äNIO 115 - BUSCAR DE gei_c115_ranking_risco_grupo_economico
    # =========================================================================
    try:
        query_c115 = f"""
        SELECT 
            num_grupo,
            ranking_risco,
            nivel_risco_grupo_economico,
            indice_risco_grupo_economico,
            qtd_cnpjs_relacionados,
            perc_cnpjs_relacionados,
            total_tomadores,
            tomadores_com_compartilhamento,
            total_compartilhamentos
        FROM {DATABASE}.gei_c115_ranking_risco_grupo_economico
        WHERE num_grupo = '{num_grupo_str}'
        """
        dossie['c115'] = pd.read_sql(query_c115, _engine)
    except Exception as e:
        print(f"Erro ao carregar C115: {e}")
        dossie['c115'] = pd.DataFrame()
    
    # =========================================================================
    # 8. CCS - CONTAS COMPARTILHADAS
    # =========================================================================
    try:
        query_ccs = f"""
        SELECT 
            nr_cpf,
            nm_banco,
            cd_agencia,
            nr_conta,
            qtd_cnpjs_usando_conta,
            qtd_vinculos_ativos,
            status_conta
        FROM {DATABASE}.gei_ccs_cpf_compartilhado
        WHERE num_grupo = '{num_grupo_str}'
        ORDER BY qtd_cnpjs_usando_conta DESC
        LIMIT 50
        """
        dossie['ccs_compartilhadas'] = pd.read_sql(query_ccs, _engine)
    except Exception as e:
        print(f"Erro ao carregar CCS compartilhadas: {e}")
        dossie['ccs_compartilhadas'] = pd.DataFrame()
    
    # =========================================================================
    # 9. CCS - SOBREPOSI√á√ïES DE RESPONS√ÅVEIS
    # =========================================================================
    try:
        query_sobreposicoes = f"""
        SELECT 
            nr_cpf,
            cnpj1,
            cnpj2,
            nm_responsavel,
            inicio1,
            fim1,
            inicio2,
            fim2,
            dias_sobreposicao
        FROM {DATABASE}.gei_ccs_sobreposicao_responsaveis
        WHERE num_grupo = '{num_grupo_str}'
        ORDER BY dias_sobreposicao DESC
        LIMIT 50
        """
        dossie['ccs_sobreposicoes'] = pd.read_sql(query_sobreposicoes, _engine)
    except Exception as e:
        print(f"Erro ao carregar sobreposi√ß√µes: {e}")
        dossie['ccs_sobreposicoes'] = pd.DataFrame()
    
    # =========================================================================
    # 10. CCS - PADR√ïES COORDENADOS
    # =========================================================================
    try:
        query_padroes = f"""
        SELECT 
            tipo_evento,
            dt_evento,
            qtd_cnpjs,
            qtd_contas,
            qtd_cpfs_distintos
        FROM {DATABASE}.gei_ccs_padroes_coordenados
        WHERE num_grupo = '{num_grupo_str}'
        ORDER BY dt_evento DESC
        LIMIT 50
        """
        dossie['ccs_padroes'] = pd.read_sql(query_padroes, _engine)
    except Exception as e:
        print(f"Erro ao carregar padr√µes coordenados: {e}")
        dossie['ccs_padroes'] = pd.DataFrame()
    
    # =========================================================================
    # 11. INCONSIST√äNCIAS NFE
    # =========================================================================
    try:
        query_incons = f"""
        SELECT
            nfe_nu_chave_acesso,
            nfe_dt_emissao,
            nfe_cnpj_cpf_emit,
            nfe_cnpj_cpf_dest,
            nfe_dest_email,
            nfe_dest_telefone,
            nfe_emit_telefone,
            nfe_cd_produto,
            nfe_de_produto,
            nfe_emit_end_completo,
            nfe_dest_end_completo,
            nfe_ip_transmissao,
            cliente_incons,
            email_incons,
            tel_dest_incons,
            tel_emit_incons,
            codigo_produto_incons,
            fornecedor_incons,
            end_emit_incons,
            end_dest_incons,
            descricao_produto_incons,
            ip_transmissao_incons
        FROM {DATABASE}.gei_nfe_completo
        WHERE grupo_emit = '{num_grupo_str}' OR grupo_dest = '{num_grupo_str}'
        LIMIT 1000
        """
        dossie['inconsistencias'] = pd.read_sql(query_incons, _engine)
    except Exception as e:
        print(f"Erro ao carregar inconsist√™ncias NFe: {e}")
        dossie['inconsistencias'] = pd.DataFrame()

    # =========================================================================
    # 12. FATURAMENTO (PGDAS + DIME CONSOLIDADO)
    # =========================================================================
    try:
        # Buscar CNPJs do grupo primeiro
        cnpjs_grupo = dossie['cnpjs']['cnpj'].tolist() if not dossie['cnpjs'].empty else []

        if cnpjs_grupo:
            cnpjs_str = "', '".join([str(c) for c in cnpjs_grupo])

            # Query PGDAS
            query_pgdas = f"""
            SELECT
                cnpj,
                jan2025, fev2025, mar2025, abr2025, mai2025, jun2025,
                jul2025, ago2025, set2025,
                'PGDAS' as fonte
            FROM gessimples.gei_pgdas
            WHERE cnpj IN ('{cnpjs_str}')
            """
            df_pgdas = pd.read_sql(query_pgdas, _engine)

            # Query DIME
            query_dime = f"""
            SELECT
                cnpj,
                jan2025, fev2025, mar2025, abr2025, mai2025, jun2025,
                jul2025, ago2025, set2025,
                'DIME' as fonte
            FROM gessimples.gei_dime
            WHERE cnpj IN ('{cnpjs_str}')
            """
            try:
                df_dime = pd.read_sql(query_dime, _engine)
            except:
                df_dime = pd.DataFrame()

            # Consolidar
            if not df_pgdas.empty or not df_dime.empty:
                dossie['faturamento'] = pd.concat([df_pgdas, df_dime], ignore_index=True)
            else:
                dossie['faturamento'] = pd.DataFrame()
        else:
            dossie['faturamento'] = pd.DataFrame()
    except Exception as e:
        print(f"Erro ao carregar faturamento: {e}")
        dossie['faturamento'] = pd.DataFrame()

    # =========================================================================
    # 13. ENERGIA EL√âTRICA (NF3e)
    # =========================================================================
    try:
        # Buscar CNPJs do grupo
        cnpjs_grupo = dossie['cnpjs']['cnpj'].tolist() if not dossie['cnpjs'].empty else []

        if cnpjs_grupo:
            cnpjs_str = "', '".join([str(c) for c in cnpjs_grupo])

            # Query NF3e - Consumo de energia el√©trica
            query_nf3e = f"""
            SELECT
                cnpj,
                jan2024, fev2024, mar2024, abr2024, mai2024, jun2024,
                jul2024, ago2024, set2024, out2024, nov2024, dez2024,
                jan2025, fev2025, mar2025, abr2025, mai2025, jun2025,
                jul2025, ago2025, set2025
            FROM gessimples.gei_nf3e
            WHERE cnpj IN ('{cnpjs_str}')
            """
            dossie['nf3e'] = pd.read_sql(query_nf3e, _engine)

            # Query m√©tricas do grupo
            query_nf3e_metricas = f"""
            SELECT *
            FROM gessimples.gei_nf3e_metricas_grupo
            WHERE num_grupo = '{num_grupo_str}'
            """
            try:
                dossie['nf3e_metricas'] = pd.read_sql(query_nf3e_metricas, _engine)
            except:
                dossie['nf3e_metricas'] = pd.DataFrame()

            # Query detalhado mensal
            query_nf3e_det = f"""
            SELECT *
            FROM gessimples.gei_nf3e_detalhado
            WHERE num_grupo = '{num_grupo_str}'
            ORDER BY ano_emissao DESC, mes_emissao DESC
            """
            try:
                dossie['nf3e_detalhado'] = pd.read_sql(query_nf3e_det, _engine)
            except:
                dossie['nf3e_detalhado'] = pd.DataFrame()
        else:
            dossie['nf3e'] = pd.DataFrame()
            dossie['nf3e_metricas'] = pd.DataFrame()
            dossie['nf3e_detalhado'] = pd.DataFrame()
    except Exception as e:
        print(f"Erro ao carregar NF3e (energia): {e}")
        dossie['nf3e'] = pd.DataFrame()
        dossie['nf3e_metricas'] = pd.DataFrame()
        dossie['nf3e_detalhado'] = pd.DataFrame()

    # =========================================================================
    # 14. TELECOMUNICA√á√ïES (NFCom)
    # =========================================================================
    try:
        # Buscar CNPJs do grupo
        cnpjs_grupo = dossie['cnpjs']['cnpj'].tolist() if not dossie['cnpjs'].empty else []

        if cnpjs_grupo:
            cnpjs_str = "', '".join([str(c) for c in cnpjs_grupo])

            # Query NFCom - Consumo de telecomunica√ß√µes
            query_nfcom = f"""
            SELECT
                cnpj,
                jan2024, fev2024, mar2024, abr2024, mai2024, jun2024,
                jul2024, ago2024, set2024, out2024, nov2024, dez2024,
                jan2025, fev2025, mar2025, abr2025, mai2025, jun2025,
                jul2025, ago2025, set2025
            FROM gessimples.gei_nfcom
            WHERE cnpj IN ('{cnpjs_str}')
            """
            dossie['nfcom'] = pd.read_sql(query_nfcom, _engine)

            # Query m√©tricas do grupo
            query_nfcom_metricas = f"""
            SELECT *
            FROM gessimples.gei_nfcom_metricas_grupo
            WHERE num_grupo = '{num_grupo_str}'
            """
            try:
                dossie['nfcom_metricas'] = pd.read_sql(query_nfcom_metricas, _engine)
            except:
                dossie['nfcom_metricas'] = pd.DataFrame()

            # Query detalhado mensal
            query_nfcom_det = f"""
            SELECT *
            FROM gessimples.gei_nfcom_detalhado
            WHERE num_grupo = '{num_grupo_str}'
            ORDER BY ano_emissao DESC, mes_emissao DESC
            """
            try:
                dossie['nfcom_detalhado'] = pd.read_sql(query_nfcom_det, _engine)
            except:
                dossie['nfcom_detalhado'] = pd.DataFrame()

            # Query por operadora
            query_nfcom_op = f"""
            SELECT *
            FROM gessimples.gei_nfcom_por_operadora
            WHERE num_grupo = '{num_grupo_str}'
            ORDER BY vl_total DESC
            """
            try:
                dossie['nfcom_operadoras'] = pd.read_sql(query_nfcom_op, _engine)
            except:
                dossie['nfcom_operadoras'] = pd.DataFrame()
        else:
            dossie['nfcom'] = pd.DataFrame()
            dossie['nfcom_metricas'] = pd.DataFrame()
            dossie['nfcom_detalhado'] = pd.DataFrame()
            dossie['nfcom_operadoras'] = pd.DataFrame()
    except Exception as e:
        print(f"Erro ao carregar NFCom (telecom): {e}")
        dossie['nfcom'] = pd.DataFrame()
        dossie['nfcom_metricas'] = pd.DataFrame()
        dossie['nfcom_detalhado'] = pd.DataFrame()
        dossie['nfcom_operadoras'] = pd.DataFrame()

    return dossie

# =============================================================================
# FUN√á√ïES AUXILIARES
# =============================================================================

def aplicar_filtros(df, filtros):
    """Aplica filtros aos dados"""
    if df.empty:
        return df
    
    df_filtrado = df.copy()
    
    if 'score_final_ccs' in df_filtrado.columns:
        df_filtrado = df_filtrado[
            (df_filtrado['score_final_ccs'] >= filtros['score_min']) &
            (df_filtrado['score_final_ccs'] <= filtros['score_max'])
        ]
    elif 'score_final_avancado' in df_filtrado.columns:
        df_filtrado = df_filtrado[
            (df_filtrado['score_final_avancado'] >= filtros['score_min']) &
            (df_filtrado['score_final_avancado'] <= filtros['score_max'])
        ]
    
    if 'qntd_cnpj' in df_filtrado.columns:
        df_filtrado = df_filtrado[
            (df_filtrado['qntd_cnpj'] >= filtros['cnpj_min']) &
            (df_filtrado['qntd_cnpj'] <= filtros['cnpj_max'])
        ]
    
    if filtros['com_indicios'] and 'qtd_total_indicios' in df_filtrado.columns:
        df_filtrado = df_filtrado[df_filtrado['qtd_total_indicios'] > 0]
    
    return df_filtrado

def formatar_moeda(valor):
    """Formata valores monet√°rios"""
    if pd.isna(valor):
        return "N/A"
    if valor >= 1e9:
        return f"R$ {valor/1e9:.1f}B"
    elif valor >= 1e6:
        return f"R$ {valor/1e6:.1f}M"
    elif valor >= 1e3:
        return f"R$ {valor/1e3:.1f}K"
    else:
        return f"R$ {valor:.2f}"

def analise_machine_learning(engine, dados, filtros):
    """An√°lise de Machine Learning para identifica√ß√£o de grupos econ√¥micos"""
    
    st.markdown("<h1 class='main-header'>ü§ñ Machine Learning - Identifica√ß√£o de Grupos Econ√¥micos</h1>", unsafe_allow_html=True)
    
    st.info("""
    Este m√≥dulo utiliza algoritmos de aprendizado n√£o supervisionado para identificar automaticamente
    padr√µes que caracterizam grupos econ√¥micos com base nos scores e m√©tricas j√° calculados pelo sistema GEI.
    """)
    
    # SE√á√ÉO 1: CONFIGURA√á√ÉO DO MODELO
    st.header("1. Configura√ß√£o do Modelo")
    
    # ADICIONAR OP√á√ÉO DE MODO
    modo_analise = st.radio(
        "Modo de An√°lise:",
        ["Individual (escolher algoritmo)", "Consenso (executar todos os 3 modelos)"],
        help="Individual: executa apenas 1 algoritmo | Consenso: executa os 3 e compara resultados"
    )
    
    if modo_analise == "Individual (escolher algoritmo)":
        col1, col2, col3 = st.columns(3)
        
        with col1:
            algoritmo = st.selectbox(
                "Algoritmo de Clustering:",
                ["K-Means", "DBSCAN", "Isolation Forest"],
                help="K-Means: R√°pido e eficiente | DBSCAN: Detecta outliers | Isolation Forest: Identifica anomalias"
            )
        
        with col2:
            if algoritmo == "K-Means":
                n_clusters = st.slider("N√∫mero de Clusters", 2, 5, 2)
            elif algoritmo == "DBSCAN":
                eps = st.slider("Epsilon (eps)", 0.1, 2.0, 0.5, 0.1)
                min_samples = st.slider("Min Samples", 2, 10, 3)
        
        with col3:
            usar_pca = st.checkbox("Usar PCA (Redu√ß√£o de Dimensionalidade)", value=True)
            if usar_pca:
                n_components_pca = st.slider("Componentes PCA", 2, 10, 3)
    else:
        # Modo consenso - configura√ß√µes fixas otimizadas
        st.info("""
        **Modo Consenso Ativado:**
        - Executar√° K-Means (2 clusters), DBSCAN e Isolation Forest
        - Comparar√° os resultados dos 3 algoritmos
        - Grupos identificados por m√∫ltiplos modelos t√™m maior confian√ßa
        """)
        usar_pca = True
        n_components_pca = 3
    
    # Bot√£o para carregar dados
    if st.button("üîÑ Carregar Dados dos Grupos", type="primary"):
        with st.spinner("Carregando dados..."):
            
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            status_text.text("Carregando dados agregados da tabela gei_percent...")
            progress_bar.progress(30)
            
            query_grupos = """
            SELECT 
                num_grupo,
                qntd_cnpj as qtd_cnpjs,
                
                -- Scores j√° calculados
                COALESCE(score_final_ccs, 0) as score_final_ccs,
                COALESCE(score_final_avancado, 0) as score_final_avancado,
                COALESCE(total, 0) as score_inconsistencias_nfe,
                
                -- M√©tricas Cadastrais
                CASE WHEN nm_razao_social = 'S' THEN 1 ELSE 0 END as razao_social_identica,
                CASE WHEN nm_fantasia = 'S' THEN 1 ELSE 0 END as fantasia_identica,
                CASE WHEN cd_cnae = 'S' THEN 1 ELSE 0 END as cnae_identico,
                CASE WHEN nm_contador = 'S' THEN 1 ELSE 0 END as contador_identico,
                CASE WHEN endereco = 'S' THEN 1 ELSE 0 END as endereco_identico,
                qntd_sn + qntd_normal + qntd_s as total_regimes,
                
                -- M√©tricas Financeiras
                COALESCE(valor_max, 0) as receita_maxima,
                CASE WHEN valor_max > 4800000 THEN 1 ELSE 0 END as acima_limite_sn,
                
                -- V√≠nculos Societ√°rios
                COALESCE(qtd_socios_compartilhados, 0) as socios_compartilhados,
                COALESCE(max_empresas_por_socio, 0) as max_empresas_socio,
                COALESCE(indice_interconexao, 0) as indice_interconexao,
                COALESCE(perc_cnpjs_com_socios, 0) as perc_cnpjs_com_socios,
                
                -- Conv√™nio 115
                COALESCE(indice_risco_grupo_economico, 0) as indice_risco_c115,
                COALESCE(perc_cnpjs_relacionados, 0) as perc_cnpjs_relacionados_c115,
                COALESCE(total_compartilhamentos, 0) as total_compartilhamentos_c115,
                CASE 
                    WHEN nivel_risco_grupo_economico = 'CR√çTICO' THEN 3
                    WHEN nivel_risco_grupo_economico = 'ALTO' THEN 2
                    WHEN nivel_risco_grupo_economico = 'M√âDIO' THEN 1
                    ELSE 0
                END as nivel_risco_c115_num,
                
                -- Ind√≠cios Fiscais
                COALESCE(qtd_total_indicios, 0) as total_indicios,
                COALESCE(qtd_tipos_indicios_distintos, 0) as tipos_indicios_distintos,
                COALESCE(perc_cnpjs_com_indicios, 0) as perc_cnpjs_com_indicios,
                COALESCE(indice_risco_indicios, 0) as indice_risco_indicios,
                
                -- Meios de Pagamento
                COALESCE(valor_meios_pagamento_empresas, 0) as pagamentos_empresas,
                COALESCE(valor_meios_pagamento_socios, 0) as pagamentos_socios,
                COALESCE(indice_risco_pagamentos, 0) as indice_risco_pagamentos,
                
                -- Funcion√°rios
                COALESCE(total_funcionarios, 0) as total_funcionarios,
                COALESCE(indice_risco_fat_func, 0) as indice_risco_fat_func,
                
                -- CCS (Contas Banc√°rias)
                COALESCE(ccs_qtd_contas_compartilhadas, 0) as contas_compartilhadas,
                COALESCE(ccs_perc_contas_compartilhadas, 0) as perc_contas_compartilhadas,
                COALESCE(ccs_max_cnpjs_por_conta, 0) as max_cnpjs_por_conta,
                COALESCE(ccs_qtd_sobreposicoes_responsaveis, 0) as sobreposicoes_responsaveis,
                COALESCE(indice_risco_ccs, 0) as indice_risco_ccs,
                CASE 
                    WHEN nivel_risco_ccs = 'CR√çTICO' THEN 3
                    WHEN nivel_risco_ccs = 'ALTO' THEN 2
                    WHEN nivel_risco_ccs = 'M√âDIO' THEN 1
                    ELSE 0
                END as nivel_risco_ccs_num,
                
                -- Inconsist√™ncias NFe (detalhadas)
                COALESCE(perc_cliente, 0) as perc_cliente_incons,
                COALESCE(perc_email, 0) as perc_email_incons,
                COALESCE(perc_tel_dest, 0) as perc_tel_dest_incons,
                COALESCE(perc_tel_emit, 0) as perc_tel_emit_incons,
                COALESCE(perc_codigo_produto, 0) as perc_codigo_produto_incons,
                COALESCE(perc_fornecedor, 0) as perc_fornecedor_incons,
                COALESCE(perc_end_emit, 0) as perc_end_emit_incons,
                COALESCE(perc_end_dest, 0) as perc_end_dest_incons,
                COALESCE(perc_descricao_produto, 0) as perc_descricao_produto_incons,
                COALESCE(perc_ip_transmissao, 0) as perc_ip_transmissao_incons,
                COALESCE(distinct_nfe, 0) as total_nfe_analisadas
                
            FROM gessimples.gei_percent
            WHERE qntd_cnpj > 1
            ORDER BY score_final_ccs DESC
            LIMIT 10000
            """
            
            progress_bar.progress(60)
            df_grupos = pd.read_sql(query_grupos, engine)
            
            if df_grupos.empty:
                st.error("Nenhum grupo encontrado com m√∫ltiplos CNPJs.")
                progress_bar.empty()
                status_text.empty()
                return
            
            progress_bar.progress(90)
            status_text.text("Processando dados...")
            
            # Preencher NaN com 0
            df_grupos = df_grupos.fillna(0)
            
            # Calcular score percentual customizado
            status_text.text("Calculando scores customizados...")
            
            scores_customizados = []
            for _, grupo in df_grupos.iterrows():
                score = 0
                max_score = 0
                
                # 1. Cadastro (peso 10 pontos)
                max_score += 10
                score += grupo['razao_social_identica'] * 2
                score += grupo['fantasia_identica'] * 1
                score += grupo['cnae_identico'] * 1
                score += grupo['contador_identico'] * 3
                score += grupo['endereco_identico'] * 3
                
                # 2. S√≥cios (peso 8 pontos)
                max_score += 8
                if grupo['socios_compartilhados'] > 0:
                    score += min(5, grupo['socios_compartilhados'] * 0.5)
                score += min(3, grupo['indice_interconexao'] * 3)
                
                # 3. Financeiro (peso 7 pontos)
                max_score += 7
                score += grupo['acima_limite_sn'] * 5
                if grupo['receita_maxima'] > 4800000 and grupo['qtd_cnpjs'] > 1:
                    excesso_normalizado = min(2, (grupo['receita_maxima'] - 4800000) / 4800000)
                    score += excesso_normalizado
                
                # 4. C115 (peso 5 pontos)
                max_score += 5
                score += min(3, grupo['indice_risco_c115'] / 10)
                score += min(2, grupo['nivel_risco_c115_num'] * 0.67)
                
                # 5. Ind√≠cios (peso 5 pontos)
                max_score += 5
                if grupo['total_indicios'] > 0:
                    score += min(5, grupo['total_indicios'] * 0.2)
                
                # 6. CCS (peso 5 pontos)
                max_score += 5
                if grupo['contas_compartilhadas'] > 0:
                    score += min(3, grupo['contas_compartilhadas'] * 0.5)
                score += min(2, grupo['nivel_risco_ccs_num'] * 0.67)
                
                # 7. NFe (peso 5 pontos)
                max_score += 5
                score_nfe = (grupo['perc_cliente_incons'] + grupo['perc_email_incons'] + 
                           grupo['perc_tel_dest_incons'] + grupo['perc_tel_emit_incons'] +
                           grupo['perc_ip_transmissao_incons']) / 5
                score += min(5, score_nfe * 5)
                
                # 8. Pagamentos (peso 3 pontos)
                max_score += 3
                if grupo['pagamentos_socios'] > 0:
                    score += min(3, grupo['indice_risco_pagamentos'] * 100)
                
                # 9. Funcion√°rios (peso 2 pontos)
                max_score += 2
                if grupo['total_funcionarios'] > 0 and grupo['receita_maxima'] > 0:
                    receita_por_func = grupo['receita_maxima'] / (grupo['total_funcionarios'] + 1)
                    if receita_por_func > 500000:
                        score += 2
                    elif receita_por_func > 300000:
                        score += 1
                
                percentual = (score / max_score * 100) if max_score > 0 else 0
                
                scores_customizados.append({
                    'score_ml_absoluto': score,
                    'score_ml_maximo': max_score,
                    'score_ml_percentual': percentual
                })
            
            df_scores = pd.DataFrame(scores_customizados)
            df_grupos = pd.concat([df_grupos, df_scores], axis=1)
            
            progress_bar.progress(100)
            status_text.text("Conclu√≠do!")
            
            import time
            time.sleep(0.5)
            progress_bar.empty()
            status_text.empty()
            
            st.session_state['df_grupos_ml'] = df_grupos
            st.success(f"‚úÖ {len(df_grupos)} grupos carregados com sucesso!")
    
    # Verificar se dados foram carregados
    if 'df_grupos_ml' not in st.session_state:
        st.warning("‚ö†Ô∏è Clique em 'Carregar Dados dos Grupos' para come√ßar.")
        return
    
    df_grupos = st.session_state['df_grupos_ml']
    
    # SE√á√ÉO 2: AN√ÅLISE EXPLORAT√ìRIA
    st.header("2. An√°lise Explorat√≥ria dos Dados")
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("Total de Grupos", len(df_grupos))
    with col2:
        st.metric("Score M√©dio (GEI)", f"{df_grupos['score_final_ccs'].mean():.1f}")
    with col3:
        st.metric("Score M√©dio (ML)", f"{df_grupos['score_ml_percentual'].mean():.1f}%")
    with col4:
        st.metric("Acima Limite SN", int(df_grupos['acima_limite_sn'].sum()))
    
    # Distribui√ß√£o de scores
    col1, col2 = st.columns(2)
    
    with col1:
        fig = px.histogram(df_grupos, x='score_ml_percentual', nbins=20,
                          title="Distribui√ß√£o de Scores ML",
                          labels={'score_ml_percentual': 'Score ML (%)', 'count': 'Frequ√™ncia'},
                          template=filtros['tema'])
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        fig = px.scatter(df_grupos, x='score_final_ccs', y='score_ml_percentual',
                        hover_data=['num_grupo', 'qtd_cnpjs'],
                        title="Score GEI vs Score ML",
                        labels={'score_final_ccs': 'Score GEI', 'score_ml_percentual': 'Score ML (%)'},
                        template=filtros['tema'])
        st.plotly_chart(fig, use_container_width=True)
    
    # Correla√ß√£o entre features
    st.subheader("Matriz de Correla√ß√£o das Features Principais")
    
    features_correlacao = [
        'score_ml_percentual', 'score_final_ccs', 'qtd_cnpjs',
        'socios_compartilhados', 'indice_interconexao', 'receita_maxima',
        'indice_risco_c115', 'total_indicios', 'indice_risco_ccs',
        'contas_compartilhadas', 'score_inconsistencias_nfe'
    ]
    
    corr_matrix = df_grupos[features_correlacao].corr()
    
    fig = px.imshow(corr_matrix,
                   text_auto='.2f',
                   aspect="auto",
                   title="Correla√ß√£o entre Features Principais",
                   template=filtros['tema'],
                   color_continuous_scale='RdBu_r')
    st.plotly_chart(fig, use_container_width=True)
    
    # SE√á√ÉO 3: TREINAMENTO DO MODELO
    st.header("3. Treinamento do Modelo")
    
    # Definir features para o modelo
    features_para_modelo = [
        'qtd_cnpjs',
        'razao_social_identica', 'fantasia_identica', 'cnae_identico',
        'contador_identico', 'endereco_identico',
        'socios_compartilhados', 'indice_interconexao', 'perc_cnpjs_com_socios',
        'receita_maxima', 'acima_limite_sn',
        'indice_risco_c115', 'nivel_risco_c115_num',
        'total_indicios', 'indice_risco_indicios',
        'contas_compartilhadas', 'indice_risco_ccs', 'nivel_risco_ccs_num',
        'score_inconsistencias_nfe',
        'indice_risco_pagamentos', 'indice_risco_fat_func'
    ]
    
    if modo_analise == "Individual (escolher algoritmo)":
        # MODO INDIVIDUAL
        if st.button("üöÄ Treinar Modelo", type="primary"):
            
            with st.spinner("Treinando modelo..."):
                
                X = df_grupos[features_para_modelo].fillna(0)
                
                # Normaliza√ß√£o
                scaler = StandardScaler()
                X_scaled = scaler.fit_transform(X)
                
                # PCA (opcional)
                if usar_pca:
                    pca = PCA(n_components=n_components_pca)
                    X_transformed = pca.fit_transform(X_scaled)
                    
                    variancia_explicada = pca.explained_variance_ratio_.sum() * 100
                    st.info(f"‚úÖ PCA aplicado: {n_components_pca} componentes explicam {variancia_explicada:.1f}% da vari√¢ncia")
                    
                    # Gr√°fico de vari√¢ncia explicada e features
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        fig = px.bar(
                            x=[f'PC{i+1}' for i in range(len(pca.explained_variance_ratio_))],
                            y=pca.explained_variance_ratio_,
                            title="Vari√¢ncia Explicada por Componente PCA",
                            labels={'x': 'Componente', 'y': 'Vari√¢ncia Explicada'},
                            template=filtros['tema']
                        )
                        st.plotly_chart(fig, use_container_width=True)
                    
                    with col2:
                        # Mostrar quais features mais influenciam cada componente
                        st.write("**Top 3 Features por Componente:**")
                        
                        for i in range(min(3, pca.n_components)):
                            loadings = pca.components_[i]
                            top_indices = np.argsort(np.abs(loadings))[-3:][::-1]
                            
                            st.write(f"**PC{i+1}** ({pca.explained_variance_ratio_[i]*100:.1f}%):")
                            for idx in top_indices:
                                feature_name = features_para_modelo[idx]
                                peso = loadings[idx]
                                st.write(f"  ‚Ä¢ {feature_name}: {peso:.3f}")
                else:
                    X_transformed = X_scaled
                
                # Aplicar algoritmo escolhido
                if algoritmo == "K-Means":
                    modelo = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
                    labels = modelo.fit_predict(X_transformed)
                    
                elif algoritmo == "DBSCAN":
                    modelo = DBSCAN(eps=eps, min_samples=min_samples)
                    labels = modelo.fit_predict(X_transformed)
                    
                elif algoritmo == "Isolation Forest":
                    modelo = IsolationForest(contamination=0.3, random_state=42)
                    predictions = modelo.fit_predict(X_transformed)
                    labels = (predictions == -1).astype(int)
                
                # Adicionar labels ao dataframe
                df_grupos['cluster'] = labels
                
                # Determinar qual cluster representa grupos econ√¥micos
                if algoritmo in ["K-Means", "DBSCAN"]:
                    score_por_cluster = df_grupos.groupby('cluster')['score_ml_percentual'].mean()
                    cluster_grupo_economico = score_por_cluster.idxmax()
                    
                    df_grupos['eh_grupo_economico'] = df_grupos['cluster'].apply(
                        lambda x: 'Grupo Econ√¥mico' if x == cluster_grupo_economico else 'N√£o √© Grupo'
                    )
                else:
                    df_grupos['eh_grupo_economico'] = df_grupos['cluster'].apply(
                        lambda x: 'Grupo Econ√¥mico' if x == 1 else 'N√£o √© Grupo'
                    )
                
                st.session_state['df_grupos_ml'] = df_grupos
                st.session_state['modelo_ml'] = modelo
                st.session_state['scaler_ml'] = scaler
                if usar_pca:
                    st.session_state['pca_ml'] = pca
                
                st.success("‚úÖ Modelo treinado com sucesso!")
    
    else:
        # MODO CONSENSO - EXECUTAR OS 3 MODELOS
        if st.button("üöÄ Executar An√°lise de Consenso (3 Modelos)", type="primary"):
            
            with st.spinner("Executando an√°lise com 3 algoritmos..."):
                
                X = df_grupos[features_para_modelo].fillna(0)
                
                # Normaliza√ß√£o
                scaler = StandardScaler()
                X_scaled = scaler.fit_transform(X)
                
                # PCA
                pca = PCA(n_components=n_components_pca)
                X_transformed = pca.fit_transform(X_scaled)
                
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                # ============================================================
                # MODELO 1: K-MEANS
                # ============================================================
                status_text.text("1/3 - Treinando K-Means...")
                progress_bar.progress(10)
                
                modelo_kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)
                labels_kmeans = modelo_kmeans.fit_predict(X_transformed)
                
                # Determinar qual cluster √© "Grupo Econ√¥mico"
                score_por_cluster_km = df_grupos.groupby(labels_kmeans)['score_ml_percentual'].mean()
                cluster_ge_km = score_por_cluster_km.idxmax()
                df_grupos['kmeans_eh_grupo'] = (labels_kmeans == cluster_ge_km).astype(int)
                
                progress_bar.progress(35)
                
                # ============================================================
                # MODELO 2: DBSCAN
                # ============================================================
                status_text.text("2/3 - Treinando DBSCAN...")
                progress_bar.progress(40)
                
                modelo_dbscan = DBSCAN(eps=0.5, min_samples=3)
                labels_dbscan = modelo_dbscan.fit_predict(X_transformed)
                
                # DBSCAN: -1 s√£o outliers, determinar qual cluster tem maior score
                if len(np.unique(labels_dbscan[labels_dbscan != -1])) > 0:
                    df_temp = df_grupos.copy()
                    df_temp['cluster_dbscan'] = labels_dbscan
                    
                    # Considerar apenas clusters v√°lidos (n√£o outliers)
                    clusters_validos = df_temp[df_temp['cluster_dbscan'] != -1]
                    if not clusters_validos.empty:
                        score_por_cluster_db = clusters_validos.groupby('cluster_dbscan')['score_ml_percentual'].mean()
                        cluster_ge_db = score_por_cluster_db.idxmax()
                        df_grupos['dbscan_eh_grupo'] = (labels_dbscan == cluster_ge_db).astype(int)
                    else:
                        df_grupos['dbscan_eh_grupo'] = 0
                else:
                    df_grupos['dbscan_eh_grupo'] = 0
                
                progress_bar.progress(65)
                
                # ============================================================
                # MODELO 3: ISOLATION FOREST
                # ============================================================
                status_text.text("3/3 - Treinando Isolation Forest...")
                progress_bar.progress(70)
                
                modelo_iforest = IsolationForest(contamination=0.3, random_state=42)
                predictions_if = modelo_iforest.fit_predict(X_transformed)
                
                # -1 = anomalia (grupo econ√¥mico suspeito), 1 = normal
                df_grupos['iforest_eh_grupo'] = (predictions_if == -1).astype(int)
                
                progress_bar.progress(90)
                
                # ============================================================
                # CALCULAR CONSENSO
                # ============================================================
                status_text.text("Calculando consenso...")
                
                df_grupos['votos_eh_grupo'] = (
                    df_grupos['kmeans_eh_grupo'] + 
                    df_grupos['dbscan_eh_grupo'] + 
                    df_grupos['iforest_eh_grupo']
                )
                
                # Classifica√ß√£o por consenso
                df_grupos['consenso_classificacao'] = df_grupos['votos_eh_grupo'].apply(
                    lambda x: 'CONSENSO FORTE (3/3)' if x == 3 else
                             'CONSENSO MODERADO (2/3)' if x == 2 else
                             'CONSENSO FRACO (1/3)' if x == 1 else
                             'N√ÉO √â GRUPO (0/3)'
                )
                
                # N√≠vel de confian√ßa
                df_grupos['nivel_confianca'] = df_grupos['votos_eh_grupo'].apply(
                    lambda x: 'Muito Alto' if x == 3 else
                             'Alto' if x == 2 else
                             'Moderado' if x == 1 else
                             'Baixo'
                )
                
                progress_bar.progress(100)
                status_text.text("Conclu√≠do!")
                
                import time
                time.sleep(0.5)
                progress_bar.empty()
                status_text.empty()
                
                # Salvar modelos
                st.session_state['df_grupos_ml'] = df_grupos
                st.session_state['modelos_consenso'] = {
                    'kmeans': modelo_kmeans,
                    'dbscan': modelo_dbscan,
                    'iforest': modelo_iforest,
                    'scaler': scaler,
                    'pca': pca
                }
                
                st.success("‚úÖ An√°lise de Consenso conclu√≠da com sucesso!")
    
    # ================================================================
    # SE√á√ÉO 4: RESULTADOS
    # ================================================================
    
    # VERIFICAR SE √â MODO CONSENSO
    if 'votos_eh_grupo' in df_grupos.columns:
        
        st.header("4. Resultados da An√°lise de Consenso")
        
        st.info("""
        **Como interpretar os resultados:**
        - **3/3 votos**: Os 3 algoritmos concordam que √© Grupo Econ√¥mico ‚Üí **Confian√ßa Muito Alta**
        - **2/3 votos**: 2 algoritmos indicam Grupo Econ√¥mico ‚Üí **Confian√ßa Alta**
        - **1/3 votos**: Apenas 1 algoritmo indica Grupo Econ√¥mico ‚Üí **Confian√ßa Moderada**
        - **0/3 votos**: Nenhum algoritmo indica Grupo Econ√¥mico ‚Üí **N√£o √© Grupo**
        """)
        
        # M√©tricas de consenso
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            consenso_forte = len(df_grupos[df_grupos['votos_eh_grupo'] == 3])
            st.metric("Consenso Forte (3/3)", consenso_forte, 
                     help="3 algoritmos concordam")
        
        with col2:
            consenso_moderado = len(df_grupos[df_grupos['votos_eh_grupo'] == 2])
            st.metric("Consenso Moderado (2/3)", consenso_moderado,
                     help="2 algoritmos concordam")
        
        with col3:
            consenso_fraco = len(df_grupos[df_grupos['votos_eh_grupo'] == 1])
            st.metric("Consenso Fraco (1/3)", consenso_fraco,
                     help="Apenas 1 algoritmo indica")
        
        with col4:
            nao_grupo = len(df_grupos[df_grupos['votos_eh_grupo'] == 0])
            st.metric("N√£o √© Grupo (0/3)", nao_grupo,
                     help="Nenhum algoritmo indica")
        
        # Gr√°fico de distribui√ß√£o de votos
        st.subheader("Distribui√ß√£o de Consenso")
        
        col1, col2 = st.columns(2)
        
        with col1:
            dist_votos = df_grupos['votos_eh_grupo'].value_counts().sort_index()
            
            fig = px.bar(
                x=['0/3 votos', '1/3 votos', '2/3 votos', '3/3 votos'],
                y=[dist_votos.get(i, 0) for i in range(4)],
                title="Distribui√ß√£o de Votos dos Algoritmos",
                labels={'x': 'Votos', 'y': 'Quantidade de Grupos'},
                template=filtros['tema'],
                color=[dist_votos.get(i, 0) for i in range(4)],
                color_continuous_scale='Reds'
            )
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            fig = px.pie(
                df_grupos,
                names='consenso_classificacao',
                title="Propor√ß√£o por N√≠vel de Consenso",
                template=filtros['tema'],
                color_discrete_sequence=['#00CC96', '#FFA15A', '#EF553B', '#AB63FA']
            )
            st.plotly_chart(fig, use_container_width=True)
        
        # Compara√ß√£o Score ML vs Votos
        st.subheader("An√°lise: Score ML vs Consenso dos Algoritmos")
        
        fig = px.box(
            df_grupos,
            x='votos_eh_grupo',
            y='score_ml_percentual',
            color='votos_eh_grupo',
            title="Distribui√ß√£o de Score ML por N√∫mero de Votos",
            labels={'votos_eh_grupo': 'Votos (Grupo Econ√¥mico)', 'score_ml_percentual': 'Score ML (%)'},
            template=filtros['tema']
        )
        st.plotly_chart(fig, use_container_width=True)
        
        # Tabela de concord√¢ncia entre modelos
        st.subheader("Matriz de Concord√¢ncia entre Algoritmos")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            concordancia_km_db = (df_grupos['kmeans_eh_grupo'] == df_grupos['dbscan_eh_grupo']).sum()
            perc_km_db = concordancia_km_db / len(df_grupos) * 100
            st.metric("K-Means ‚Üî DBSCAN", f"{perc_km_db:.1f}%",
                     help=f"{concordancia_km_db} grupos com classifica√ß√£o id√™ntica")
        
        with col2:
            concordancia_km_if = (df_grupos['kmeans_eh_grupo'] == df_grupos['iforest_eh_grupo']).sum()
            perc_km_if = concordancia_km_if / len(df_grupos) * 100
            st.metric("K-Means ‚Üî Isolation Forest", f"{perc_km_if:.1f}%",
                     help=f"{concordancia_km_if} grupos com classifica√ß√£o id√™ntica")
        
        with col3:
            concordancia_db_if = (df_grupos['dbscan_eh_grupo'] == df_grupos['iforest_eh_grupo']).sum()
            perc_db_if = concordancia_db_if / len(df_grupos) * 100
            st.metric("DBSCAN ‚Üî Isolation Forest", f"{perc_db_if:.1f}%",
                     help=f"{concordancia_db_if} grupos com classifica√ß√£o id√™ntica")
        
        # ================================================================
        # SE√á√ÉO 5: AN√ÅLISE DETALHADA POR N√çVEL DE CONSENSO
        # ================================================================
        st.header("5. An√°lise Detalhada por N√≠vel de Consenso")
        
        tab1, tab2, tab3, tab4 = st.tabs([
            "üî¥ Consenso Forte (3/3)",
            "üü° Consenso Moderado (2/3)",
            "üü† Consenso Fraco (1/3)",
            "üü¢ N√£o √© Grupo (0/3)"
        ])
        
        with tab1:
            grupos_3votos = df_grupos[df_grupos['votos_eh_grupo'] == 3].sort_values('score_ml_percentual', ascending=False)
            
            if not grupos_3votos.empty:
                st.success(f"**{len(grupos_3votos)} grupos com CONSENSO FORTE** - Todos os 3 algoritmos concordam")
                
                st.write("**Caracter√≠sticas destes grupos:**")
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("Score ML M√©dio", f"{grupos_3votos['score_ml_percentual'].mean():.1f}%")
                with col2:
                    st.metric("Score GEI M√©dio", f"{grupos_3votos['score_final_ccs'].mean():.1f}")
                with col3:
                    acima_limite = (grupos_3votos['acima_limite_sn'] == 1).sum()
                    st.metric("Acima Limite SN", f"{acima_limite} ({acima_limite/len(grupos_3votos)*100:.1f}%)")
                
                # Tabela top 50
                colunas_exibir = [
                    'num_grupo', 'score_ml_percentual', 'score_final_ccs', 'qtd_cnpjs',
                    'socios_compartilhados', 'receita_maxima', 'total_indicios',
                    'contas_compartilhadas', 'kmeans_eh_grupo', 'dbscan_eh_grupo', 'iforest_eh_grupo'
                ]
                
                df_display = grupos_3votos[colunas_exibir].copy()
                df_display['receita_maxima'] = df_display['receita_maxima'].apply(formatar_moeda)
                df_display = df_display.rename(columns={
                    'kmeans_eh_grupo': 'K-Means',
                    'dbscan_eh_grupo': 'DBSCAN',
                    'iforest_eh_grupo': 'I.Forest'
                })
                
                st.dataframe(df_display.head(50), width='stretch', hide_index=True)
                
                # Seletor de grupo
                grupo_sel = st.selectbox(
                    "Selecione um grupo para an√°lise detalhada:",
                    grupos_3votos['num_grupo'].tolist(),
                    format_func=lambda x: f"Grupo {x} - Score: {grupos_3votos[grupos_3votos['num_grupo']==x]['score_ml_percentual'].iloc[0]:.1f}%",
                    key="grupo_3votos"
                )
                
                if grupo_sel:
                    st.divider()
                    mostrar_detalhes_grupo(engine, grupo_sel, df_grupos, filtros)
            else:
                st.info("Nenhum grupo com consenso forte (3/3).")
        
        with tab2:
            grupos_2votos = df_grupos[df_grupos['votos_eh_grupo'] == 2].sort_values('score_ml_percentual', ascending=False)
            
            if not grupos_2votos.empty:
                st.warning(f"**{len(grupos_2votos)} grupos com CONSENSO MODERADO** - 2 algoritmos concordam")
                
                # Mostrar quais combina√ß√µes de algoritmos
                st.write("**Combina√ß√µes de Algoritmos:**")
                
                comb_km_db = len(grupos_2votos[
                    (grupos_2votos['kmeans_eh_grupo'] == 1) & 
                    (grupos_2votos['dbscan_eh_grupo'] == 1) & 
                    (grupos_2votos['iforest_eh_grupo'] == 0)
                ])
                
                comb_km_if = len(grupos_2votos[
                    (grupos_2votos['kmeans_eh_grupo'] == 1) & 
                    (grupos_2votos['dbscan_eh_grupo'] == 0) & 
                    (grupos_2votos['iforest_eh_grupo'] == 1)
                ])
                
                comb_db_if = len(grupos_2votos[
                    (grupos_2votos['kmeans_eh_grupo'] == 0) & 
                    (grupos_2votos['dbscan_eh_grupo'] == 1) & 
                    (grupos_2votos['iforest_eh_grupo'] == 1)
                ])
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("K-Means + DBSCAN", comb_km_db)
                with col2:
                    st.metric("K-Means + I.Forest", comb_km_if)
                with col3:
                    st.metric("DBSCAN + I.Forest", comb_db_if)
                
                # Tabela
                colunas_exibir = [
                    'num_grupo', 'score_ml_percentual', 'score_final_ccs', 'qtd_cnpjs',
                    'kmeans_eh_grupo', 'dbscan_eh_grupo', 'iforest_eh_grupo'
                ]
                
                df_display = grupos_2votos[colunas_exibir].copy()
                df_display = df_display.rename(columns={
                    'kmeans_eh_grupo': 'K-Means',
                    'dbscan_eh_grupo': 'DBSCAN',
                    'iforest_eh_grupo': 'I.Forest'
                })
                
                st.dataframe(df_display.head(50), width='stretch', hide_index=True)
            else:
                st.info("Nenhum grupo com consenso moderado (2/3).")
        
        with tab3:
            grupos_1voto = df_grupos[df_grupos['votos_eh_grupo'] == 1].sort_values('score_ml_percentual', ascending=False)
            
            if not grupos_1voto.empty:
                st.info(f"**{len(grupos_1voto)} grupos com CONSENSO FRACO** - Apenas 1 algoritmo indica")
                
                # Mostrar qual algoritmo votou
                st.write("**Algoritmo que Indicou:**")
                
                apenas_km = len(grupos_1voto[
                    (grupos_1voto['kmeans_eh_grupo'] == 1) & 
                    (grupos_1voto['dbscan_eh_grupo'] == 0) & 
                    (grupos_1voto['iforest_eh_grupo'] == 0)
                ])
                
                apenas_db = len(grupos_1voto[
                    (grupos_1voto['kmeans_eh_grupo'] == 0) & 
                    (grupos_1voto['dbscan_eh_grupo'] == 1) & 
                    (grupos_1voto['iforest_eh_grupo'] == 0)
                ])
                
                apenas_if = len(grupos_1voto[
                    (grupos_1voto['kmeans_eh_grupo'] == 0) & 
                    (grupos_1voto['dbscan_eh_grupo'] == 0) & 
                    (grupos_1voto['iforest_eh_grupo'] == 1)
                ])
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("Apenas K-Means", apenas_km)
                with col2:
                    st.metric("Apenas DBSCAN", apenas_db)
                with col3:
                    st.metric("Apenas I.Forest", apenas_if)
                
                # Tabela resumida
                colunas_exibir = [
                    'num_grupo', 'score_ml_percentual', 'qtd_cnpjs',
                    'kmeans_eh_grupo', 'dbscan_eh_grupo', 'iforest_eh_grupo'
                ]
                
                df_display = grupos_1voto[colunas_exibir].copy()
                df_display = df_display.rename(columns={
                    'kmeans_eh_grupo': 'K-Means',
                    'dbscan_eh_grupo': 'DBSCAN',
                    'iforest_eh_grupo': 'I.Forest'
                })
                
                st.dataframe(df_display.head(50), width='stretch', hide_index=True)
            else:
                st.info("Nenhum grupo com consenso fraco (1/3).")
        
        with tab4:
            grupos_0votos = df_grupos[df_grupos['votos_eh_grupo'] == 0].sort_values('score_ml_percentual', ascending=False)
            
            if not grupos_0votos.empty:
                st.success(f"**{len(grupos_0votos)} grupos classificados como N√ÉO √â GRUPO** - Nenhum algoritmo indicou")
                
                st.write("**Caracter√≠sticas destes grupos:**")
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("Score ML M√©dio", f"{grupos_0votos['score_ml_percentual'].mean():.1f}%")
                with col2:
                    st.metric("Score GEI M√©dio", f"{grupos_0votos['score_final_ccs'].mean():.1f}")
                
                # Tabela resumida
                colunas_exibir = ['num_grupo', 'score_ml_percentual', 'score_final_ccs', 'qtd_cnpjs']
                st.dataframe(grupos_0votos[colunas_exibir].head(50), width='stretch', hide_index=True)
            else:
                st.info("Todos os grupos foram identificados como Grupo Econ√¥mico por pelo menos 1 algoritmo.")
        
        # ================================================================
        # SE√á√ÉO 6: EXPORTAR RESULTADOS
        # ================================================================
        st.header("6. Exportar Resultados")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # CSV com resultados de consenso
            colunas_export = [
                'num_grupo', 'qtd_cnpjs', 'score_ml_percentual', 'score_final_ccs',
                'votos_eh_grupo', 'consenso_classificacao', 'nivel_confianca',
                'kmeans_eh_grupo', 'dbscan_eh_grupo', 'iforest_eh_grupo',
                'socios_compartilhados', 'receita_maxima', 'total_indicios', 
                'contas_compartilhadas', 'acima_limite_sn'
            ]
            
            csv_resultados = df_grupos[colunas_export].to_csv(index=False)
            
            st.download_button(
                label="üì• Download Resultados Consenso (CSV)",
                data=csv_resultados,
                file_name=f"grupos_ml_consenso_{datetime.now().strftime('%Y%m%d_%H%M')}.csv",
                mime="text/csv"
            )
        
        with col2:
            # Excel com resultados detalhados por n√≠vel de consenso
            try:
                output = BytesIO()
                with pd.ExcelWriter(output, engine='openpyxl') as writer:
                    df_grupos.to_excel(writer, sheet_name='Todos os Grupos', index=False)
                    grupos_3votos.to_excel(writer, sheet_name='Consenso Forte (3-3)', index=False)
                    grupos_2votos.to_excel(writer, sheet_name='Consenso Moderado (2-3)', index=False)
                    grupos_1voto.to_excel(writer, sheet_name='Consenso Fraco (1-3)', index=False)
                    grupos_0votos.to_excel(writer, sheet_name='N√£o √© Grupo (0-3)', index=False)
                
                st.download_button(
                    label="üìä Download Completo (Excel)",
                    data=output.getvalue(),
                    file_name=f"grupos_ml_consenso_completo_{datetime.now().strftime('%Y%m%d_%H%M')}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
            except ImportError:
                st.warning("‚ö†Ô∏è Biblioteca openpyxl n√£o dispon√≠vel. Use o download CSV.")
    
    elif 'cluster' in df_grupos.columns:
        # MODO INDIVIDUAL - RESULTADOS
        st.header("4. Resultados da Classifica√ß√£o")
        
        # M√©tricas de avalia√ß√£o
        col1, col2, col3 = st.columns(3)
        
        with col1:
            grupos_economicos = (df_grupos['eh_grupo_economico'] == 'Grupo Econ√¥mico').sum()
            st.metric("Grupos Econ√¥micos Identificados", grupos_economicos)
        
        with col2:
            nao_grupos = (df_grupos['eh_grupo_economico'] == 'N√£o √© Grupo').sum()
            st.metric("N√£o √© Grupo Econ√¥mico", nao_grupos)
        
        with col3:
            if 'modelo_ml' in st.session_state and 'scaler_ml' in st.session_state:
                if algoritmo != "Isolation Forest" and len(df_grupos['cluster'].unique()) > 1:
                    X = df_grupos[features_para_modelo].fillna(0)
                    scaler = st.session_state['scaler_ml']
                    X_scaled = scaler.transform(X)
                    
                    if usar_pca and 'pca_ml' in st.session_state:
                        pca = st.session_state['pca_ml']
                        X_transformed = pca.transform(X_scaled)
                    else:
                        X_transformed = X_scaled
                    
                    try:
                        silhouette = silhouette_score(X_transformed, df_grupos['cluster'])
                        st.metric("Silhouette Score", f"{silhouette:.3f}")
                    except:
                        st.metric("Silhouette Score", "N/A")
        
        # Compara√ß√£o de scores
        fig = px.box(df_grupos, x='eh_grupo_economico', y='score_ml_percentual',
                    color='eh_grupo_economico',
                    title="Distribui√ß√£o de Scores ML por Classifica√ß√£o",
                    labels={'score_ml_percentual': 'Score ML (%)', 'eh_grupo_economico': 'Classifica√ß√£o'},
                    template=filtros['tema'],
                    color_discrete_map={
                        'Grupo Econ√¥mico': '#EF553B',
                        'N√£o √© Grupo': '#00CC96'
                    })
        st.plotly_chart(fig, use_container_width=True)
        
        # Tabelas
        st.header("5. Grupos Identificados")
        
        tab1, tab2 = st.tabs(["‚úÖ Grupos Econ√¥micos", "‚ùå N√£o √© Grupo"])
        
        with tab1:
            grupos_eco = df_grupos[df_grupos['eh_grupo_economico'] == 'Grupo Econ√¥mico'].sort_values('score_ml_percentual', ascending=False)
            
            if not grupos_eco.empty:
                st.write(f"**{len(grupos_eco)} grupos identificados como Grupo Econ√¥mico**")
                
                colunas_exibir = [
                    'num_grupo', 'score_ml_percentual', 'score_final_ccs', 'qtd_cnpjs',
                    'socios_compartilhados', 'receita_maxima', 'total_indicios',
                    'contas_compartilhadas'
                ]
                
                df_display = grupos_eco[colunas_exibir].copy()
                df_display['receita_maxima'] = df_display['receita_maxima'].apply(formatar_moeda)
                
                st.dataframe(df_display.head(50), width='stretch', hide_index=True)
            else:
                st.info("Nenhum grupo classificado como Grupo Econ√¥mico.")
        
        with tab2:
            nao_grupos_df = df_grupos[df_grupos['eh_grupo_economico'] == 'N√£o √© Grupo'].sort_values('score_ml_percentual', ascending=False)
            
            if not nao_grupos_df.empty:
                st.write(f"**{len(nao_grupos_df)} grupos classificados como N√£o √© Grupo**")
                
                colunas_exibir = [
                    'num_grupo', 'score_ml_percentual', 'score_final_ccs', 'qtd_cnpjs'
                ]
                
                st.dataframe(nao_grupos_df[colunas_exibir].head(50), width='stretch', hide_index=True)
            else:
                st.info("Todos grupos classificados como Grupo Econ√¥mico.")
        
        # Exporta√ß√£o
        st.header("6. Exportar Resultados")
        
        col1, col2 = st.columns(2)
        
        with col1:
            colunas_export = [
                'num_grupo', 'qtd_cnpjs', 'score_ml_percentual', 'score_final_ccs',
                'cluster', 'eh_grupo_economico', 'socios_compartilhados', 'receita_maxima',
                'total_indicios', 'contas_compartilhadas', 'acima_limite_sn'
            ]
            
            csv_resultados = df_grupos[colunas_export].to_csv(index=False)
            
            st.download_button(
                label="üì• Download Resultados (CSV)",
                data=csv_resultados,
                file_name=f"grupos_ml_classificacao_{datetime.now().strftime('%Y%m%d_%H%M')}.csv",
                mime="text/csv"
            )
        
        with col2:
            try:
                output = BytesIO()
                with pd.ExcelWriter(output, engine='openpyxl') as writer:
                    df_grupos.to_excel(writer, sheet_name='Todos os Grupos', index=False)
                    grupos_eco.to_excel(writer, sheet_name='Grupos Econ√¥micos', index=False)
                    nao_grupos_df.to_excel(writer, sheet_name='N√£o √© Grupo', index=False)
                
                st.download_button(
                    label="üìä Download Completo (Excel)",
                    data=output.getvalue(),
                    file_name=f"grupos_ml_analise_completa_{datetime.now().strftime('%Y%m%d_%H%M')}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
            except ImportError:
                st.warning("‚ö†Ô∏è Biblioteca openpyxl n√£o dispon√≠vel. Use o download CSV.")

def mostrar_detalhes_grupo(engine, num_grupo, df_grupos, filtros):
    """Mostra detalhes completos de um grupo espec√≠fico"""
    
    grupo_info = df_grupos[df_grupos['num_grupo'] == num_grupo].iloc[0]
    
    st.subheader(f"üìã Detalhes do Grupo {num_grupo}")
    
    # M√©tricas principais
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Score ML", f"{grupo_info['score_ml_percentual']:.1f}%")
    with col2:
        st.metric("CNPJs", int(grupo_info['qtd_cnpjs']))
    with col3:
        st.metric("Score GEI", f"{grupo_info['score_final_ccs']:.1f}")
    with col4:
        st.metric("Classifica√ß√£o", grupo_info.get('eh_grupo_economico', 'N/A'))
    
    # Vota√ß√£o dos algoritmos
    st.write("**Vota√ß√£o dos Algoritmos:**")
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("K-Means", "‚úÖ SIM" if grupo_info['kmeans_eh_grupo'] == 1 else "‚ùå N√ÉO")
    with col2:
        st.metric("DBSCAN", "‚úÖ SIM" if grupo_info['dbscan_eh_grupo'] == 1 else "‚ùå N√ÉO")
    with col3:
        st.metric("Isolation Forest", "‚úÖ SIM" if grupo_info['iforest_eh_grupo'] == 1 else "‚ùå N√ÉO")
    with col4:
        votos = int(grupo_info['votos_eh_grupo'])
        consenso = "FORTE" if votos == 3 else "MODERADO" if votos == 2 else "FRACO" if votos == 1 else "NENHUM"
        st.metric("Consenso", f"{consenso} ({votos}/3)")
    
    st.divider()
    
    # Caracter√≠sticas do grupo
    st.write("**Caracter√≠sticas:**")
    
    # Converter todos os valores para string para evitar conflito de tipos
    caracteristicas = {
        'Raz√£o Social Id√™ntica': 'Sim' if grupo_info['razao_social_identica'] == 1 else 'N√£o',
        'Nome Fantasia Id√™ntico': 'Sim' if grupo_info['fantasia_identica'] == 1 else 'N√£o',
        'CNAE Id√™ntico': 'Sim' if grupo_info['cnae_identico'] == 1 else 'N√£o',
        'Contador Id√™ntico': 'Sim' if grupo_info['contador_identico'] == 1 else 'N√£o',
        'Endere√ßo Id√™ntico': 'Sim' if grupo_info['endereco_identico'] == 1 else 'N√£o',
        'S√≥cios Compartilhados': str(int(grupo_info['socios_compartilhados'])),
        '√çndice Interconex√£o': f"{grupo_info['indice_interconexao']:.3f}",
        'Receita M√°xima': formatar_moeda(grupo_info['receita_maxima']),
        'Acima Limite SN': 'Sim' if grupo_info['acima_limite_sn'] == 1 else 'N√£o',
        'Total de Ind√≠cios': str(int(grupo_info['total_indicios'])),
        'Tipos Ind√≠cios Distintos': str(int(grupo_info['tipos_indicios_distintos'])),
        'Contas Compartilhadas': str(int(grupo_info['contas_compartilhadas'])),
        '√çndice Risco CCS': f"{grupo_info['indice_risco_ccs']:.4f}",
        '√çndice Risco C115': f"{grupo_info['indice_risco_c115']:.4f}",
        'Total Funcion√°rios': str(int(grupo_info['total_funcionarios'])),
        'Score Inconsist√™ncias NFe': f"{grupo_info['score_inconsistencias_nfe']:.2f}"
    }
    
    # Criar dataframe com tipos consistentes
    df_caract = pd.DataFrame({
        'Caracter√≠stica': list(caracteristicas.keys()),
        'Valor': list(caracteristicas.values())
    })
    
    # Garantir que ambas as colunas s√£o string
    df_caract['Caracter√≠stica'] = df_caract['Caracter√≠stica'].astype(str)
    df_caract['Valor'] = df_caract['Valor'].astype(str)
    
    st.dataframe(df_caract, hide_index=True)
    
    st.divider()
    
    # CNPJs do grupo
    st.write("**CNPJs do Grupo:**")
    
    query_cnpjs = f"""
    SELECT 
        g.cnpj,
        c.nm_razao_social,
        c.nm_fantasia,
        c.cd_cnae,
        c.nm_reg_apuracao,
        c.nm_munic as municipio
    FROM gessimples.gei_cnpj g
    LEFT JOIN usr_sat_ods.vw_ods_contrib c ON g.cnpj = c.nu_cnpj
    WHERE CAST(g.num_grupo AS INT) = {num_grupo}
    """
    
    try:
        df_cnpjs_grupo = pd.read_sql(query_cnpjs, engine)
        if not df_cnpjs_grupo.empty:
            # Garantir que todas as colunas s√£o string para evitar problemas com Arrow
            for col in df_cnpjs_grupo.columns:
                df_cnpjs_grupo[col] = df_cnpjs_grupo[col].astype(str)
            
            st.dataframe(df_cnpjs_grupo, hide_index=True)
        else:
            st.info("CNPJs n√£o encontrados ou erro ao carregar dados cadastrais.")
    except Exception as e:
        st.warning(f"Erro ao carregar CNPJs: {e}")
    
    st.divider()
    
    # S√≥cios compartilhados - SEM nm_socio
    if grupo_info['socios_compartilhados'] > 0:
        st.write("**S√≥cios Compartilhados:**")
        try:
            query_socios = f"""
            SELECT 
                cpf_socio,
                qtd_empresas
            FROM gessimples.gei_socios_compartilhados
            WHERE CAST(num_grupo AS INT) = {num_grupo}
            ORDER BY qtd_empresas DESC
            """
            
            df_socios = pd.read_sql(query_socios, engine)
            
            if not df_socios.empty:
                # Converter para string
                for col in df_socios.columns:
                    df_socios[col] = df_socios[col].astype(str)
                st.dataframe(df_socios.head(20), hide_index=True)
            else:
                st.info("Detalhes de s√≥cios n√£o dispon√≠veis.")
        except Exception as e:
            st.warning(f"N√£o foi poss√≠vel carregar s√≥cios: {e}")
    
    st.divider()
    
    # Ind√≠cios - SEM dt_referencia
    if grupo_info['total_indicios'] > 0:
        st.write("**Ind√≠cios Fiscais:**")
        try:
            query_indicios = f"""
            SELECT 
                tx_descricao_indicio,
                cnpj
            FROM gessimples.gei_indicios
            WHERE CAST(num_grupo AS INT) = {num_grupo}
            """
            
            df_indicios = pd.read_sql(query_indicios, engine)
            
            if not df_indicios.empty:
                # Resumo por tipo
                resumo_indicios = df_indicios['tx_descricao_indicio'].value_counts().reset_index()
                resumo_indicios.columns = ['Tipo de Ind√≠cio', 'Quantidade']
                
                col1, col2 = st.columns([1, 2])
                with col1:
                    st.dataframe(resumo_indicios, hide_index=True)
                with col2:
                    fig = px.bar(resumo_indicios, x='Quantidade', y='Tipo de Ind√≠cio',
                               orientation='h', title="Distribui√ß√£o de Ind√≠cios",
                               template=filtros.get('tema', 'plotly'))
                    st.plotly_chart(fig)
                
                # Mostrar lista completa
                st.write("**Lista de Ind√≠cios:**")
                st.dataframe(df_indicios.head(50), hide_index=True)
            else:
                st.info("Detalhes de ind√≠cios n√£o dispon√≠veis.")
        except Exception as e:
            st.warning(f"N√£o foi poss√≠vel carregar ind√≠cios: {e}")
    
    st.divider()
    
    # Contas compartilhadas (CCS)
    if grupo_info['contas_compartilhadas'] > 0:
        st.write("**Contas Compartilhadas (CCS):**")
        try:
            query_ccs = f"""
            SELECT 
                nr_cpf,
                nm_banco,
                cd_agencia,
                nr_conta,
                qtd_cnpjs_usando_conta,
                qtd_vinculos_ativos
            FROM gessimples.gei_ccs_cpf_compartilhado
            WHERE CAST(num_grupo AS INT) = {num_grupo}
            ORDER BY qtd_cnpjs_usando_conta DESC
            """
            
            df_ccs = pd.read_sql(query_ccs, engine)
            
            if not df_ccs.empty:
                # Converter para string
                for col in df_ccs.columns:
                    df_ccs[col] = df_ccs[col].astype(str)
                st.dataframe(df_ccs.head(20), hide_index=True)
            else:
                st.info("Detalhes de contas compartilhadas n√£o dispon√≠veis.")
        except Exception as e:
            st.warning(f"N√£o foi poss√≠vel carregar CCS: {e}")
    
def gerar_pdf_analise_pontual(cnpjs_validos, resultados):
    """Gera PDF completo da an√°lise pontual"""
    buffer = BytesIO()
    doc = SimpleDocTemplate(buffer, pagesize=A4, topMargin=0.5*inch, bottomMargin=0.5*inch)
    styles = getSampleStyleSheet()
    story = []
    
    # T√≠tulo
    title_style = ParagraphStyle(
        'CustomTitle',
        parent=styles['Heading1'],
        fontSize=20,
        textColor=colors.HexColor('#1f77b4'),
        spaceAfter=20,
        alignment=TA_CENTER
    )
    story.append(Paragraph("AN√ÅLISE PONTUAL DE CNPJs", title_style))
    story.append(Paragraph("Sistema GEI - Receita Estadual de Santa Catarina", styles['Normal']))
    story.append(Paragraph(f"Data de Gera√ß√£o: {datetime.now().strftime('%d/%m/%Y %H:%M')}", styles['Normal']))
    story.append(Spacer(1, 0.3*inch))
    
    # SE√á√ÉO 1: RESUMO EXECUTIVO
    story.append(Paragraph("<b>1. RESUMO EXECUTIVO</b>", styles['Heading2']))
    
    dados_resumo = [
        ['M√©trica', 'Valor'],
        ['CNPJs Analisados', str(len(cnpjs_validos))],
        ['CNPJs com Cadastro', str(len(resultados.get('cadastro', pd.DataFrame())))],
        ['V√≠nculos Societ√°rios', str(len(resultados.get('socios', pd.DataFrame())))],
        ['S√≥cios Compartilhados', str(len(resultados.get('socios_compartilhados', pd.Series())))],
        ['Notas Fiscais (2025)', str(len(resultados.get('nfe', pd.DataFrame())))],
        ['Ind√≠cios Fiscais', str(len(resultados.get('indicios', pd.DataFrame())))],
        ['Contas Banc√°rias', str(len(resultados.get('ccs', pd.DataFrame())))],
        ['Funcion√°rios Encontrados', str(resultados.get('funcionarios', pd.DataFrame())['total_funcionarios'].sum() if not resultados.get('funcionarios', pd.DataFrame()).empty else 0)],
        ['Em Grupos GEI Existentes', str(len(resultados.get('grupos_existentes', pd.DataFrame())))]
    ]
    
    table = Table(dados_resumo, colWidths=[3*inch, 3*inch])
    table.setStyle(TableStyle([
        ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
        ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
        ('ALIGN', (0, 0), (-1, -1), 'LEFT'),
        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
        ('FONTSIZE', (0, 0), (-1, 0), 11),
        ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
        ('BACKGROUND', (0, 1), (-1, -1), colors.beige),
        ('GRID', (0, 0), (-1, -1), 1, colors.black)
    ]))
    story.append(table)
    story.append(Spacer(1, 0.3*inch))
    
    # ALERTAS CR√çTICOS
    alertas = []
    
    if len(resultados.get('socios_compartilhados', pd.Series())) > 0:
        alertas.append("CR√çTICO: S√≥cios compartilhados detectados - poss√≠vel grupo econ√¥mico")
    
    # Verificar receitas altas (PGDAS + DIME)
    tem_pgdas_alerta = not resultados.get('pgdas', pd.DataFrame()).empty
    tem_dime_alerta = not resultados.get('dime', pd.DataFrame()).empty

    cnpjs_acima_limite = set()
    if tem_pgdas_alerta:
        receitas_altas_pgdas = resultados['pgdas'][resultados['pgdas']['receita_12m'] > 4800000]
        cnpjs_acima_limite.update(receitas_altas_pgdas['cnpj'].unique())
    if tem_dime_alerta:
        receitas_altas_dime = resultados['dime'][resultados['dime']['receita_12m'] > 4800000]
        cnpjs_acima_limite.update(receitas_altas_dime['cnpj'].unique())

    if cnpjs_acima_limite:
        alertas.append(f"ATEN√á√ÉO: {len(cnpjs_acima_limite)} CNPJs com faturamento acima do limite SN (PGDAS/DIME)")
    
    if not resultados.get('indicios', pd.DataFrame()).empty:
        alertas.append(f"CR√çTICO: {len(resultados['indicios'])} ind√≠cios fiscais identificados")
    
    if not resultados.get('ccs', pd.DataFrame()).empty:
        cpfs_contas = resultados['ccs'].groupby('nr_cpf')['cnpj'].nunique()
        if (cpfs_contas > 1).any():
            alertas.append("ATEN√á√ÉO: Contas banc√°rias compartilhadas detectadas")
    
    if alertas:
        story.append(Paragraph("<b>ALERTAS:</b>", styles['Heading3']))
        for alerta in alertas:
            story.append(Paragraph(f"‚Ä¢ {alerta}", styles['Normal']))
        story.append(Spacer(1, 0.2*inch))
    
    story.append(PageBreak())
    
    # SE√á√ÉO 2: CNPJs ANALISADOS E DADOS CADASTRAIS
    story.append(Paragraph(f"<b>2. CNPJs ANALISADOS ({len(cnpjs_validos)})</b>", styles['Heading2']))
    
    for cnpj in cnpjs_validos:
        story.append(Paragraph(f"<b>CNPJ: {cnpj}</b>", styles['Normal']))
        
        if not resultados.get('cadastro', pd.DataFrame()).empty:
            cadastro = resultados['cadastro'][resultados['cadastro']['cnpj'] == cnpj]
            if not cadastro.empty:
                info = cadastro.iloc[0]
                story.append(Paragraph(f"Raz√£o Social: {info.get('nm_razao_social', 'N/A')}", styles['Normal']))
                if pd.notna(info.get('nm_fantasia')):
                    story.append(Paragraph(f"Nome Fantasia: {info.get('nm_fantasia')}", styles['Normal']))
                if pd.notna(info.get('cd_cnae')):
                    story.append(Paragraph(f"CNAE: {info.get('cd_cnae')}", styles['Normal']))
                if pd.notna(info.get('nm_reg_apuracao')):
                    story.append(Paragraph(f"Regime: {info.get('nm_reg_apuracao')}", styles['Normal']))
                if pd.notna(info.get('municipio')):
                    story.append(Paragraph(f"Munic√≠pio: {info.get('municipio')}", styles['Normal']))
                if pd.notna(info.get('nm_contador')):
                    story.append(Paragraph(f"Contador: {info.get('nm_contador')}", styles['Normal']))
        
        story.append(Spacer(1, 0.15*inch))
    
    story.append(PageBreak())
    
    # =====================================================================
    # SE√á√ÉO 3: AN√ÅLISE DE SIMILARIDADE - EVID√äNCIAS DE GRUPO ECON√îMICO
    # =====================================================================
    story.append(Paragraph("<b>3. AN√ÅLISE DE SIMILARIDADE - EVID√äNCIAS DE GRUPO ECON√îMICO</b>", styles['Heading2']))
    story.append(Spacer(1, 0.1*inch))
    
    # Calcular score de similaridade
    score_similaridade = 0
    max_score_possivel = 0
    evidencias_pdf = {}
    
    # 3.1 - AN√ÅLISE CADASTRAL
    story.append(Paragraph("<b>3.1. Consist√™ncia Cadastral</b>", styles['Heading3']))
    
    if not resultados['cadastro'].empty and len(resultados['cadastro']) > 1:
        cadastro_dados = []
        
        # Raz√£o Social
        max_score_possivel += 2
        razoes = resultados['cadastro']['nm_razao_social'].dropna().unique()
        if len(razoes) == 1:
            cadastro_dados.append(['Raz√£o Social', 'ID√äNTICA', '1', '+2.0', 'CR√çTICO'])
            evidencias_pdf['razao_social'] = True
            score_similaridade += 2
        else:
            cadastro_dados.append(['Raz√£o Social', 'DIFERENTES', str(len(razoes)), '0.0', '-'])
        
        # Contador
        max_score_possivel += 2
        contadores = resultados['cadastro']['nm_contador'].dropna().unique()
        if len(contadores) == 1:
            cadastro_dados.append(['Contador', 'MESMO', '1', '+2.0', 'CR√çTICO'])
            evidencias_pdf['contador'] = True
            score_similaridade += 2
        else:
            cadastro_dados.append(['Contador', 'DIFERENTES', str(len(contadores)), '0.0', '-'])
        
        # Endere√ßo
        max_score_possivel += 3
        enderecos = resultados['cadastro'].apply(
            lambda row: f"{row.get('nm_logradouro', '')} {row.get('nu_logradouro', '')} {row.get('nm_bairro', '')} {row.get('municipio', '')}".strip(),
            axis=1
        ).unique()
        if len(enderecos) == 1:
            cadastro_dados.append(['Endere√ßo', 'ID√äNTICO', '1', '+3.0', 'CR√çTICO'])
            evidencias_pdf['endereco'] = True
            score_similaridade += 3
        else:
            cadastro_dados.append(['Endere√ßo', 'DIFERENTES', str(len(enderecos)), '0.0', '-'])
        
        # CNAE
        max_score_possivel += 1
        cnaes = resultados['cadastro']['cd_cnae'].dropna().unique()
        if len(cnaes) == 1:
            cadastro_dados.append(['CNAE', 'ID√äNTICO', '1', '+1.0', 'Alto'])
            evidencias_pdf['cnae'] = True
            score_similaridade += 1
        else:
            cadastro_dados.append(['CNAE', 'DIFERENTES', str(len(cnaes)), '0.0', '-'])
        
        # Munic√≠pio
        max_score_possivel += 0.5
        municipios = resultados['cadastro']['municipio'].dropna().unique()
        if len(municipios) == 1:
            cadastro_dados.append(['Munic√≠pio', 'MESMO', '1', '+0.5', 'Leve'])
            score_similaridade += 0.5
        
        table = Table([['Atributo', 'Status', 'Qtd', 'Pontos', 'N√≠vel']] + cadastro_dados,
                     colWidths=[1.5*inch, 1.3*inch, 0.8*inch, 0.9*inch, 1*inch])
        table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
            ('ALIGN', (0, 0), (-1, -1), 'LEFT'),
            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
            ('FONTSIZE', (0, 0), (-1, -1), 8),
            ('GRID', (0, 0), (-1, -1), 1, colors.black)
        ]))
        story.append(table)
        story.append(Spacer(1, 0.2*inch))
    
    # 3.2 - V√çNCULOS SOCIET√ÅRIOS
    story.append(Paragraph("<b>3.2. V√≠nculos Societ√°rios</b>", styles['Heading3']))
    
    if not resultados['socios'].empty and len(cnpjs_validos) > 1:
        socios_dados = []
        
        max_score_possivel += 5
        socios_compartilhados = resultados.get('socios_compartilhados', pd.Series())
        
        if len(socios_compartilhados) > 0:
            pontos_socios = min(len(socios_compartilhados) * 2, 5)
            socios_dados.append(['S√≥cios Compartilhados', str(len(socios_compartilhados)), 
                                'DETECTADO', f'+{pontos_socios:.1f}', 'CR√çTICO'])
            evidencias_pdf['socios_compartilhados'] = True
            score_similaridade += pontos_socios
            
            # Listar s√≥cios compartilhados
            story.append(Paragraph("S√≥cios que participam de m√∫ltiplos CNPJs:", styles['Normal']))
            for cpf, qtd in list(socios_compartilhados.items())[:10]:
                story.append(Paragraph(f"‚Ä¢ CPF {cpf}: Presente em {qtd} CNPJs", 
                                      ParagraphStyle('Indent', parent=styles['Normal'], leftIndent=20)))
        else:
            socios_dados.append(['S√≥cios Compartilhados', '0', 'N√ÉO DETECTADO', '0.0', '-'])
        
        table = Table([['Indicador', 'Quantidade', 'Status', 'Pontos', 'N√≠vel']] + socios_dados,
                     colWidths=[2*inch, 1*inch, 1.5*inch, 0.8*inch, 0.7*inch])
        table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
            ('ALIGN', (0, 0), (-1, -1), 'LEFT'),
            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
            ('FONTSIZE', (0, 0), (-1, -1), 8),
            ('GRID', (0, 0), (-1, -1), 1, colors.black)
        ]))
        story.append(table)
        story.append(Spacer(1, 0.2*inch))
    
    # 3.3 - FATURAMENTO (PGDAS + DIME)
    story.append(Paragraph("<b>3.3. An√°lise de Faturamento (PGDAS / DIME)</b>", styles['Heading3']))

    # Consolidar dados de faturamento
    tem_pgdas_pdf = not resultados.get('pgdas', pd.DataFrame()).empty
    tem_dime_pdf = not resultados.get('dime', pd.DataFrame()).empty

    if (tem_pgdas_pdf or tem_dime_pdf) and len(cnpjs_validos) > 1:
        receitas_dados = []

        # Calcular receitas consolidadas
        receitas_pgdas = resultados['pgdas'].groupby('cnpj')['receita_12m'].max() if tem_pgdas_pdf else pd.Series(dtype=float)
        receitas_dime = resultados['dime'].groupby('cnpj')['receita_12m'].max() if tem_dime_pdf else pd.Series(dtype=float)

        # Combinar receitas (soma de PGDAS e DIME por CNPJ √∫nico)
        todos_cnpjs = set(receitas_pgdas.index.tolist()) | set(receitas_dime.index.tolist())
        receitas_por_cnpj = pd.Series(dtype=float)
        for cnpj in todos_cnpjs:
            valor_pgdas = receitas_pgdas.get(cnpj, 0)
            valor_dime = receitas_dime.get(cnpj, 0)
            receitas_por_cnpj[cnpj] = max(valor_pgdas, valor_dime)  # Usar o maior valor para evitar duplica√ß√£o

        receita_total_grupo = receitas_por_cnpj.sum()

        # Info sobre fontes
        fontes_str = []
        if tem_pgdas_pdf:
            fontes_str.append(f"PGDAS: {len(receitas_pgdas)} CNPJs")
        if tem_dime_pdf:
            fontes_str.append(f"DIME: {len(receitas_dime)} CNPJs")
        story.append(Paragraph(f"Fontes: {', '.join(fontes_str)}", styles['Normal']))
        story.append(Spacer(1, 0.1*inch))

        max_score_possivel += 5
        if receita_total_grupo > 4800000:
            excesso = receita_total_grupo - 4800000
            receitas_dados.append(['Faturamento Total', formatar_moeda(receita_total_grupo),
                                   'ACIMA LIMITE', formatar_moeda(excesso), '+5.0', 'CR√çTICO'])
            evidencias_pdf['receita_excesso'] = True
            score_similaridade += 5
        else:
            receitas_dados.append(['Faturamento Total', formatar_moeda(receita_total_grupo),
                                   'DENTRO LIMITE', '-', '0.0', '-'])

        # Distribui√ß√£o uniforme
        max_score_possivel += 2
        if len(receitas_por_cnpj) > 1:
            receita_media = receitas_por_cnpj.mean()
            desvio_padrao = receitas_por_cnpj.std()
            coef_variacao = (desvio_padrao / receita_media) if receita_media > 0 else 0

            if coef_variacao < 0.3:
                receitas_dados.append(['Distribui√ß√£o', f'CV: {coef_variacao:.2f}',
                                       'MUITO UNIFORME', '-', '+2.0', 'Planejada'])
                evidencias_pdf['receita_uniforme'] = True
                score_similaridade += 2
            else:
                receitas_dados.append(['Distribui√ß√£o', f'CV: {coef_variacao:.2f}',
                                       'VARIADA', '-', '0.0', '-'])

        # An√°lise de regimes mistos
        if tem_pgdas_pdf and tem_dime_pdf:
            receitas_dados.append(['Regimes Tribut√°rios', 'Misto (SN + Normal)',
                                   'ATEN√á√ÉO', '-', '+1.0', 'Planejamento'])
            score_similaridade += 1

        table = Table([['Indicador', 'Valor', 'Status', 'Detalhe', 'Pontos', 'N√≠vel']] + receitas_dados,
                     colWidths=[1.2*inch, 1.3*inch, 1.2*inch, 1*inch, 0.6*inch, 0.7*inch])
        table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
            ('ALIGN', (0, 0), (-1, -1), 'LEFT'),
            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
            ('FONTSIZE', (0, 0), (-1, -1), 7),
            ('GRID', (0, 0), (-1, -1), 1, colors.black)
        ]))
        story.append(table)
        story.append(Spacer(1, 0.2*inch))
    
    # 3.4 - NOTAS FISCAIS
    story.append(Paragraph("<b>3.4. Compartilhamento em Notas Fiscais</b>", styles['Heading3']))
    
    if not resultados['nfe'].empty and len(cnpjs_validos) > 1:
        nfe_dados = []
        
        # IPs compartilhados
        max_score_possivel += 3
        if 'nfe_ip_transmissao' in resultados['nfe'].columns:
            ips_por_cnpj = {}
            for cnpj in cnpjs_validos:
                ips = resultados['nfe'][resultados['nfe']['nfe_cnpj_cpf_emit'] == cnpj]['nfe_ip_transmissao'].dropna().unique()
                if len(ips) > 0:
                    ips_por_cnpj[cnpj] = set(ips)
            
            if len(ips_por_cnpj) > 1:
                all_ips = set()
                for ips in ips_por_cnpj.values():
                    all_ips.update(ips)
                
                ips_compart = [ip for ip in all_ips if sum(1 for ips in ips_por_cnpj.values() if ip in ips) > 1]
                
                if len(ips_compart) > 0:
                    pontos_ip = min(len(ips_compart), 3)
                    nfe_dados.append(['IPs Transmiss√£o', str(len(ips_compart)), 'COMPARTILHADOS', 
                                     f'+{pontos_ip:.1f}', 'CR√çTICO'])
                    evidencias_pdf['ip_compartilhado'] = True
                    score_similaridade += pontos_ip
                else:
                    nfe_dados.append(['IPs Transmiss√£o', '0', 'N√ÉO COMPART.', '0.0', '-'])
        
        # Clientes compartilhados
        max_score_possivel += 2
        clientes_por_cnpj = {}
        for cnpj in cnpjs_validos:
            clientes = resultados['nfe'][resultados['nfe']['nfe_cnpj_cpf_emit'] == cnpj]['nfe_cnpj_cpf_dest'].dropna().unique()
            clientes_por_cnpj[cnpj] = set(clientes)
        
        if len(clientes_por_cnpj) > 1:
            clientes_compart = set.intersection(*clientes_por_cnpj.values()) if clientes_por_cnpj else set()
            
            if len(clientes_compart) > 0:
                pontos_cli = min(len(clientes_compart) / 10, 2)
                nfe_dados.append(['Clientes Comuns', str(len(clientes_compart)), 'DETECTADOS',
                                 f'+{pontos_cli:.1f}', 'Moderado'])
                evidencias_pdf['clientes_comuns'] = True
                score_similaridade += pontos_cli
        
        # Fornecedores compartilhados
        max_score_possivel += 2
        fornec_por_cnpj = {}
        for cnpj in cnpjs_validos:
            fornec = resultados['nfe'][resultados['nfe']['nfe_cnpj_cpf_dest'] == cnpj]['nfe_cnpj_cpf_emit'].dropna().unique()
            fornec_por_cnpj[cnpj] = set(fornec)
        
        if len(fornec_por_cnpj) > 1:
            fornec_compart = set.intersection(*fornec_por_cnpj.values()) if fornec_por_cnpj else set()
            
            if len(fornec_compart) > 0:
                pontos_forn = min(len(fornec_compart) / 10, 2)
                nfe_dados.append(['Fornecedores Comuns', str(len(fornec_compart)), 'DETECTADOS',
                                 f'+{pontos_forn:.1f}', 'Moderado'])
                evidencias_pdf['fornecedores_comuns'] = True
                score_similaridade += pontos_forn
        
        # >>> ADICIONAR AQUI <
        # Endere√ßos de emiss√£o compartilhados
        max_score_possivel += 2
        if 'nfe_emit_end_completo' in resultados['nfe'].columns:
            enderecos_emit = resultados['nfe'][resultados['nfe']['nfe_cnpj_cpf_emit'].isin(cnpjs_validos)]['nfe_emit_end_completo'].dropna().unique()
            if len(enderecos_emit) == 1 and len(enderecos_emit[0]) > 10:
                nfe_dados.append(['Endere√ßo Emiss√£o', '1', 'MESMO ENDERE√áO',
                                 '+2.0', 'CR√çTICO'])
                evidencias_pdf['endereco_nfe_emit'] = True
                score_similaridade += 2
        
        # Endere√ßos de destino compartilhados
        max_score_possivel += 2
        if 'nfe_dest_end_completo' in resultados['nfe'].columns:
            enderecos_dest = resultados['nfe'][resultados['nfe']['nfe_cnpj_cpf_dest'].isin(cnpjs_validos)]['nfe_dest_end_completo'].dropna().unique()
            if len(enderecos_dest) == 1 and len(enderecos_dest[0]) > 10:
                nfe_dados.append(['Endere√ßo Destino', '1', 'MESMO ENDERE√áO',
                                 '+2.0', 'CR√çTICO'])
                evidencias_pdf['endereco_nfe_dest'] = True
                score_similaridade += 2
        # >>> FIM DA ADI√á√ÉO <
        
        if nfe_dados:
            table = Table([['Indicador', 'Quantidade', 'Status', 'Pontos', 'N√≠vel']] + nfe_dados,
                         colWidths=[1.8*inch, 1.2*inch, 1.3*inch, 0.8*inch, 0.9*inch])
            table.setStyle(TableStyle([
                ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
                ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
                ('ALIGN', (0, 0), (-1, -1), 'LEFT'),
                ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                ('FONTSIZE', (0, 0), (-1, -1), 8),
                ('GRID', (0, 0), (-1, -1), 1, colors.black)
            ]))
            story.append(table)
            story.append(Spacer(1, 0.2*inch))
    
    # 3.5 - CONV√äNIO 115
    story.append(Paragraph("<b>3.5. Conv√™nio 115</b>", styles['Heading3']))
    
    if not resultados['c115'].empty and len(cnpjs_validos) > 1:
        c115_dados = []
        
        max_score_possivel += 3
        identificadores = resultados['c115'].groupby('nu_identificador_tomador')['cnpj_tomador'].nunique()
        ident_compart = identificadores[identificadores > 1]
        
        if len(ident_compart) > 0:
            pontos_id = min(len(ident_compart), 3)
            c115_dados.append(['Identificadores', str(len(ident_compart)), 'COMPARTILHADOS',
                              f'+{pontos_id:.1f}', 'CR√çTICO'])
            evidencias_pdf['c115_identificador'] = True
            score_similaridade += pontos_id
        else:
            c115_dados.append(['Identificadores', '0', 'N√ÉO COMPART.', '0.0', '-'])
        
        # Telefones
        max_score_possivel += 2
        if 'nu_tel_contato' in resultados['c115'].columns:
            telefones = resultados['c115'].groupby('nu_tel_contato')['cnpj_tomador'].nunique()
            tel_compart = telefones[telefones > 1]
            
            if len(tel_compart) > 0:
                pontos_tel = min(len(tel_compart), 2)
                c115_dados.append(['Telefones', str(len(tel_compart)), 'COMPARTILHADOS',
                                  f'+{pontos_tel:.1f}', 'Alto'])
                evidencias_pdf['c115_telefone'] = True
                score_similaridade += pontos_tel
        
        if c115_dados:
            table = Table([['Indicador', 'Quantidade', 'Status', 'Pontos', 'N√≠vel']] + c115_dados,
                         colWidths=[1.8*inch, 1.2*inch, 1.3*inch, 0.8*inch, 0.9*inch])
            table.setStyle(TableStyle([
                ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
                ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
                ('ALIGN', (0, 0), (-1, -1), 'LEFT'),
                ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                ('FONTSIZE', (0, 0), (-1, -1), 8),
                ('GRID', (0, 0), (-1, -1), 1, colors.black)
            ]))
            story.append(table)
            story.append(Spacer(1, 0.2*inch))
    
    # 3.6 - CONTAS BANC√ÅRIAS (CCS)
    story.append(Paragraph("<b>3.6. Contas Banc√°rias - CCS</b>", styles['Heading3']))
    
    if not resultados['ccs'].empty and len(cnpjs_validos) > 1:
        ccs_dados = []
        
        max_score_possivel += 4
        cpfs_contas = resultados['ccs'].groupby('nr_cpf')['cnpj'].nunique()
        cpfs_compart = cpfs_contas[cpfs_contas > 1]
        
        if len(cpfs_compart) > 0:
            pontos_cpf = min(len(cpfs_compart) * 2, 4)
            ccs_dados.append(['CPFs M√∫ltiplas Contas', str(len(cpfs_compart)), 'DETECTADOS',
                             f'+{pontos_cpf:.1f}', 'CR√çTICO'])
            evidencias_pdf['ccs_cpf_compartilhado'] = True
            score_similaridade += pontos_cpf
            
            # Listar CPFs compartilhados
            story.append(Paragraph("CPFs com acesso a m√∫ltiplas contas:", styles['Normal']))
            for cpf, qtd in list(cpfs_compart.items())[:5]:
                story.append(Paragraph(f"‚Ä¢ CPF {cpf}: {qtd} CNPJs",
                                      ParagraphStyle('Indent', parent=styles['Normal'], leftIndent=20)))
        else:
            ccs_dados.append(['CPFs M√∫ltiplas Contas', '0', 'N√ÉO DETECTADOS', '0.0', '-'])
        
        if ccs_dados:
            table = Table([['Indicador', 'Quantidade', 'Status', 'Pontos', 'N√≠vel']] + ccs_dados,
                         colWidths=[1.8*inch, 1.2*inch, 1.3*inch, 0.8*inch, 0.9*inch])
            table.setStyle(TableStyle([
                ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
                ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
                ('ALIGN', (0, 0), (-1, -1), 'LEFT'),
                ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                ('FONTSIZE', (0, 0), (-1, -1), 8),
                ('GRID', (0, 0), (-1, -1), 1, colors.black)
            ]))
            story.append(table)
            story.append(Spacer(1, 0.2*inch))
    
    story.append(PageBreak())
    
    # 3.7 - SCORE FINAL DE SIMILARIDADE
    story.append(Paragraph("<b>3.7. Score Final de Similaridade</b>", styles['Heading3']))
    
    # Tabela de score
    percentual = (score_similaridade / max_score_possivel * 100) if max_score_possivel > 0 else 0
    total_evidencias = len([v for v in evidencias_pdf.values() if v])
    
    # Determinar n√≠vel de risco
    if score_similaridade >= 15:
        nivel_risco = "CR√çTICO"
        cor_nivel = colors.red
    elif score_similaridade >= 10:
        nivel_risco = "ALTO"
        cor_nivel = colors.orange
    elif score_similaridade >= 5:
        nivel_risco = "MODERADO"
        cor_nivel = colors.yellow
    else:
        nivel_risco = "BAIXO"
        cor_nivel = colors.green
    
    dados_score = [
        ['M√©trica', 'Valor'],
        ['Score de Similaridade', f"{score_similaridade:.1f} pontos"],
        ['Score M√°ximo Poss√≠vel', f"{max_score_possivel:.1f} pontos"],
        ['Percentual Atingido', f"{percentual:.1f}%"],
        ['Total de Evid√™ncias', str(total_evidencias)],
        ['N√≠vel de Risco', nivel_risco]
    ]
    
    table = Table(dados_score, colWidths=[3*inch, 3*inch])
    table.setStyle(TableStyle([
        ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
        ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
        ('ALIGN', (0, 0), (-1, -1), 'LEFT'),
        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
        ('GRID', (0, 0), (-1, -1), 1, colors.black),
        ('BACKGROUND', (0, -1), (-1, -1), cor_nivel)
    ]))
    story.append(table)
    story.append(Spacer(1, 0.2*inch))
    
    # Lista de evid√™ncias encontradas
    if evidencias_pdf:
        story.append(Paragraph("<b>Evid√™ncias Identificadas:</b>", styles['Heading3']))
        
        categorias_evidencias = {
                    'Cadastrais': ['razao_social', 'fantasia', 'cnae', 'contador', 'endereco'],
                    'Societ√°rias': ['socios_compartilhados'],
                    'Fiscais': ['receita_excesso', 'receita_uniforme', 'receita_correlacao'],
                    'Operacionais': ['ip_compartilhado', 'clientes_comuns', 'fornecedores_comuns', 'produtos_comuns', 'desc_produtos_comuns', 'tel_emit_compartilhado', 'email_dest_compartilhado', 'endereco_nfe_emit', 'endereco_nfe_dest'],
                    'C115': ['c115_identificador', 'c115_telefone'],
                    'Financeiras': ['ccs_cpf_compartilhado', 'socios_meios_pagamento']
                }
        
        for categoria, chaves in categorias_evidencias.items():
            evidencias_cat = [k.replace('_', ' ').title() for k in chaves if evidencias_pdf.get(k, False)]
            if evidencias_cat:
                story.append(Paragraph(f"<b>{categoria}:</b> {', '.join(evidencias_cat)}", styles['Normal']))
        
        story.append(Spacer(1, 0.2*inch))
    
    # Conclus√£o baseada no score
    story.append(Paragraph("<b>Conclus√£o da An√°lise de Similaridade:</b>", styles['Heading3']))
    
    if score_similaridade >= 15:
        conclusao = """
        FORTE EVID√äNCIA DE GRUPO ECON√îMICO - Os CNPJs analisados apresentam m√∫ltiplas e graves 
        evid√™ncias de pertencerem ao mesmo grupo econ√¥mico. As similaridades detectadas em dados 
        cadastrais, v√≠nculos societ√°rios, padr√µes operacionais e indicadores fiscais sugerem 
        fortemente opera√ß√£o coordenada e gest√£o centralizada.
        
        RECOMENDA√á√ÉO URGENTE: Cria√ß√£o imediata de grupo GEI para monitoramento integrado, an√°lise 
        aprofundada de poss√≠vel planejamento tribut√°rio abusivo, verifica√ß√£o de fraude √† lei 
        (fracionamento artificial), intima√ß√£o dos contribuintes para esclarecimentos e considerar 
        procedimento fiscal conjunto.
        """
    elif score_similaridade >= 10:
        conclusao = """
        EVID√äNCIA SIGNIFICATIVA DE GRUPO ECON√îMICO - Os CNPJs apresentam v√°rias caracter√≠sticas 
        compat√≠veis com grupo econ√¥mico. As evid√™ncias encontradas justificam investiga√ß√£o mais 
        aprofundada.
        
        RECOMENDA√á√ÉO: Cria√ß√£o de grupo GEI para monitoramento, an√°lise complementar com dados 
        adicionais, solicitar documenta√ß√£o adicional aos contribuintes, monitoramento refor√ßado 
        nos pr√≥ximos per√≠odos e verificar hist√≥rico de altera√ß√µes cadastrais.
        """
    elif score_similaridade >= 5:
        conclusao = """
        IND√çCIOS MODERADOS DE GRUPO ECON√îMICO - Alguns ind√≠cios sugerem poss√≠vel vincula√ß√£o entre 
        os CNPJs, mas n√£o s√£o conclusivos. Recomenda-se monitoramento e coleta de evid√™ncias 
        adicionais.
        
        RECOMENDA√á√ÉO: Monitoramento peri√≥dico dos CNPJs, aten√ß√£o a novos ind√≠cios que possam surgir, 
        cruzamento com outras bases de dados e acompanhar evolu√ß√£o das receitas.
        """
    else:
        conclusao = """
        BAIXA EVID√äNCIA DE GRUPO ECON√îMICO - Com base nos dados analisados, n√£o foram encontradas 
        evid√™ncias significativas de que os CNPJs perten√ßam ao mesmo grupo econ√¥mico. As 
        similaridades detectadas podem ser coincid√™ncias ou caracter√≠sticas comuns do setor.
        
        RECOMENDA√á√ÉO: Monitoramento de rotina conforme procedimentos padr√£o e aten√ß√£o caso surjam 
        novos ind√≠cios futuramente.
        """
    
    story.append(Paragraph(conclusao, styles['Normal']))
    story.append(PageBreak())
    
    # DEMAIS SE√á√ïES (mantidas do c√≥digo original)
    # SE√á√ÉO 4: V√çNCULOS SOCIET√ÅRIOS (detalhamento)
    if not resultados.get('socios', pd.DataFrame()).empty:
        story.append(Paragraph(f"<b>4. V√çNCULOS SOCIET√ÅRIOS ({len(resultados['socios'])} v√≠nculos)</b>", styles['Heading2']))
        
        dados_socios = [['CNPJ', 'CPF S√≥cio', 'Qualifica√ß√£o', 'Rela√ß√£o Ativa']]
        for _, row in resultados['socios'].head(50).iterrows():
            dados_socios.append([
                str(row.get('cnpj', '')),
                str(row.get('cpf_socio', '')),
                str(row.get('nm_qualificacao', ''))[:25],
                str(row.get('sn_relacao_ativa', ''))
            ])
        
        table = Table(dados_socios, colWidths=[1.5*inch, 1.5*inch, 2*inch, 1*inch])
        table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
            ('ALIGN', (0, 0), (-1, -1), 'LEFT'),
            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
            ('FONTSIZE', (0, 0), (-1, -1), 8),
            ('GRID', (0, 0), (-1, -1), 1, colors.black)
        ]))
        story.append(table)
        story.append(PageBreak())
    
    # SE√á√ÉO 5: FATURAMENTO DECLARADO (PGDAS + DIME)
    tem_pgdas = not resultados.get('pgdas', pd.DataFrame()).empty
    tem_dime = not resultados.get('dime', pd.DataFrame()).empty
    tem_faturamento = not resultados.get('faturamento', pd.DataFrame()).empty

    if tem_pgdas or tem_dime or tem_faturamento:
        story.append(Paragraph("<b>5. FATURAMENTO DECLARADO (PGDAS / DIME)</b>", styles['Heading2']))

        # 5.1 PGDAS (Simples Nacional)
        if tem_pgdas:
            story.append(Paragraph("<b>5.1 PGDAS - Simples Nacional</b>", styles['Heading3']))

            receita_max_pgdas = resultados['pgdas'].groupby('cnpj')['receita_12m'].max().reset_index()

            dados_pgdas = [['CNPJ', 'Receita M√°xima (12m)', 'Acima Limite SN']]
            for _, row in receita_max_pgdas.iterrows():
                receita = row['receita_12m']
                dados_pgdas.append([
                    str(row['cnpj']),
                    formatar_moeda(receita),
                    'SIM' if receita > 4800000 else 'N√ÉO'
                ])

            table_pgdas = Table(dados_pgdas, colWidths=[2*inch, 2.5*inch, 1.5*inch])
            table_pgdas.setStyle(TableStyle([
                ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#4CAF50')),
                ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
                ('ALIGN', (0, 0), (-1, -1), 'LEFT'),
                ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                ('GRID', (0, 0), (-1, -1), 1, colors.black)
            ]))
            story.append(table_pgdas)
            story.append(Spacer(1, 0.2*inch))

        # 5.2 DIME (Regime Normal)
        if tem_dime:
            story.append(Paragraph("<b>5.2 DIME - Regime Normal</b>", styles['Heading3']))

            df_dime = resultados['dime']
            receita_max_dime = df_dime.groupby('cnpj')['receita_12m'].max().reset_index()

            dados_dime = [['CNPJ', 'Faturamento M√°ximo (12m)', 'Total Cr√©ditos', 'Total D√©bitos']]
            for _, row in receita_max_dime.iterrows():
                cnpj = str(row['cnpj'])
                faturamento = row['receita_12m']
                # Buscar totais do CNPJ
                dados_cnpj = df_dime[df_dime['cnpj'] == cnpj]
                total_creditos = dados_cnpj['total_creditos'].sum() if 'total_creditos' in dados_cnpj.columns else 0
                total_debitos = dados_cnpj['total_debitos'].sum() if 'total_debitos' in dados_cnpj.columns else 0
                dados_dime.append([
                    cnpj,
                    formatar_moeda(faturamento),
                    formatar_moeda(total_creditos),
                    formatar_moeda(total_debitos)
                ])

            table_dime = Table(dados_dime, colWidths=[1.8*inch, 1.8*inch, 1.5*inch, 1.5*inch])
            table_dime.setStyle(TableStyle([
                ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#2196F3')),
                ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
                ('ALIGN', (0, 0), (-1, -1), 'LEFT'),
                ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                ('FONTSIZE', (0, 0), (-1, -1), 8),
                ('GRID', (0, 0), (-1, -1), 1, colors.black)
            ]))
            story.append(table_dime)
            story.append(Spacer(1, 0.2*inch))

        # 5.3 Resumo Consolidado
        story.append(Paragraph("<b>5.3 Resumo Consolidado do Grupo</b>", styles['Heading3']))

        # Calcular totais
        receita_total_pgdas = resultados['pgdas'].groupby('cnpj')['receita_12m'].max().sum() if tem_pgdas else 0
        receita_total_dime = resultados['dime'].groupby('cnpj')['receita_12m'].max().sum() if tem_dime else 0
        receita_total_grupo = receita_total_pgdas + receita_total_dime

        dados_resumo = [
            ['Fonte', 'Qtd CNPJs', 'Faturamento Total'],
            ['PGDAS (Simples)', str(len(resultados['pgdas']['cnpj'].unique())) if tem_pgdas else '0', formatar_moeda(receita_total_pgdas)],
            ['DIME (Normal)', str(len(resultados['dime']['cnpj'].unique())) if tem_dime else '0', formatar_moeda(receita_total_dime)],
            ['TOTAL GRUPO', '-', formatar_moeda(receita_total_grupo)]
        ]

        table_resumo = Table(dados_resumo, colWidths=[2.5*inch, 1.5*inch, 2.5*inch])
        table_resumo.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
            ('BACKGROUND', (0, 3), (-1, 3), colors.HexColor('#FFE0E0')),
            ('ALIGN', (0, 0), (-1, -1), 'LEFT'),
            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
            ('FONTNAME', (0, 3), (-1, 3), 'Helvetica-Bold'),
            ('GRID', (0, 0), (-1, -1), 1, colors.black)
        ]))
        story.append(table_resumo)

        # Alerta se ultrapassar limite
        if receita_total_grupo > 4800000:
            excesso = receita_total_grupo - 4800000
            story.append(Spacer(1, 0.1*inch))
            alerta_style = ParagraphStyle('Alerta', parent=styles['Normal'], textColor=colors.red, fontSize=10)
            story.append(Paragraph(
                f"<b>ALERTA: Faturamento total do grupo ({formatar_moeda(receita_total_grupo)}) excede o limite do Simples Nacional em {formatar_moeda(excesso)}</b>",
                alerta_style
            ))

        story.append(PageBreak())
    
    # SE√á√ÉO 6: IND√çCIOS FISCAIS
    if not resultados.get('indicios', pd.DataFrame()).empty:
        story.append(Paragraph(f"<b>6. IND√çCIOS FISCAIS ({len(resultados['indicios'])} ind√≠cios)</b>", styles['Heading2']))
        
        resumo_indicios = resultados['indicios']['tx_descricao_indicio'].value_counts().reset_index()
        resumo_indicios.columns = ['Tipo', 'Quantidade']
        
        dados_indicios_resumo = [['Tipo de Ind√≠cio', 'Quantidade']]
        for _, row in resumo_indicios.iterrows():
            dados_indicios_resumo.append([
                str(row['Tipo'])[:50],
                str(row['Quantidade'])
            ])
        
        table = Table(dados_indicios_resumo, colWidths=[4.5*inch, 1.5*inch])
        table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
            ('ALIGN', (0, 0), (-1, -1), 'LEFT'),
            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
            ('FONTSIZE', (0, 0), (-1, -1), 8),
            ('GRID', (0, 0), (-1, -1), 1, colors.black)
        ]))
        story.append(table)
        story.append(PageBreak())
    
    # Rodap√©
    story.append(Spacer(1, 0.5*inch))
    story.append(Paragraph(
        "Sistema GEI v3.0 - Receita Estadual de Santa Catarina",
        ParagraphStyle('Footer', parent=styles['Normal'], fontSize=10, alignment=TA_CENTER)
    ))
    story.append(Paragraph(
        "Documento de car√°ter sigiloso - Uso restrito √† fiscaliza√ß√£o tribut√°ria",
        ParagraphStyle('Footer2', parent=styles['Normal'], fontSize=9, alignment=TA_CENTER, textColor=colors.grey)
    ))
    
    doc.build(story)
    buffer.seek(0)
    return buffer
    
def gerar_pdf_dossie(dossie, num_grupo):
    """Gera PDF completo com todas as informa√ß√µes do grupo"""
    buffer = BytesIO()
    doc = SimpleDocTemplate(buffer, pagesize=A4, topMargin=0.5*inch, bottomMargin=0.5*inch)
    styles = getSampleStyleSheet()
    story = []
    
    # Fun√ß√£o auxiliar para valores seguros
    def safe_value(value, default='N/A'):
        """Retorna valor seguro ou default se None/NaN"""
        if value is None or (isinstance(value, float) and pd.isna(value)):
            return default
        return value
    
    def safe_int(value, default=0):
        """Retorna int seguro ou default"""
        try:
            return int(value) if pd.notna(value) else default
        except (ValueError, TypeError):
            return default
    
    def safe_float(value, decimals=2, default=0.0):
        """Retorna float formatado ou default"""
        try:
            return f"{float(value):.{decimals}f}" if pd.notna(value) else f"{default:.{decimals}f}"
        except (ValueError, TypeError):
            return f"{default:.{decimals}f}"
    
    # T√≠tulo
    title_style = ParagraphStyle(
        'CustomTitle',
        parent=styles['Heading1'],
        fontSize=20,
        textColor=colors.HexColor('#1f77b4'),
        spaceAfter=20,
        alignment=TA_CENTER
    )
    story.append(Paragraph(f"DOSSI√ä COMPLETO - GRUPO ECON√îMICO {num_grupo}", title_style))
    story.append(Paragraph("Receita Estadual de Santa Catarina", styles['Normal']))
    story.append(Paragraph(f"Data de Gera√ß√£o: {datetime.now().strftime('%d/%m/%Y %H:%M')}", styles['Normal']))
    story.append(Spacer(1, 0.3*inch))
    
    # SE√á√ÉO 1: INFORMA√á√ïES PRINCIPAIS
    if not dossie['principal'].empty:
        info = dossie['principal'].iloc[0]
        
        story.append(Paragraph("<b>1. INFORMA√á√ïES PRINCIPAIS DO GRUPO</b>", styles['Heading2']))
        
        dados_principais = [
            ['M√©trica', 'Valor'],
            ['N√∫mero do Grupo', str(num_grupo)],
            ['Score Final CCS', safe_float(info.get('score_final_ccs'), 2)],
            ['Score Final Avan√ßado', safe_float(info.get('score_final_avancado'), 2)],
            ['Quantidade de CNPJs', str(safe_int(info.get('qntd_cnpj')))],
            ['Receita M√°xima (12 meses)', formatar_moeda(safe_value(info.get('valor_max'), 0))],
            ['Total de Funcion√°rios', str(safe_int(info.get('total_funcionarios')))],
            ['N√≠vel de Risco C115', str(safe_value(info.get('nivel_risco_grupo_economico')))],
            ['N√≠vel de Risco CCS', str(safe_value(info.get('nivel_risco_ccs')))],
            ['Total de Ind√≠cios', str(safe_int(info.get('qtd_total_indicios')))],
            ['S√≥cios Compartilhados', str(safe_int(info.get('qtd_socios_compartilhados')))],
            ['√çndice de Interconex√£o', safe_float(info.get('indice_interconexao'), 3)],
            ['√çndice de Risco CCS', safe_float(info.get('indice_risco_ccs'), 4)],
            ['Score Inconsist√™ncias NFe', safe_float(info.get('total'), 2)]
        ]
        
        table = Table(dados_principais, colWidths=[3*inch, 3*inch])
        table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
            ('ALIGN', (0, 0), (-1, -1), 'LEFT'),
            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
            ('FONTSIZE', (0, 0), (-1, 0), 11),
            ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
            ('BACKGROUND', (0, 1), (-1, -1), colors.beige),
            ('GRID', (0, 0), (-1, -1), 1, colors.black)
        ]))
        story.append(table)
        story.append(Spacer(1, 0.3*inch))
    
    # SE√á√ÉO 2: CNPJs DO GRUPO
    if not dossie['cnpjs'].empty:
        story.append(Paragraph(f"<b>2. CNPJs DO GRUPO ({len(dossie['cnpjs'])} empresas)</b>", styles['Heading2']))
        
        for idx, row in dossie['cnpjs'].iterrows():
            story.append(Paragraph(f"<b>CNPJ:</b> {safe_value(row.get('cnpj'))}", styles['Normal']))
            story.append(Paragraph(f"<b>Raz√£o Social:</b> {safe_value(row.get('nm_razao_social'))}", styles['Normal']))
            
            if pd.notna(row.get('nm_fantasia')) and str(row.get('nm_fantasia')).strip():
                story.append(Paragraph(f"<b>Nome Fantasia:</b> {row.get('nm_fantasia')}", styles['Normal']))
            if pd.notna(row.get('cd_cnae')):
                story.append(Paragraph(f"<b>CNAE:</b> {row.get('cd_cnae')}", styles['Normal']))
            if pd.notna(row.get('nm_municipio')):
                story.append(Paragraph(f"<b>Munic√≠pio:</b> {row.get('nm_municipio')}", styles['Normal']))
            if pd.notna(row.get('nm_contador')) and str(row.get('nm_contador')).strip():
                story.append(Paragraph(f"<b>Contador:</b> {row.get('nm_contador')}", styles['Normal']))
            if pd.notna(row.get('dt_constituicao_empresa')):
                story.append(Paragraph(f"<b>Data Constitui√ß√£o:</b> {row.get('dt_constituicao_empresa')}", styles['Normal']))
            if pd.notna(row.get('nm_reg_apuracao')):
                story.append(Paragraph(f"<b>Regime Apura√ß√£o:</b> {row.get('nm_reg_apuracao')}", styles['Normal']))
            
            story.append(Spacer(1, 0.15*inch))
    
    story.append(PageBreak())
    
    # SE√á√ÉO 3: V√çNCULOS SOCIET√ÅRIOS
    if not dossie['socios'].empty:
        story.append(Paragraph(f"<b>3. V√çNCULOS SOCIET√ÅRIOS ({len(dossie['socios'])} registros)</b>", styles['Heading2']))
        
        socios_unicos = dossie['socios']['cpf_socio'].nunique() if 'cpf_socio' in dossie['socios'].columns else 0
        story.append(Paragraph(f"<b>Total de s√≥cios √∫nicos:</b> {socios_unicos}", styles['Normal']))
        story.append(Spacer(1, 0.2*inch))
        
        # Mapear CNPJs para raz√µes sociais
        cnpj_para_razao = {}
        if not dossie['cnpjs'].empty:
            for _, row in dossie['cnpjs'].iterrows():
                cnpj_para_razao[safe_value(row.get('cnpj'))] = safe_value(row.get('nm_razao_social'))
        
        for idx, row in dossie['socios'].head(50).iterrows():
            cpf = safe_value(row.get('cpf_socio'))
            qtd_empresas = safe_value(row.get('qtd_empresas'), 'N/A')
            
            story.append(Paragraph(f"<b>‚Ä¢ CPF:</b> {cpf}", styles['Normal']))
            story.append(Paragraph(f"  <b>Participa de {qtd_empresas} empresas do grupo</b>", styles['Normal']))
            story.append(Spacer(1, 0.1*inch))
        
        story.append(Spacer(1, 0.2*inch))
    
    # SE√á√ÉO 4: IND√çCIOS FISCAIS
    if not dossie['indicios'].empty:
        story.append(Paragraph(f"<b>4. IND√çCIOS FISCAIS DETALHADOS ({len(dossie['indicios'])} registros)</b>", styles['Heading2']))
        
        tipos = dossie['indicios']['tx_descricao_indicio'].value_counts()
        story.append(Paragraph("<b>Resumo por Tipo de Ind√≠cio:</b>", styles['Heading3']))
        for tipo, qtd in tipos.items():
            story.append(Paragraph(f"‚Ä¢ {tipo}: {qtd} ocorr√™ncias", styles['Normal']))
        
        story.append(Spacer(1, 0.2*inch))
        story.append(Paragraph("<b>Lista Completa de Ind√≠cios:</b>", styles['Heading3']))
        
        for idx, row in dossie['indicios'].head(100).iterrows():
            story.append(Paragraph(f"‚Ä¢ {safe_value(row.get('tx_descricao_indicio'))}", styles['Normal']))
            if pd.notna(row.get('cnpj')):
                story.append(Paragraph(f"  CNPJ: {row.get('cnpj')}", styles['Normal']))
            if pd.notna(row.get('tx_descricao_complemento')):
                complemento = str(row.get('tx_descricao_complemento'))[:100]
                story.append(Paragraph(f"  Complemento: {complemento}", styles['Normal']))
        
        story.append(Spacer(1, 0.2*inch))
    
    story.append(PageBreak())
    
    # SE√á√ÉO 5: DADOS FINANCEIROS
    if not dossie['principal'].empty:
        info = dossie['principal'].iloc[0]
        story.append(Paragraph("<b>5. AN√ÅLISE FINANCEIRA</b>", styles['Heading2']))
        
        valor_max = safe_value(info.get('valor_max'), 0)
        acima_limite = 'Sim' if (pd.notna(valor_max) and float(valor_max) > 4800000) else 'N√£o'
        
        dados_financeiros = [
            ['M√©trica Financeira', 'Valor'],
            ['Receita M√°xima (12m)', formatar_moeda(valor_max)],
            ['Acima Limite Simples Nacional', acima_limite],
            ['√çndice Risco Faturamento/Funcion√°rios', safe_float(info.get('indice_risco_fat_func'), 3)]
        ]
        
        table = Table(dados_financeiros, colWidths=[3*inch, 3*inch])
        table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
            ('ALIGN', (0, 0), (-1, -1), 'LEFT'),
            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
            ('GRID', (0, 0), (-1, -1), 1, colors.black)
        ]))
        story.append(table)
        story.append(Spacer(1, 0.3*inch))
    
    # SE√á√ÉO 6: FUNCION√ÅRIOS
    if not dossie['funcionarios'].empty:
        story.append(Paragraph("<b>6. DADOS DE FUNCION√ÅRIOS</b>", styles['Heading2']))
        info_func = dossie['funcionarios'].iloc[0]
        
        dados_funcionarios = [
            ['M√©trica', 'Valor'],
            ['Total de Funcion√°rios', str(safe_int(info_func.get('total_funcionarios')))],
            ['CNPJs com Funcion√°rios', str(safe_int(info_func.get('cnpjs_com_funcionarios')))]
        ]
        
        table = Table(dados_funcionarios, colWidths=[3*inch, 3*inch])
        table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
            ('ALIGN', (0, 0), (-1, -1), 'LEFT'),
            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
            ('GRID', (0, 0), (-1, -1), 1, colors.black)
        ]))
        story.append(table)
        story.append(Spacer(1, 0.2*inch))
    
    # SE√á√ÉO 7: MEIOS DE PAGAMENTO
    if not dossie['pagamentos'].empty:
        story.append(Paragraph("<b>7. MEIOS DE PAGAMENTO</b>", styles['Heading2']))
        info_pag = dossie['pagamentos'].iloc[0]
        
        dados_pagamentos = [
            ['Tipo', 'Valor'],
            ['Pagamentos das Empresas', formatar_moeda(safe_value(info_pag.get('valor_meios_pagamento_empresas'), 0))],
            ['Pagamentos dos S√≥cios', formatar_moeda(safe_value(info_pag.get('valor_meios_pagamento_socios'), 0))]
        ]
        
        table = Table(dados_pagamentos, colWidths=[3*inch, 3*inch])
        table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
            ('ALIGN', (0, 0), (-1, -1), 'LEFT'),
            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
            ('GRID', (0, 0), (-1, -1), 1, colors.black)
        ]))
        story.append(table)
        story.append(Spacer(1, 0.2*inch))
    
    # SE√á√ÉO 8: CONV√äNIO 115
    if not dossie['c115'].empty:
        story.append(Paragraph("<b>8. DADOS CONV√äNIO 115</b>", styles['Heading2']))
        info_c115 = dossie['c115'].iloc[0]
        
        dados_c115 = [
            ['M√©trica C115', 'Valor'],
            ['Ranking de Risco', str(safe_int(info_c115.get('ranking_risco')))],
            ['N√≠vel de Risco', str(safe_value(info_c115.get('nivel_risco_grupo_economico')))],
            ['√çndice de Risco', safe_float(info_c115.get('indice_risco_grupo_economico'), 4)],
            ['CNPJs Relacionados', str(safe_int(info_c115.get('qtd_cnpjs_relacionados')))],
            ['% CNPJs Relacionados', safe_float(info_c115.get('perc_cnpjs_relacionados'), 1) + '%']
        ]
        
        table = Table(dados_c115, colWidths=[3*inch, 3*inch])
        table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
            ('ALIGN', (0, 0), (-1, -1), 'LEFT'),
            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
            ('GRID', (0, 0), (-1, -1), 1, colors.black)
        ]))
        story.append(table)
        story.append(Spacer(1, 0.2*inch))
    
    story.append(PageBreak())
    
    # SE√á√ÉO 9: CCS
    if not dossie['principal'].empty:
        info = dossie['principal'].iloc[0]
        story.append(Paragraph("<b>9. PROCURA√á√ÉO BANC√ÅRIA (CCS)</b>", styles['Heading2']))
        
        dados_ccs = [
            ['M√©trica CCS', 'Valor'],
            ['√çndice de Risco CCS', safe_float(info.get('indice_risco_ccs'), 4)],
            ['N√≠vel de Risco CCS', str(safe_value(info.get('nivel_risco_ccs')))],
            ['Total Contas √önicas', str(safe_int(info.get('ccs_total_contas_unicas')))],
            ['Contas Compartilhadas', str(safe_int(info.get('ccs_qtd_contas_compartilhadas')))],
            ['% Contas Compartilhadas', safe_float(info.get('ccs_perc_contas_compartilhadas'), 2) + '%'],
            ['Max CNPJs por Conta', str(safe_int(info.get('ccs_max_cnpjs_por_conta')))],
            ['Sobreposi√ß√µes de Respons√°veis', str(safe_int(info.get('ccs_qtd_sobreposicoes_responsaveis')))],
            ['M√©dia Dias Sobreposi√ß√£o', safe_float(info.get('ccs_media_dias_sobreposicao'), 0)],
            ['Aberturas Coordenadas', str(safe_int(info.get('ccs_qtd_datas_abertura_coordenada')))],
            ['Encerramentos Coordenados', str(safe_int(info.get('ccs_qtd_datas_encerramento_coordenado')))]
        ]
        
        table = Table(dados_ccs, colWidths=[3*inch, 3*inch])
        table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
            ('ALIGN', (0, 0), (-1, -1), 'LEFT'),
            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
            ('GRID', (0, 0), (-1, -1), 1, colors.black)
        ]))
        story.append(table)
        story.append(Spacer(1, 0.2*inch))
        
        # Detalhamento de contas compartilhadas
        if not dossie['ccs_compartilhadas'].empty:
            story.append(Paragraph("<b>Contas Compartilhadas (Top 20):</b>", styles['Heading3']))
            for idx, row in dossie['ccs_compartilhadas'].head(20).iterrows():
                cpf = safe_value(row.get('nr_cpf'))
                banco = safe_value(row.get('nm_banco'))
                agencia = safe_value(row.get('cd_agencia'))
                conta = safe_value(row.get('nr_conta'))
                qtd_cnpjs = safe_int(row.get('qtd_cnpjs_usando_conta'))
                qtd_vinculos = safe_int(row.get('qtd_vinculos_ativos'))
                
                story.append(Paragraph(f"‚Ä¢ CPF: {cpf} | Banco: {banco} | Ag√™ncia: {agencia} | Conta: {conta}", styles['Normal']))
                story.append(Paragraph(f"  CNPJs usando: {qtd_cnpjs} | V√≠nculos ativos: {qtd_vinculos}", styles['Normal']))
    
    story.append(PageBreak())
    
    # SE√á√ÉO 10: INCONSIST√äNCIAS NFE
    if not dossie['inconsistencias'].empty:
        story.append(Paragraph(f"<b>10. INCONSIST√äNCIAS DE NFE ({len(dossie['inconsistencias'])} documentos)</b>", styles['Heading2']))
        
        tipos_incons = ['cliente_incons', 'email_incons', 'tel_dest_incons', 
                       'tel_emit_incons', 'codigo_produto_incons', 'fornecedor_incons',
                       'end_emit_incons', 'end_dest_incons', 'descricao_produto_incons', 
                       'ip_transmissao_incons']
        
        story.append(Paragraph("<b>Resumo por Tipo de Inconsist√™ncia:</b>", styles['Heading3']))
        
        for tipo in tipos_incons:
            if tipo in dossie['inconsistencias'].columns:
                total = len(dossie['inconsistencias'][dossie['inconsistencias'][tipo] == 'S'])
                if total > 0:
                    nome_tipo = tipo.replace('_incons', '').replace('_', ' ').title()
                    story.append(Paragraph(f"‚Ä¢ {nome_tipo}: {total} ocorr√™ncias", styles['Normal']))
    
    # Rodap√© final
    story.append(PageBreak())
    story.append(Paragraph("OBSERVA√á√ïES FINAIS", styles['Heading2']))
    story.append(Paragraph("Este dossi√™ foi gerado automaticamente pelo Sistema GEI (Grupos Econ√¥micos Interconectados) da Receita Estadual de Santa Catarina.", styles['Normal']))
    story.append(Paragraph("As informa√ß√µes contidas neste relat√≥rio s√£o de car√°ter sigiloso e destinam-se exclusivamente ao uso da fiscaliza√ß√£o tribut√°ria.", styles['Normal']))
    story.append(Spacer(1, 0.5*inch))
    story.append(Paragraph("Sistema GEI v3.0 - Receita Estadual de Santa Catarina", 
                          ParagraphStyle('Footer', parent=styles['Normal'], fontSize=10, alignment=TA_CENTER)))
    
    doc.build(story)
    buffer.seek(0)
    return buffer

def criar_filtros_sidebar():
    """Cria filtros na sidebar"""
    filtros = {}
    
    with st.sidebar.expander("‚öôÔ∏è Filtros", expanded=False):
        filtros['score_min'] = st.slider("Score M√≠nimo", 0.0, 50.0, 0.0, 0.5)
        filtros['score_max'] = st.slider("Score M√°ximo", 0.0, 50.0, 50.0, 0.5)
        filtros['cnpj_min'] = st.number_input("Min. CNPJs", min_value=1, value=1)
        filtros['cnpj_max'] = st.number_input("Max. CNPJs", min_value=1, value=100)
        filtros['com_indicios'] = st.checkbox("Apenas com ind√≠cios")
        filtros['tema'] = st.selectbox("Tema", ["plotly", "plotly_white", "plotly_dark"])
    
    return filtros

# =============================================================================
# FUN√á√ïES DAS P√ÅGINAS PRINCIPAIS
# =============================================================================

def analise_pontual(engine, dados, filtros):
    """An√°lise pontual de CNPJs espec√≠ficos"""
    st.markdown("<h1 class='main-header'>An√°lise Pontual de CNPJs</h1>", unsafe_allow_html=True)
    
    st.info("""
    Esta ferramenta permite analisar CNPJs espec√≠ficos executando todas as verifica√ß√µes do sistema GEI
    sem criar registros permanentes. Os resultados s√£o exibidos em tempo real para an√°lise imediata.
    """)
    
    # Inicializar session_state
    if 'analise_resultados' not in st.session_state:
        st.session_state.analise_resultados = None
    if 'cnpjs_validos_analise' not in st.session_state:
        st.session_state.cnpjs_validos_analise = []
    
    # Entrada de CNPJs
    st.subheader("1. Entrada de CNPJs")
    
    col1, col2 = st.columns([3, 1])
    
    with col1:
        cnpjs_input = st.text_area(
            "Digite os CNPJs (um por linha, apenas n√∫meros):",
            height=150,
            placeholder="12345678000190\n98765432000112\n..."
        )
    
    with col2:
        st.write("**Ou carregue um arquivo:**")
        uploaded_file = st.file_uploader("CSV/TXT", type=['csv', 'txt'])
    
    # Processar CNPJs
    cnpjs_lista = []
    
    if uploaded_file is not None:
        try:
            content = uploaded_file.read().decode('utf-8')
            cnpjs_lista = [linha.strip() for linha in content.split('\n') if linha.strip()]
        except Exception as e:
            st.error(f"Erro ao ler arquivo: {e}")
    elif cnpjs_input:
        cnpjs_lista = [linha.strip() for linha in cnpjs_input.split('\n') if linha.strip()]
    
    # Limpar e validar CNPJs
    cnpjs_validos = []
    cnpjs_invalidos = []
    
    for cnpj in cnpjs_lista:
        cnpj_limpo = ''.join(filter(str.isdigit, cnpj))
        if len(cnpj_limpo) == 14:
            cnpjs_validos.append(cnpj_limpo)
        elif cnpj_limpo:
            cnpjs_invalidos.append(cnpj)
    
    # Mostrar valida√ß√£o
    if cnpjs_validos or cnpjs_invalidos:
        col1, col2 = st.columns(2)
        with col1:
            st.success(f"‚úÖ {len(cnpjs_validos)} CNPJs v√°lidos")
        with col2:
            if cnpjs_invalidos:
                st.warning(f"‚ö†Ô∏è {len(cnpjs_invalidos)} CNPJs inv√°lidos")
                with st.expander("Ver CNPJs inv√°lidos"):
                    st.write(cnpjs_invalidos)
    
    if not cnpjs_validos:
        st.warning("Nenhum CNPJ v√°lido para an√°lise.")
        return
    
    # Bot√£o de an√°lise
    st.divider()
    
    if st.button("üîç Executar An√°lise Completa", type="primary", width='stretch'):
        
        st.session_state.cnpjs_validos_analise = cnpjs_validos
        cnpjs_str = "', '".join(cnpjs_validos)
        
        with st.spinner("Executando an√°lises..."):
            
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            st.session_state.analise_resultados = {}
            
            # 1. DADOS CADASTRAIS
            try:
                status_text.text("1/10 - Buscando dados cadastrais...")
                progress_bar.progress(10)
                
                query_cadastro = f"""
                SELECT 
                    nu_cnpj as cnpj,
                    nm_razao_social,
                    nm_fantasia,
                    cd_cnae,
                    nm_reg_apuracao,
                    dt_constituicao_empresa,
                    nm_munic as municipio,
                    nm_contador,
                    nm_logradouro,
                    nu_logradouro,
                    tx_complemento,
                    nm_bairro
                FROM usr_sat_ods.vw_ods_contrib
                WHERE nu_cnpj IN ('{cnpjs_str}')
                """
                st.session_state.analise_resultados['cadastro'] = pd.read_sql(query_cadastro, engine)
            except Exception as e:
                st.warning(f"Erro ao buscar cadastro: {e}")
                st.session_state.analise_resultados['cadastro'] = pd.DataFrame()
            
            # 2. V√çNCULOS SOCIET√ÅRIOS
            try:
                status_text.text("2/10 - Analisando v√≠nculos societ√°rios...")
                progress_bar.progress(20)
                
                query_socios = f"""
                SELECT 
                    nu_cnpj_princ as cnpj,
                    nu_cnpj_cpf_secund as cpf_socio,
                    nm_relacao,
                    nm_qualificacao,
                    dt_inicio_relacao,
                    dt_fim_relacao,
                    pe_capital_empresa,
                    sn_relacao_ativa
                FROM usr_sat_ods.vw_cad_vinculo
                WHERE nu_cnpj_princ IN ('{cnpjs_str}')
                AND nm_relacao != 'CONTABILISTA'
                """
                df_socios = pd.read_sql(query_socios, engine)
                
                if not df_socios.empty:
                    socios_compartilhados = df_socios.groupby('cpf_socio')['cnpj'].nunique()
                    socios_compartilhados = socios_compartilhados[socios_compartilhados > 1]
                    
                    st.session_state.analise_resultados['socios'] = df_socios
                    st.session_state.analise_resultados['socios_compartilhados'] = socios_compartilhados
                else:
                    st.session_state.analise_resultados['socios'] = pd.DataFrame()
                    st.session_state.analise_resultados['socios_compartilhados'] = pd.Series()
                    
            except Exception as e:
                st.warning(f"Erro ao buscar s√≥cios: {e}")
                st.session_state.analise_resultados['socios'] = pd.DataFrame()
                st.session_state.analise_resultados['socios_compartilhados'] = pd.Series()
            
            # 3. PGDAS
            try:
                status_text.text("3/10 - Verificando receitas declaradas (PGDAS)...")
                progress_bar.progress(30)
                
                query_pgdas = f"""
                WITH base AS (
                    SELECT
                        nu_cnpj,
                        nu_per_ref,
                        SUM(vl_rec_bruta_estab) OVER (
                            PARTITION BY nu_cnpj
                            ORDER BY nu_per_ref
                            ROWS BETWEEN 11 PRECEDING AND CURRENT ROW
                        ) AS vl_rec_bruta_12m
                    FROM usr_sat_ods.sna_pgdasd_estabelecimento_raw
                    WHERE nu_cnpj IN ('{cnpjs_str}')
                    AND nu_per_ref BETWEEN 202001 AND 202509
                )
                SELECT 
                    nu_cnpj as cnpj,
                    nu_per_ref as periodo,
                    vl_rec_bruta_12m as receita_12m
                FROM base
                WHERE vl_rec_bruta_12m IS NOT NULL
                ORDER BY nu_cnpj, nu_per_ref DESC
                """
                st.session_state.analise_resultados['pgdas'] = pd.read_sql(query_pgdas, engine)
            except Exception as e:
                st.warning(f"Erro ao buscar PGDAS: {e}")
                st.session_state.analise_resultados['pgdas'] = pd.DataFrame()

            # 3.5. DIME (Regime Normal)
            try:
                status_text.text("3.5/10 - Verificando receitas declaradas (DIME - Regime Normal)...")
                progress_bar.progress(35)

                query_dime = f"""
                WITH base AS (
                    SELECT
                        REGEXP_REPLACE(TRIM(CAST(NU_CNPJ AS STRING)), '[^0-9]', '') AS nu_cnpj,
                        nu_per_ref,
                        COALESCE(VL_FATURAMENTO, 0) AS vl_faturamento,
                        COALESCE(VL_RECEITA_BRUTA, 0) AS vl_receita_bruta,
                        COALESCE(VL_TOT_CRED, 0) AS vl_tot_cred,
                        COALESCE(VL_TOT_DEB, 0) AS vl_tot_deb,
                        COALESCE(VL_DEB_RECOLHER, 0) AS vl_deb_recolher,
                        sn_com_movimento
                    FROM usr_sat_ods.ods_decl_dime_raw
                    WHERE REGEXP_REPLACE(TRIM(CAST(NU_CNPJ AS STRING)), '[^0-9]', '') IN ('{cnpjs_str}')
                    AND sn_cancelada = 0
                    AND nu_per_ref BETWEEN 202001 AND 202509
                ),
                receitas_12m AS (
                    SELECT
                        nu_cnpj,
                        nu_per_ref,
                        vl_faturamento,
                        vl_receita_bruta,
                        vl_tot_cred,
                        vl_tot_deb,
                        vl_deb_recolher,
                        sn_com_movimento,
                        SUM(vl_faturamento) OVER (
                            PARTITION BY nu_cnpj
                            ORDER BY nu_per_ref
                            ROWS BETWEEN 11 PRECEDING AND CURRENT ROW
                        ) AS vl_faturamento_12m
                    FROM base
                )
                SELECT
                    nu_cnpj AS cnpj,
                    nu_per_ref AS periodo,
                    vl_faturamento AS faturamento_mensal,
                    vl_receita_bruta AS receita_bruta_mensal,
                    vl_faturamento_12m AS receita_12m,
                    vl_tot_cred AS total_creditos,
                    vl_tot_deb AS total_debitos,
                    vl_deb_recolher AS debito_recolher,
                    sn_com_movimento AS com_movimento,
                    CASE
                        WHEN vl_faturamento = 0 THEN 'SEM MOVIMENTO'
                        WHEN vl_tot_cred = 0 AND vl_tot_deb = 0 THEN 'ZERADA'
                        ELSE 'NORMAL'
                    END AS situacao_declaracao
                FROM receitas_12m
                WHERE vl_faturamento_12m IS NOT NULL
                ORDER BY nu_cnpj, nu_per_ref DESC
                """
                st.session_state.analise_resultados['dime'] = pd.read_sql(query_dime, engine)
            except Exception as e:
                st.warning(f"Erro ao buscar DIME: {e}")
                st.session_state.analise_resultados['dime'] = pd.DataFrame()

            # 3.6. Consolidar Faturamento (PGDAS + DIME)
            try:
                df_pgdas = st.session_state.analise_resultados.get('pgdas', pd.DataFrame())
                df_dime = st.session_state.analise_resultados.get('dime', pd.DataFrame())
                df_cadastro = st.session_state.analise_resultados.get('cadastro', pd.DataFrame())

                # Identificar regime de cada CNPJ pelo cadastro
                regimes_por_cnpj = {}
                if not df_cadastro.empty and 'nm_reg_apuracao' in df_cadastro.columns:
                    for _, row in df_cadastro.iterrows():
                        cnpj = str(row.get('cnpj', '')).replace('.', '').replace('/', '').replace('-', '')
                        regime = str(row.get('nm_reg_apuracao', '')).upper()
                        # Simples Nacional usa PGDAS, Regime Normal usa DIME
                        if 'SIMPLES' in regime or 'SN' in regime:
                            regimes_por_cnpj[cnpj] = 'PGDAS'
                        else:
                            regimes_por_cnpj[cnpj] = 'DIME'

                # Consolidar faturamento
                faturamento_consolidado = []

                # Adicionar dados do PGDAS (para empresas do Simples)
                if not df_pgdas.empty:
                    for _, row in df_pgdas.iterrows():
                        cnpj = str(row['cnpj']).replace('.', '').replace('/', '').replace('-', '')
                        faturamento_consolidado.append({
                            'cnpj': cnpj,
                            'periodo': row['periodo'],
                            'receita_12m': row['receita_12m'],
                            'fonte': 'PGDAS',
                            'regime': 'Simples Nacional'
                        })

                # Adicionar dados da DIME (para empresas do Regime Normal)
                if not df_dime.empty:
                    for _, row in df_dime.iterrows():
                        cnpj = str(row['cnpj']).replace('.', '').replace('/', '').replace('-', '')
                        faturamento_consolidado.append({
                            'cnpj': cnpj,
                            'periodo': row['periodo'],
                            'receita_12m': row['receita_12m'],
                            'faturamento_mensal': row.get('faturamento_mensal', 0),
                            'receita_bruta_mensal': row.get('receita_bruta_mensal', 0),
                            'total_creditos': row.get('total_creditos', 0),
                            'total_debitos': row.get('total_debitos', 0),
                            'fonte': 'DIME',
                            'regime': 'Regime Normal'
                        })

                if faturamento_consolidado:
                    st.session_state.analise_resultados['faturamento'] = pd.DataFrame(faturamento_consolidado)
                else:
                    st.session_state.analise_resultados['faturamento'] = pd.DataFrame()

            except Exception as e:
                st.warning(f"Erro ao consolidar faturamento: {e}")
                st.session_state.analise_resultados['faturamento'] = pd.DataFrame()

            # 4. NFE
            try:
                status_text.text("4/10 - Analisando notas fiscais (NFe/NFCe)...")
                progress_bar.progress(40)
                
                query_nfe = f"""
                SELECT
                    a.chave AS nfe_nu_chave_acesso,
                    a.dhemi_orig AS nfe_dt_emissao,
                    a.procnfe.nfe.infnfe.emit.cnpj AS nfe_cnpj_cpf_emit,
                    a.procnfe.nfe.infnfe.dest.cnpj AS nfe_cnpj_cpf_dest,
                    a.procnfe.nfe.infnfe.dest.email AS nfe_dest_email,
                    a.procnfe.nfe.infnfe.emit.enderemit.fone AS nfe_emit_telefone,
                    a.ip_transmissor AS nfe_ip_transmissao,
                    b.prod.cprod AS nfe_cd_produto,
                    b.prod.xprod AS nfe_de_produto,
                    CONCAT(
                        COALESCE(a.procnfe.nfe.infnfe.emit.enderemit.xlgr, ''), ' ',
                        COALESCE(a.procnfe.nfe.infnfe.emit.enderemit.nro, ''), ' ',
                        COALESCE(a.procnfe.nfe.infnfe.emit.enderemit.xcpl, ''), ' ',
                        COALESCE(a.procnfe.nfe.infnfe.emit.enderemit.xbairro, ''), ' ',
                        COALESCE(a.procnfe.nfe.infnfe.emit.enderemit.xmun, '')
                    ) AS nfe_emit_end_completo,
                    CONCAT(
                        COALESCE(a.procnfe.nfe.infnfe.dest.enderdest.xlgr, ''), ' ',
                        COALESCE(a.procnfe.nfe.infnfe.dest.enderdest.nro, ''), ' ',
                        COALESCE(a.procnfe.nfe.infnfe.dest.enderdest.xcpl, ''), ' ',
                        COALESCE(a.procnfe.nfe.infnfe.dest.enderdest.xbairro, ''), ' ',
                        COALESCE(a.procnfe.nfe.infnfe.dest.enderdest.xmun, '')
                    ) AS nfe_dest_end_completo
                FROM nfe.nfe a, a.procnfe.nfe.infnfe.det b
                WHERE (a.procnfe.nfe.infnfe.emit.cnpj IN ('{cnpjs_str}')
                   OR a.procnfe.nfe.infnfe.dest.cnpj IN ('{cnpjs_str}'))
                AND a.situacao = 1
                AND CAST((a.ano_emissao * 100 + a.mes_emissao) AS STRING) LIKE '2025%'
                LIMIT 10000
                """
                st.session_state.analise_resultados['nfe'] = pd.read_sql(query_nfe, engine)
            except Exception as e:
                st.warning(f"Erro ao buscar NFe: {e}")
                st.session_state.analise_resultados['nfe'] = pd.DataFrame()
                
            # 5. C115
            try:
                status_text.text("5/10 - Verificando dados C115...")
                progress_bar.progress(50)
                
                query_c115 = f"""
                SELECT 
                    nu_cnpj_cpf_tomador as cnpj_tomador,
                    nu_identificador_tomador,
                    nu_tel_contato,
                    nu_tel_ou_unidade_consumidora,
                    COUNT(*) as qtd_registros,
                    COUNT(DISTINCT dt_emissao) as qtd_datas_distintas
                FROM c115.c115_dados_cadastrais_dest
                WHERE nu_cnpj_cpf_tomador IN ('{cnpjs_str}')
                GROUP BY 
                    nu_cnpj_cpf_tomador,
                    nu_identificador_tomador,
                    nu_tel_contato,
                    nu_tel_ou_unidade_consumidora
                """
                st.session_state.analise_resultados['c115'] = pd.read_sql(query_c115, engine)
            except Exception as e:
                st.warning(f"Erro ao buscar C115: {e}")
                st.session_state.analise_resultados['c115'] = pd.DataFrame()
            
            # 6. CCS
            try:
                status_text.text("6/10 - Verificando contas banc√°rias (CCS)...")
                progress_bar.progress(60)
                
                query_ccs = f"""
                SELECT 
                    nr_cnpj as cnpj,
                    nr_cpf,
                    nm_responsavel,
                    nm_banco,
                    cd_agencia,
                    nr_conta,
                    tp_conta,
                    dt_abertura,
                    dt_encerramento,
                    tp_responsavel,
                    dt_inicio_responsavel,
                    dt_final_responsavel
                FROM usr_sat_fsn.fsn_conta_bancaria
                WHERE nr_cnpj IN ('{cnpjs_str}')
                AND (valido IS NULL OR valido = 1)
                """
                st.session_state.analise_resultados['ccs'] = pd.read_sql(query_ccs, engine)
            except Exception as e:
                st.warning(f"Erro ao buscar CCS: {e}")
                st.session_state.analise_resultados['ccs'] = pd.DataFrame()
            
            # 7. FUNCION√ÅRIOS
            try:
                status_text.text("7/10 - Verificando funcion√°rios (RAIS/CAGED)...")
                progress_bar.progress(70)
                
                query_funcionarios = f"""
                SELECT 
                    cnpj_cei as cnpj,
                    COUNT(DISTINCT cpf) as total_funcionarios,
                    AVG(vl_remun_media_nom) as remuneracao_media
                FROM rais_caged.vw_rais_vinculos
                WHERE cnpj_cei IN ('{cnpjs_str}')
                AND motivo_desligamento = 'NAO DESLIGADO NO ANO'
                GROUP BY cnpj_cei
                """
                st.session_state.analise_resultados['funcionarios'] = pd.read_sql(query_funcionarios, engine)
            except Exception as e:
                st.warning(f"Erro ao buscar funcion√°rios: {e}")
                st.session_state.analise_resultados['funcionarios'] = pd.DataFrame()
            
            # 8. PAGAMENTOS
            try:
                status_text.text("8/10 - Verificando meios de pagamento...")
                progress_bar.progress(80)
                
                # Primeiro, buscar CPFs dos s√≥cios ativos
                query_socios_cpf = f"""
                SELECT DISTINCT
                    nu_cnpj_princ as cnpj,
                    TRIM(nu_cnpj_cpf_secund) AS cpf_socio
                FROM usr_sat_ods.vw_cad_vinculo
                WHERE nu_cnpj_princ IN ('{cnpjs_str}')
                AND sn_relacao_ativa = 1
                AND nm_relacao != 'CONTABILISTA'
                AND LENGTH(TRIM(nu_cnpj_cpf_secund)) = 11
                """
                df_socios_cpf = pd.read_sql(query_socios_cpf, engine)
                
                # Pagamentos das empresas (CNPJ)
                query_pagamentos_cnpj = f"""
                SELECT 
                    ato_nu_cnpjmf as identificador,
                    'CNPJ' as tipo_identificador,
                    ato_dt_referencia as periodo,
                    SUM(ato_vl_credito + ato_vl_debito + ato_vl_pix) as valor_total
                FROM usr_sat_admcc.acc_r66_totalestab
                WHERE ato_nu_cnpjmf IN ('{cnpjs_str}')
                AND ato_dt_referencia BETWEEN 202501 AND 202509
                AND LENGTH(TRIM(ato_nu_cnpjmf)) = 14
                GROUP BY ato_nu_cnpjmf, ato_dt_referencia
                ORDER BY ato_nu_cnpjmf, ato_dt_referencia
                """
                df_pag_cnpj = pd.read_sql(query_pagamentos_cnpj, engine)
                
                # Pagamentos dos s√≥cios (CPF)
                df_pag_cpf = pd.DataFrame()
                if not df_socios_cpf.empty:
                    cpfs_socios = "', '".join(df_socios_cpf['cpf_socio'].unique())
                    query_pagamentos_cpf = f"""
                    SELECT 
                        ato_nu_cnpjmf as identificador,
                        'CPF' as tipo_identificador,
                        ato_dt_referencia as periodo,
                        SUM(ato_vl_credito + ato_vl_debito + ato_vl_pix) as valor_total
                    FROM usr_sat_admcc.acc_r66_totalestab
                    WHERE ato_nu_cnpjmf IN ('{cpfs_socios}')
                    AND ato_dt_referencia BETWEEN 202501 AND 202509
                    AND LENGTH(TRIM(ato_nu_cnpjmf)) = 11
                    GROUP BY ato_nu_cnpjmf, ato_dt_referencia
                    ORDER BY ato_nu_cnpjmf, ato_dt_referencia
                    """
                    df_pag_cpf = pd.read_sql(query_pagamentos_cpf, engine)
                
                # Combinar ambos
                st.session_state.analise_resultados['pagamentos'] = pd.concat([df_pag_cnpj, df_pag_cpf], ignore_index=True)
                st.session_state.analise_resultados['socios_cpf'] = df_socios_cpf
                
            except Exception as e:
                st.warning(f"Erro ao buscar pagamentos: {e}")
                st.session_state.analise_resultados['pagamentos'] = pd.DataFrame()
                st.session_state.analise_resultados['socios_cpf'] = pd.DataFrame()
            
            # 9. IND√çCIOS
            try:
                status_text.text("9/10 - Verificando ind√≠cios fiscais...")
                progress_bar.progress(90)
                
                query_indicios = f"""
                SELECT
                    t.nu_cpf_cnpj as cnpj,
                    t.tx_descricao_indicio,
                    p.tx_descricao_complemento
                FROM neaf.empresa_indicio t, t.indicio_complemento p
                WHERE t.nu_cpf_cnpj IN ('{cnpjs_str}')
                AND t.cd_atual = 1
                """
                st.session_state.analise_resultados['indicios'] = pd.read_sql(query_indicios, engine)
            except Exception as e:
                st.warning(f"Erro ao buscar ind√≠cios: {e}")
                st.session_state.analise_resultados['indicios'] = pd.DataFrame()
            
            # 10. GRUPOS EXISTENTES
            try:
                status_text.text("10/10 - Verificando grupos existentes...")
                progress_bar.progress(100)
                
                query_grupos = f"""
                SELECT 
                    cnpj,
                    num_grupo
                FROM gessimples.gei_cnpj
                WHERE cnpj IN ('{cnpjs_str}')
                """
                st.session_state.analise_resultados['grupos_existentes'] = pd.read_sql(query_grupos, engine)
            except Exception as e:
                st.session_state.analise_resultados['grupos_existentes'] = pd.DataFrame()
            
            progress_bar.empty()
            status_text.empty()
    
    # EXIBI√á√ÉO DOS RESULTADOS (fora do bot√£o)
    if st.session_state.analise_resultados is not None:
        
        resultados = st.session_state.analise_resultados
        cnpjs_validos = st.session_state.cnpjs_validos_analise
        
        st.success("‚úÖ An√°lise conclu√≠da!")
        st.divider()
        
        # RESUMO EXECUTIVO
        st.header("üìä Resumo Executivo")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("CNPJs Analisados", len(cnpjs_validos))
        
        with col2:
            cadastrados = len(resultados['cadastro'])
            st.metric("Com Cadastro", cadastrados)
        
        with col3:
            com_indicios = len(resultados['indicios']) if not resultados['indicios'].empty else 0
            st.metric("Com Ind√≠cios", com_indicios)
        
        with col4:
            em_grupos = len(resultados['grupos_existentes']) if not resultados['grupos_existentes'].empty else 0
            st.metric("J√° em Grupos GEI", em_grupos)
        
        # TABS PARA RESULTADOS DETALHADOS
        tabs = st.tabs([
            "Cadastro",
            "S√≥cios",
            "Faturamento (PGDAS/DIME)",
            "Notas Fiscais",
            "C115",
            "Contas (CCS)",
            "Funcion√°rios",
            "Pagamentos",
            "Ind√≠cios",
            "Grupos Existentes"
        ])
        
        # TAB 1: CADASTRO
        with tabs[0]:
            if not resultados['cadastro'].empty:
                st.subheader(f"Dados Cadastrais ({len(resultados['cadastro'])} registros)")
                st.dataframe(resultados['cadastro'], width='stretch', hide_index=True)
            else:
                st.info("Nenhum dado cadastral encontrado.")
        
        # TAB 2: S√ìCIOS
        with tabs[1]:
            if not resultados['socios'].empty:
                st.subheader(f"V√≠nculos Societ√°rios ({len(resultados['socios'])} v√≠nculos)")
                
                if len(resultados['socios_compartilhados']) > 0:
                    st.warning(f"‚ö†Ô∏è {len(resultados['socios_compartilhados'])} s√≥cios compartilhados encontrados!")
                    
                    st.write("**S√≥cios Compartilhados:**")
                    df_comp = pd.DataFrame({
                        'CPF': resultados['socios_compartilhados'].index,
                        'Qtd_CNPJs': resultados['socios_compartilhados'].values
                    })
                    st.dataframe(df_comp, width='stretch', hide_index=True)
                
                st.write("**Todos os V√≠nculos:**")
                st.dataframe(resultados['socios'], width='stretch', hide_index=True)
            else:
                st.info("Nenhum v√≠nculo societ√°rio encontrado.")
        
        # TAB 3: FATURAMENTO (PGDAS + DIME)
        with tabs[2]:
            # Verificar se h√° dados em qualquer uma das fontes
            tem_pgdas = not resultados['pgdas'].empty
            tem_dime = not resultados.get('dime', pd.DataFrame()).empty
            tem_faturamento = not resultados.get('faturamento', pd.DataFrame()).empty

            if tem_pgdas or tem_dime or tem_faturamento:
                st.subheader("Faturamento Declarado (PGDAS / DIME)")

                # M√©tricas resumidas
                col_m1, col_m2, col_m3 = st.columns(3)
                with col_m1:
                    qtd_pgdas = len(resultados['pgdas']['cnpj'].unique()) if tem_pgdas else 0
                    st.metric("Empresas PGDAS (Simples)", qtd_pgdas)
                with col_m2:
                    qtd_dime = len(resultados.get('dime', pd.DataFrame())['cnpj'].unique()) if tem_dime else 0
                    st.metric("Empresas DIME (Normal)", qtd_dime)
                with col_m3:
                    st.metric("Total de Fontes", (1 if tem_pgdas else 0) + (1 if tem_dime else 0))

                # Sub-tabs para separar PGDAS, DIME e Consolidado
                sub_tabs = st.tabs(["Consolidado", "PGDAS (Simples Nacional)", "DIME (Regime Normal)"])

                # SUB-TAB: CONSOLIDADO
                with sub_tabs[0]:
                    if tem_faturamento:
                        df_fat = resultados['faturamento']
                        st.write("**Vis√£o Consolidada - Receita por CNPJ e Fonte:**")

                        # Receita m√°xima por CNPJ consolidada
                        receita_consolidada = df_fat.groupby(['cnpj', 'fonte', 'regime'])['receita_12m'].max().reset_index()
                        receita_consolidada.columns = ['CNPJ', 'Fonte', 'Regime', 'Receita_Maxima_12m']
                        receita_consolidada['Acima_Limite_SN'] = receita_consolidada['Receita_Maxima_12m'] > 4800000
                        receita_consolidada['Receita_Maxima_12m_Fmt'] = receita_consolidada['Receita_Maxima_12m'].apply(formatar_moeda)

                        st.dataframe(receita_consolidada[['CNPJ', 'Fonte', 'Regime', 'Receita_Maxima_12m_Fmt', 'Acima_Limite_SN']],
                                   width='stretch', hide_index=True)

                        # Receita total do grupo (somando todas as empresas)
                        receita_total_grupo = receita_consolidada['Receita_Maxima_12m'].sum()
                        st.info(f"**Receita Total do Grupo (soma de todas as empresas):** {formatar_moeda(receita_total_grupo)}")

                        if receita_total_grupo > 4800000:
                            excesso = receita_total_grupo - 4800000
                            st.error(f"‚ö†Ô∏è **ALERTA:** Receita total do grupo ({formatar_moeda(receita_total_grupo)}) excede o limite do Simples Nacional em {formatar_moeda(excesso)}")

                        # Gr√°fico de evolu√ß√£o consolidada
                        fig_consolidado = px.line(
                            df_fat,
                            x='periodo',
                            y='receita_12m',
                            color='cnpj',
                            line_dash='fonte',
                            title="Evolu√ß√£o da Receita (12 meses) - Todas as Fontes",
                            labels={'receita_12m': 'Receita (R$)', 'periodo': 'Per√≠odo', 'fonte': 'Fonte'},
                            template=filtros['tema']
                        )
                        fig_consolidado.add_hline(y=4800000, line_dash="dash", line_color="red",
                                                annotation_text="Limite SN (R$ 4,8M)")
                        st.plotly_chart(fig_consolidado, use_container_width=True)
                    else:
                        st.info("Dados consolidados n√£o dispon√≠veis.")

                # SUB-TAB: PGDAS
                with sub_tabs[1]:
                    if tem_pgdas:
                        st.write("**Receitas Declaradas via PGDAS (Simples Nacional):**")

                        receita_max_pgdas = resultados['pgdas'].groupby('cnpj')['receita_12m'].max().reset_index()
                        receita_max_pgdas.columns = ['CNPJ', 'Receita_Maxima_12m']
                        receita_max_pgdas['Acima_Limite_SN'] = receita_max_pgdas['Receita_Maxima_12m'] > 4800000
                        receita_max_pgdas['Receita_Maxima_12m'] = receita_max_pgdas['Receita_Maxima_12m'].apply(formatar_moeda)

                        st.dataframe(receita_max_pgdas, width='stretch', hide_index=True)

                        fig_pgdas = px.line(resultados['pgdas'], x='periodo', y='receita_12m', color='cnpj',
                                          title="Evolu√ß√£o da Receita PGDAS (12 meses)",
                                          template=filtros['tema'])
                        fig_pgdas.add_hline(y=4800000, line_dash="dash", line_color="red",
                                          annotation_text="Limite SN")
                        st.plotly_chart(fig_pgdas, use_container_width=True)

                        st.write("**Dados Completos PGDAS:**")
                        st.dataframe(resultados['pgdas'], width='stretch', hide_index=True)
                    else:
                        st.info("Nenhuma declara√ß√£o PGDAS encontrada para os CNPJs informados.")

                # SUB-TAB: DIME
                with sub_tabs[2]:
                    if tem_dime:
                        df_dime = resultados['dime']
                        st.write("**Receitas Declaradas via DIME (Regime Normal):**")

                        receita_max_dime = df_dime.groupby('cnpj')['receita_12m'].max().reset_index()
                        receita_max_dime.columns = ['CNPJ', 'Faturamento_Maximo_12m']
                        receita_max_dime['Faturamento_Maximo_12m_Fmt'] = receita_max_dime['Faturamento_Maximo_12m'].apply(formatar_moeda)

                        st.dataframe(receita_max_dime[['CNPJ', 'Faturamento_Maximo_12m_Fmt']], width='stretch', hide_index=True)

                        # M√©tricas adicionais da DIME
                        col_d1, col_d2, col_d3 = st.columns(3)
                        with col_d1:
                            total_creditos = df_dime['total_creditos'].sum() if 'total_creditos' in df_dime.columns else 0
                            st.metric("Total Cr√©ditos ICMS", formatar_moeda(total_creditos))
                        with col_d2:
                            total_debitos = df_dime['total_debitos'].sum() if 'total_debitos' in df_dime.columns else 0
                            st.metric("Total D√©bitos ICMS", formatar_moeda(total_debitos))
                        with col_d3:
                            debito_recolher = df_dime['debito_recolher'].sum() if 'debito_recolher' in df_dime.columns else 0
                            st.metric("D√©bito a Recolher", formatar_moeda(debito_recolher))

                        fig_dime = px.line(df_dime, x='periodo', y='receita_12m', color='cnpj',
                                          title="Evolu√ß√£o do Faturamento DIME (12 meses)",
                                          template=filtros['tema'])
                        st.plotly_chart(fig_dime, use_container_width=True)

                        # Situa√ß√£o das declara√ß√µes
                        if 'situacao_declaracao' in df_dime.columns:
                            st.write("**Situa√ß√£o das Declara√ß√µes DIME:**")
                            situacao_resumo = df_dime.groupby(['cnpj', 'situacao_declaracao']).size().reset_index(name='qtd')
                            st.dataframe(situacao_resumo, width='stretch', hide_index=True)

                        st.write("**Dados Completos DIME:**")
                        st.dataframe(df_dime, width='stretch', hide_index=True)
                    else:
                        st.info("Nenhuma declara√ß√£o DIME encontrada para os CNPJs informados.")
            else:
                st.info("Nenhuma declara√ß√£o de faturamento encontrada (PGDAS ou DIME).")
        
        # TAB 4: NFE
        with tabs[3]:
            if not resultados['nfe'].empty:
                st.subheader(f"Notas Fiscais ({len(resultados['nfe'])} registros)")
                
                col1, col2 = st.columns(2)
                with col1:
                    emitidas = resultados['nfe']['nfe_cnpj_cpf_emit'].isin(cnpjs_validos).sum()
                    st.metric("Notas Emitidas", emitidas)
                with col2:
                    recebidas = resultados['nfe']['nfe_cnpj_cpf_dest'].isin(cnpjs_validos).sum()
                    st.metric("Notas Recebidas", recebidas)
                
                st.dataframe(resultados['nfe'].head(100), width='stretch', hide_index=True)
            else:
                st.info("Nenhuma nota fiscal encontrada para 2025.")
        
        # TAB 5: C115
        with tabs[4]:
            if not resultados['c115'].empty:
                st.subheader(f"Conv√™nio 115 ({len(resultados['c115'])} registros)")
                
                identificadores = resultados['c115'].groupby('nu_identificador_tomador')['cnpj_tomador'].nunique()
                compartilhados = identificadores[identificadores > 1]
                
                if len(compartilhados) > 0:
                    st.warning(f"‚ö†Ô∏è {len(compartilhados)} identificadores compartilhados!")
                
                st.dataframe(resultados['c115'], width='stretch', hide_index=True)
            else:
                st.info("Nenhum dado C115 encontrado.")
        
        # TAB 6: CCS
        with tabs[5]:
            if not resultados['ccs'].empty:
                st.subheader(f"Contas Banc√°rias ({len(resultados['ccs'])} registros)")
                
                cpfs_contas = resultados['ccs'].groupby('nr_cpf')['cnpj'].nunique()
                cpfs_compartilhados = cpfs_contas[cpfs_contas > 1]
                
                if len(cpfs_compartilhados) > 0:
                    st.warning(f"‚ö†Ô∏è {len(cpfs_compartilhados)} CPFs com acesso a m√∫ltiplos CNPJs!")
                    
                    df_cpf = pd.DataFrame({
                        'CPF': cpfs_compartilhados.index,
                        'Qtd_CNPJs': cpfs_compartilhados.values
                    })
                    st.dataframe(df_cpf, width='stretch', hide_index=True)
                
                st.write("**Todas as Contas:**")
                st.dataframe(resultados['ccs'], width='stretch', hide_index=True)
            else:
                st.info("Nenhuma conta banc√°ria encontrada.")
        
        # TAB 7: FUNCION√ÅRIOS
        with tabs[6]:
            if not resultados['funcionarios'].empty:
                st.subheader("Funcion√°rios (RAIS/CAGED)")
                st.dataframe(resultados['funcionarios'], width='stretch', hide_index=True)
            else:
                st.info("Nenhum funcion√°rio encontrado.")
        
        # TAB 8: PAGAMENTOS
        with tabs[7]:
            if not resultados['pagamentos'].empty:
                st.subheader(f"Meios de Pagamento ({len(resultados['pagamentos'])} registros)")
                
                # Separar por tipo
                pag_cnpj = resultados['pagamentos'][resultados['pagamentos']['tipo_identificador'] == 'CNPJ']
                pag_cpf = resultados['pagamentos'][resultados['pagamentos']['tipo_identificador'] == 'CPF']
                
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("Registros de CNPJ", len(pag_cnpj))
                with col2:
                    st.metric("Registros de S√≥cios (CPF)", len(pag_cpf))
                
                # Resumo por tipo
                st.write("**Total por Tipo:**")
                resumo_tipo = resultados['pagamentos'].groupby('tipo_identificador')['valor_total'].sum().reset_index()
                resumo_tipo.columns = ['Tipo', 'Valor_Total']
                resumo_tipo['Valor_Total'] = resumo_tipo['Valor_Total'].apply(formatar_moeda)
                st.dataframe(resumo_tipo, width='stretch', hide_index=True)
                
                # Resumo por identificador (CNPJ/CPF)
                st.write("**Total por Identificador:**")
                resumo_ident = resultados['pagamentos'].groupby(['identificador', 'tipo_identificador'])['valor_total'].sum().reset_index()
                resumo_ident.columns = ['Identificador', 'Tipo', 'Valor_Total']
                resumo_ident = resumo_ident.sort_values('Valor_Total', ascending=False)
                resumo_ident['Valor_Total'] = resumo_ident['Valor_Total'].apply(formatar_moeda)
                st.dataframe(resumo_ident, width='stretch', hide_index=True)
                
                # Gr√°fico de evolu√ß√£o
                st.write("**Evolu√ß√£o Temporal:**")
                fig = px.line(resultados['pagamentos'], 
                             x='periodo', 
                             y='valor_total', 
                             color='identificador',
                             line_dash='tipo_identificador',
                             title="Evolu√ß√£o dos Meios de Pagamento (Empresas e S√≥cios)",
                             labels={'valor_total': 'Valor (R$)', 'periodo': 'Per√≠odo'},
                             template=filtros['tema'])
                st.plotly_chart(fig, use_container_width=True)
                
                # Dados completos
                with st.expander("Ver Dados Completos"):
                    st.dataframe(resultados['pagamentos'], width='stretch', hide_index=True)
                
            else:
                st.info("Nenhum dado de pagamento encontrado.")
        
        # TAB 9: IND√çCIOS
        with tabs[8]:
            if not resultados['indicios'].empty:
                st.subheader(f"Ind√≠cios Fiscais ({len(resultados['indicios'])} registros)")
                
                resumo_indicios = resultados['indicios']['tx_descricao_indicio'].value_counts().reset_index()
                resumo_indicios.columns = ['Tipo', 'Quantidade']
                
                col1, col2 = st.columns(2)
                with col1:
                    st.dataframe(resumo_indicios, width='stretch', hide_index=True)
                with col2:
                    fig = px.pie(resumo_indicios, values='Quantidade', names='Tipo',
                                title="Distribui√ß√£o de Ind√≠cios",
                                template=filtros['tema'])
                    st.plotly_chart(fig)
                
                st.write("**Lista Completa:**")
                st.dataframe(resultados['indicios'], width='stretch', hide_index=True)
            else:
                st.success("‚úÖ Nenhum ind√≠cio fiscal encontrado.")
        
        # TAB 10: GRUPOS EXISTENTES
        with tabs[9]:
            if not resultados['grupos_existentes'].empty:
                st.warning(f"‚ö†Ô∏è {len(resultados['grupos_existentes'])} CNPJs j√° est√£o cadastrados em grupos GEI!")
                
                st.dataframe(resultados['grupos_existentes'], width='stretch', hide_index=True)
                
                for grupo in resultados['grupos_existentes']['num_grupo'].unique():
                    st.info(f"Ver detalhes do Grupo {grupo} na aba 'Dossi√™ do Grupo'")
            else:
                st.success("‚úÖ Nenhum CNPJ est√° em grupos GEI existentes.")
        
        # CONCLUS√ïES E RECOMENDA√á√ïES
        st.divider()
        st.header("üéØ Conclus√µes e Recomenda√ß√µes")
        
        alertas = []
        
        if len(resultados['socios_compartilhados']) > 0:
            alertas.append(f"üî¥ **CR√çTICO**: {len(resultados['socios_compartilhados'])} s√≥cios compartilhados entre os CNPJs analisados, indicando poss√≠vel grupo econ√¥mico.")
        
        # Verificar faturamento alto (PGDAS + DIME)
        cnpjs_faturamento_alto = set()
        if not resultados['pgdas'].empty:
            cnpjs_pgdas_alto = resultados['pgdas'][resultados['pgdas']['receita_12m'] > 4800000]['cnpj'].unique()
            cnpjs_faturamento_alto.update(cnpjs_pgdas_alto)
        if not resultados.get('dime', pd.DataFrame()).empty:
            cnpjs_dime_alto = resultados['dime'][resultados['dime']['receita_12m'] > 4800000]['cnpj'].unique()
            cnpjs_faturamento_alto.update(cnpjs_dime_alto)

        if len(cnpjs_faturamento_alto) > 0:
            alertas.append(f"üü° **ATEN√á√ÉO**: {len(cnpjs_faturamento_alto)} CNPJs com faturamento acima do limite do Simples Nacional (PGDAS/DIME).")
        
        if not resultados['ccs'].empty:
            cpfs_contas = resultados['ccs'].groupby('nr_cpf')['cnpj'].nunique()
            if (cpfs_contas > 1).any():
                alertas.append(f"üü° **ATEN√á√ÉO**: Contas banc√°rias com CPFs compartilhados entre CNPJs.")
        
        if not resultados['indicios'].empty:
            alertas.append(f"üî¥ **CR√çTICO**: {len(resultados['indicios'])} ind√≠cios fiscais encontrados.")
        
        if not resultados['c115'].empty:
            identificadores = resultados['c115'].groupby('nu_identificador_tomador')['cnpj_tomador'].nunique()
            if (identificadores > 1).any():
                alertas.append(f"üü° **ATEN√á√ÉO**: Identificadores C115 compartilhados entre CNPJs.")
        
        if alertas:
            for alerta in alertas:
                st.markdown(alerta)
            
            st.markdown("---")
            st.info("üí° **Recomenda√ß√£o**: Considere criar um grupo GEI para estes CNPJs e monitor√°-los continuamente.")
        else:
            st.success("‚úÖ Nenhum alerta cr√≠tico identificado na an√°lise.")

# =====================================================================
        # AN√ÅLISE DE SIMILARIDADE - EVID√äNCIAS DE GRUPO ECON√îMICO
        # =====================================================================
        st.divider()
        st.header("üîç An√°lise de Similaridade - Evid√™ncias de Grupo Econ√¥mico")
        
        st.info("""
        Esta an√°lise verifica se os CNPJs compartilham informa√ß√µes que indicam
        forma√ß√£o de grupo econ√¥mico, conforme metodologia do Sistema GEI.
        """)
        
        evidencias = {}
        score_similaridade = 0
        max_score_possivel = 0
        
        # Criar abas para cada tipo de an√°lise
        tabs_similaridade = st.tabs([
            "üìã Cadastro",
            "üë• S√≥cios",
            "üìä Receitas",
            "üìÑ Notas Fiscais",
            "üì± Conv√™nio 115",
            "üè¶ Contas Banc√°rias",
            "üëî Funcion√°rios",
            "üí≥ Pagamentos",
            "üìä Score Final"
        ])
        
        # ===================================================================
        # TAB 1: AN√ÅLISE DE DADOS CADASTRAIS
        # ===================================================================
        with tabs_similaridade[0]:
            st.subheader("Consist√™ncia Cadastral")
            
            if not resultados['cadastro'].empty and len(resultados['cadastro']) > 1:
                cadastro_checks = []
                
                # Raz√£o Social
                max_score_possivel += 2
                razoes = resultados['cadastro']['nm_razao_social'].dropna().unique()
                if len(razoes) == 1:
                    cadastro_checks.append({
                        'Atributo': 'Raz√£o Social',
                        'Status': '‚úÖ ID√äNTICA',
                        'Quantidade': '1',
                        'Pontos': 2,
                        'Avalia√ß√£o': 'CR√çTICO - Forte ind√≠cio'
                    })
                    evidencias['razao_social'] = True
                    score_similaridade += 2
                elif len(razoes) > 1:
                    cadastro_checks.append({
                        'Atributo': 'Raz√£o Social',
                        'Status': '‚ùå DIFERENTES',
                        'Quantidade': str(len(razoes)),
                        'Pontos': 0,
                        'Avalia√ß√£o': '-'
                    })
                
                # Nome Fantasia
                max_score_possivel += 1
                fantasias = resultados['cadastro']['nm_fantasia'].dropna().unique()
                if len(fantasias) == 1 and len(fantasias[0]) > 0:
                    cadastro_checks.append({
                        'Atributo': 'Nome Fantasia',
                        'Status': '‚úÖ ID√äNTICO',
                        'Quantidade': '1',
                        'Pontos': 1,
                        'Avalia√ß√£o': 'Alto ind√≠cio'
                    })
                    evidencias['fantasia'] = True
                    score_similaridade += 1
                elif len(fantasias) > 1:
                    cadastro_checks.append({
                        'Atributo': 'Nome Fantasia',
                        'Status': '‚ùå DIFERENTES',
                        'Quantidade': str(len(fantasias)),
                        'Pontos': 0,
                        'Avalia√ß√£o': '-'
                    })
                
                # CNAE
                max_score_possivel += 1
                cnaes = resultados['cadastro']['cd_cnae'].dropna().unique()
                if len(cnaes) == 1:
                    cadastro_checks.append({
                        'Atributo': 'CNAE',
                        'Status': '‚úÖ ID√äNTICO',
                        'Quantidade': '1',
                        'Pontos': 1,
                        'Avalia√ß√£o': 'Mesmo ramo'
                    })
                    evidencias['cnae'] = True
                    score_similaridade += 1
                elif len(cnaes) > 1:
                    cadastro_checks.append({
                        'Atributo': 'CNAE',
                        'Status': '‚ùå DIFERENTES',
                        'Quantidade': str(len(cnaes)),
                        'Pontos': 0,
                        'Avalia√ß√£o': '-'
                    })
                
                # Contador
                max_score_possivel += 2
                contadores = resultados['cadastro']['nm_contador'].dropna().unique()
                if len(contadores) == 1 and len(contadores[0]) > 0:
                    cadastro_checks.append({
                        'Atributo': 'Contador',
                        'Status': '‚úÖ MESMO',
                        'Quantidade': '1',
                        'Pontos': 2,
                        'Avalia√ß√£o': 'CR√çTICO - Gest√£o comum'
                    })
                    evidencias['contador'] = True
                    score_similaridade += 2
                elif len(contadores) > 1:
                    cadastro_checks.append({
                        'Atributo': 'Contador',
                        'Status': '‚ùå DIFERENTES',
                        'Quantidade': str(len(contadores)),
                        'Pontos': 0,
                        'Avalia√ß√£o': '-'
                    })
                
                # Endere√ßo Completo
                max_score_possivel += 3
                enderecos = resultados['cadastro'].apply(
                    lambda row: f"{row.get('nm_logradouro', '')} {row.get('nu_logradouro', '')} {row.get('nm_bairro', '')} {row.get('municipio', '')}".strip(),
                    axis=1
                ).unique()
                if len(enderecos) == 1 and len(enderecos[0]) > 10:
                    cadastro_checks.append({
                        'Atributo': 'Endere√ßo',
                        'Status': '‚úÖ ID√äNTICO',
                        'Quantidade': '1',
                        'Pontos': 3,
                        'Avalia√ß√£o': 'CR√çTICO - Mesmo local'
                    })
                    evidencias['endereco'] = True
                    score_similaridade += 3
                elif len(enderecos) > 1:
                    cadastro_checks.append({
                        'Atributo': 'Endere√ßo',
                        'Status': '‚ùå DIFERENTES',
                        'Quantidade': str(len(enderecos)),
                        'Pontos': 0,
                        'Avalia√ß√£o': '-'
                    })
                
                # Munic√≠pio
                max_score_possivel += 0.5
                municipios = resultados['cadastro']['municipio'].dropna().unique()
                if len(municipios) == 1:
                    cadastro_checks.append({
                        'Atributo': 'Munic√≠pio',
                        'Status': '‚úÖ MESMO',
                        'Quantidade': '1',
                        'Pontos': 0.5,
                        'Avalia√ß√£o': 'Ind√≠cio leve'
                    })
                    score_similaridade += 0.5
                elif len(municipios) > 1:
                    cadastro_checks.append({
                        'Atributo': 'Munic√≠pio',
                        'Status': '‚ùå DIFERENTES',
                        'Quantidade': str(len(municipios)),
                        'Pontos': 0,
                        'Avalia√ß√£o': '-'
                    })
                
                # Regime de Apura√ß√£o
                max_score_possivel += 1
                regimes = resultados['cadastro']['nm_reg_apuracao'].dropna().unique()
                if len(regimes) == 1:
                    cadastro_checks.append({
                        'Atributo': 'Regime Tribut√°rio',
                        'Status': '‚úÖ MESMO',
                        'Quantidade': str(regimes[0]),
                        'Pontos': 1,
                        'Avalia√ß√£o': 'Mesmo regime'
                    })
                    score_similaridade += 1
                elif len(regimes) > 1:
                    cadastro_checks.append({
                        'Atributo': 'Regime Tribut√°rio',
                        'Status': '‚ö†Ô∏è MISTO',
                        'Quantidade': str(len(regimes)),
                        'Pontos': 0,
                        'Avalia√ß√£o': 'Poss√≠vel planejamento'
                    })
                
                df_cadastro = pd.DataFrame(cadastro_checks)
                st.dataframe(df_cadastro, width='stretch', hide_index=True)
                
                pontos_cadastro = df_cadastro['Pontos'].sum()
                if pontos_cadastro >= 5:
                    st.error(f"üî¥ CR√çTICO: {pontos_cadastro:.1f} pontos - Forte evid√™ncia de grupo econ√¥mico")
                elif pontos_cadastro >= 3:
                    st.warning(f"üü° ALTO: {pontos_cadastro:.1f} pontos - Evid√™ncia significativa")
                elif pontos_cadastro >= 1:
                    st.info(f"üü† MODERADO: {pontos_cadastro:.1f} pontos")
                else:
                    st.success(f"üü¢ BAIXO: {pontos_cadastro:.1f} pontos")
            else:
                st.warning("Dados cadastrais insuficientes para an√°lise")
        
        # ===================================================================
        # TAB 2: AN√ÅLISE DE V√çNCULOS SOCIET√ÅRIOS
        # ===================================================================
        with tabs_similaridade[1]:
            st.subheader("An√°lise de V√≠nculos Societ√°rios")
            
            if not resultados['socios'].empty and len(cnpjs_validos) > 1:
                socios_checks = []
                
                # S√≥cios compartilhados
                max_score_possivel += 5
                socios_compartilhados = resultados.get('socios_compartilhados', pd.Series())
                
                # CALCULAR PRIMEIRO O PERCENTUAL DE INTERCONEX√ÉO E PARES
                total_cnpjs = len(cnpjs_validos)
                pares_com_socios = 0
                perc_interconexao = 0
                
                if total_cnpjs > 1 and len(socios_compartilhados) > 0:
                    pares_possiveis = (total_cnpjs * (total_cnpjs - 1)) / 2
                    
                    for cpf in socios_compartilhados.index:
                        cnpjs_do_socio = resultados['socios'][resultados['socios']['cpf_socio'] == cpf]['cnpj'].unique()
                        if len(cnpjs_do_socio) > 1:
                            pares_com_socios += len(cnpjs_do_socio) * (len(cnpjs_do_socio) - 1) / 2
                    
                    if pares_possiveis > 0:
                        perc_interconexao = (pares_com_socios / pares_possiveis) * 100
                
                # AGORA SIM ADICIONAR AOS CHECKS
                if len(socios_compartilhados) > 0:
                    pontos_socios = min(len(socios_compartilhados) * 2, 5)
                    
                    socios_checks.append({
                        'Indicador': 'S√≥cios Compartilhados',
                        'Quantidade': str(len(socios_compartilhados)),
                        'Status': '‚úÖ DETECTADOS',
                        'Pontos': str(pontos_socios),
                        'Avalia√ß√£o': 'CR√çTICO - V√≠nculos cruzados'
                    })
                    
                    socios_checks.append({
                        'Indicador': '√çndice de Interconex√£o',
                        'Quantidade': str(int(pares_com_socios)),
                        'Status': f'{perc_interconexao:.1f}%',
                        'Pontos': '-',
                        'Avalia√ß√£o': 'Alto' if perc_interconexao > 50 else 'Moderado' if perc_interconexao > 20 else 'Baixo'
                    })
                    
                    evidencias['socios_compartilhados'] = True
                    score_similaridade += pontos_socios
                    
                    # Detalhar os s√≥cios compartilhados
                    st.write("**S√≥cios que participam de m√∫ltiplos CNPJs:**")
                    for cpf, qtd in socios_compartilhados.items():
                        socios_info = resultados['socios'][resultados['socios']['cpf_socio'] == cpf]
                        st.write(f"‚Ä¢ **CPF {cpf}**: Presente em {qtd} CNPJs")
                        for _, s in socios_info.iterrows():
                            st.write(f"  - {s['cnpj']}: {s.get('nm_qualificacao', 'N/A')}")
                else:
                    socios_checks.append({
                        'Indicador': 'S√≥cios Compartilhados',
                        'Quantidade': '0',
                        'Status': '‚ùå N√ÉO DETECTADO',
                        'Pontos': '0',
                        'Avalia√ß√£o': '-'
                    })
                
                df_socios = pd.DataFrame(socios_checks)
                
                # Garantir que todas as colunas sejam string
                for col in df_socios.columns:
                    df_socios[col] = df_socios[col].astype(str)
                
                st.dataframe(df_socios, hide_index=True)
                
                # Calcular pontos apenas dos que n√£o s√£o '-'
                pontos_numericos = df_socios[df_socios['Pontos'] != '-']['Pontos'].astype(float)
                pontos_socios_total = pontos_numericos.sum() if len(pontos_numericos) > 0 else 0
                
                if pontos_socios_total >= 4:
                    st.error(f"üî¥ CR√çTICO: {pontos_socios_total:.1f} pontos - Controle societ√°rio compartilhado")
                elif pontos_socios_total >= 2:
                    st.warning(f"üü° ALTO: {pontos_socios_total:.1f} pontos")
                else:
                    st.info(f"üü¢ BAIXO: {pontos_socios_total:.1f} pontos")
            else:
                st.warning("Dados de v√≠nculos societ√°rios insuficientes")
        
        # ===================================================================
        # TAB 3: AN√ÅLISE DE RECEITAS (PGDAS + DIME)
        # ===================================================================
        with tabs_similaridade[2]:
            st.subheader("An√°lise de Faturamento - PGDAS / DIME")

            # Verificar disponibilidade de dados de faturamento
            tem_pgdas = not resultados['pgdas'].empty
            tem_dime = not resultados.get('dime', pd.DataFrame()).empty
            tem_faturamento = not resultados.get('faturamento', pd.DataFrame()).empty

            # Consolidar dados para an√°lise
            if tem_faturamento:
                df_analise = resultados['faturamento'].copy()
            elif tem_pgdas or tem_dime:
                # Fallback: criar dataframe consolidado manualmente
                dados_consolidados = []
                if tem_pgdas:
                    for _, row in resultados['pgdas'].iterrows():
                        dados_consolidados.append({
                            'cnpj': str(row['cnpj']),
                            'periodo': row['periodo'],
                            'receita_12m': row['receita_12m'],
                            'fonte': 'PGDAS'
                        })
                if tem_dime:
                    for _, row in resultados['dime'].iterrows():
                        dados_consolidados.append({
                            'cnpj': str(row['cnpj']),
                            'periodo': row['periodo'],
                            'receita_12m': row['receita_12m'],
                            'fonte': 'DIME'
                        })
                df_analise = pd.DataFrame(dados_consolidados) if dados_consolidados else pd.DataFrame()
            else:
                df_analise = pd.DataFrame()

            if not df_analise.empty and len(cnpjs_validos) > 1:
                receitas_checks = []

                # Informa√ß√£o sobre fontes de dados
                fontes_disponiveis = df_analise['fonte'].unique().tolist() if 'fonte' in df_analise.columns else ['PGDAS']
                st.info(f"**Fontes de dados utilizadas:** {', '.join(fontes_disponiveis)}")

                # Mostrar contagem por fonte
                if 'fonte' in df_analise.columns:
                    col_f1, col_f2 = st.columns(2)
                    with col_f1:
                        cnpjs_pgdas = df_analise[df_analise['fonte'] == 'PGDAS']['cnpj'].nunique() if 'PGDAS' in fontes_disponiveis else 0
                        st.metric("CNPJs com PGDAS (Simples)", cnpjs_pgdas)
                    with col_f2:
                        cnpjs_dime = df_analise[df_analise['fonte'] == 'DIME']['cnpj'].nunique() if 'DIME' in fontes_disponiveis else 0
                        st.metric("CNPJs com DIME (Normal)", cnpjs_dime)

                # Receita somada ultrapassa limite
                max_score_possivel += 5
                receitas_por_cnpj = df_analise.groupby('cnpj')['receita_12m'].max()
                receita_total_grupo = receitas_por_cnpj.sum()
                receita_media = receitas_por_cnpj.mean()

                if receita_total_grupo > 4800000:
                    excesso = receita_total_grupo - 4800000
                    pontos_receita = 5
                    receitas_checks.append({
                        'Indicador': 'Receita Total do Grupo',
                        'Valor': formatar_moeda(receita_total_grupo),
                        'Status': 'üî¥ ACIMA DO LIMITE',
                        'Excesso': formatar_moeda(excesso),
                        'Pontos': str(pontos_receita),
                        'Avalia√ß√£o': 'CR√çTICO - Fracionamento'
                    })
                    evidencias['receita_excesso'] = True
                    score_similaridade += pontos_receita

                    st.error(f"""
                    **üî¥ ALERTA CR√çTICO - LIMITE ULTRAPASSADO**

                    Receita somada (PGDAS + DIME): **{formatar_moeda(receita_total_grupo)}**

                    Excesso: **{formatar_moeda(excesso)}** ({((excesso/4800000)*100):.1f}% acima do limite)

                    Este √© um forte ind√≠cio de fracionamento para manuten√ß√£o artificial no Simples Nacional.
                    """)
                else:
                    receitas_checks.append({
                        'Indicador': 'Receita Total do Grupo',
                        'Valor': formatar_moeda(receita_total_grupo),
                        'Status': '‚úÖ DENTRO DO LIMITE',
                        'Excesso': '-',
                        'Pontos': '0',
                        'Avalia√ß√£o': '-'
                    })

                # Distribui√ß√£o equilibrada (ind√≠cio de divis√£o artificial)
                max_score_possivel += 2
                desvio_padrao = receitas_por_cnpj.std()
                coef_variacao = (desvio_padrao / receita_media) if receita_media > 0 else 0

                if coef_variacao < 0.3 and len(receitas_por_cnpj) > 1:
                    receitas_checks.append({
                        'Indicador': 'Distribui√ß√£o de Receitas',
                        'Valor': f"CV: {coef_variacao:.2f}",
                        'Status': '‚ö†Ô∏è MUITO UNIFORME',
                        'Excesso': '-',
                        'Pontos': '2',
                        'Avalia√ß√£o': 'Poss√≠vel divis√£o planejada'
                    })
                    evidencias['receita_uniforme'] = True
                    score_similaridade += 2
                else:
                    receitas_checks.append({
                        'Indicador': 'Distribui√ß√£o de Receitas',
                        'Valor': f"CV: {coef_variacao:.2f}",
                        'Status': '‚úÖ VARIADA',
                        'Excesso': '-',
                        'Pontos': '0',
                        'Avalia√ß√£o': '-'
                    })

                # Correla√ß√£o temporal (evolu√ß√£o sincronizada)
                max_score_possivel += 3
                if len(cnpjs_validos) > 1:
                    pivot_receitas = df_analise.pivot_table(
                        index='periodo',
                        columns='cnpj',
                        values='receita_12m',
                        aggfunc='max'
                    )

                    if len(pivot_receitas) >= 3 and pivot_receitas.shape[1] > 1:
                        correlacoes = pivot_receitas.corr()
                        correlacao_media = correlacoes.values[np.triu_indices_from(correlacoes.values, k=1)].mean()

                        if correlacao_media > 0.7:
                            receitas_checks.append({
                                'Indicador': 'Correla√ß√£o Temporal',
                                'Valor': f"{correlacao_media:.2f}",
                                'Status': '‚ö†Ô∏è ALTA CORRELA√á√ÉO',
                                'Excesso': '-',
                                'Pontos': '3',
                                'Avalia√ß√£o': 'Opera√ß√µes sincronizadas'
                            })
                            evidencias['receita_correlacao'] = True
                            score_similaridade += 3
                        elif correlacao_media > 0.5:
                            receitas_checks.append({
                                'Indicador': 'Correla√ß√£o Temporal',
                                'Valor': f"{correlacao_media:.2f}",
                                'Status': '‚ö†Ô∏è CORRELA√á√ÉO MODERADA',
                                'Excesso': '-',
                                'Pontos': '1.5',
                                'Avalia√ß√£o': 'Poss√≠vel coordena√ß√£o'
                            })
                            score_similaridade += 1.5
                        else:
                            receitas_checks.append({
                                'Indicador': 'Correla√ß√£o Temporal',
                                'Valor': f"{correlacao_media:.2f}",
                                'Status': '‚úÖ BAIXA CORRELA√á√ÉO',
                                'Excesso': '-',
                                'Pontos': '0',
                                'Avalia√ß√£o': '-'
                            })

                # An√°lise de regimes mistos (Simples + Normal)
                if 'fonte' in df_analise.columns:
                    fontes_por_cnpj = df_analise.groupby('cnpj')['fonte'].first()
                    if len(fontes_por_cnpj.unique()) > 1:
                        receitas_checks.append({
                            'Indicador': 'Regimes Tribut√°rios',
                            'Valor': f"{len(fontes_por_cnpj.unique())} regimes",
                            'Status': '‚ö†Ô∏è MISTO',
                            'Excesso': '-',
                            'Pontos': '1',
                            'Avalia√ß√£o': 'Poss√≠vel planejamento tribut√°rio'
                        })
                        score_similaridade += 1

                df_receitas = pd.DataFrame(receitas_checks)

                # Garantir que todas as colunas sejam string
                for col in df_receitas.columns:
                    df_receitas[col] = df_receitas[col].astype(str)

                st.dataframe(df_receitas, hide_index=True)

                # GR√ÅFICOS
                col1, col2 = st.columns(2)

                with col1:
                    st.write("**Distribui√ß√£o de Receitas por CNPJ:**")

                    # Preparar dados para gr√°fico com cores por fonte
                    df_bar = df_analise.groupby(['cnpj', 'fonte'])['receita_12m'].max().reset_index()

                    fig1 = px.bar(
                        df_bar,
                        x='cnpj',
                        y='receita_12m',
                        color='fonte' if 'fonte' in df_bar.columns else None,
                        labels={'cnpj': 'CNPJ', 'receita_12m': 'Receita (R$)', 'fonte': 'Fonte'},
                        title="Receita M√°xima por CNPJ e Fonte",
                        template=filtros['tema'],
                        barmode='group'
                    )
                    fig1.add_hline(y=4800000, line_dash="dash", line_color="red",
                                 annotation_text="Limite SN")
                    st.plotly_chart(fig1, use_container_width=True)

                with col2:
                    st.write("**Evolu√ß√£o da Receita Total do Grupo:**")

                    # Receita somada por per√≠odo
                    receita_grupo_temporal = df_analise.groupby('periodo')['receita_12m'].sum().reset_index()
                    receita_grupo_temporal = receita_grupo_temporal.sort_values('periodo')

                    fig2 = px.line(
                        receita_grupo_temporal,
                        x='periodo',
                        y='receita_12m',
                        labels={'periodo': 'Per√≠odo', 'receita_12m': 'Receita Total (R$)'},
                        title="Receita Total do Grupo ao Longo do Tempo",
                        template=filtros['tema'],
                        markers=True
                    )
                    fig2.add_hline(y=4800000, line_dash="dash", line_color="red",
                                 annotation_text="Limite SN", annotation_position="bottom right")

                    # Adicionar linha com valores
                    fig2.update_traces(
                        mode='lines+markers+text',
                        text=[formatar_moeda(v) for v in receita_grupo_temporal['receita_12m']],
                        textposition='top center',
                        textfont=dict(size=9)
                    )

                    st.plotly_chart(fig2, use_container_width=True)

                # Tabela detalhada da evolu√ß√£o temporal
                if len(pivot_receitas) > 0:
                    st.write("**Receitas Detalhadas por CNPJ e Per√≠odo:**")

                    # Adicionar coluna de total
                    pivot_display = pivot_receitas.copy()
                    pivot_display['TOTAL GRUPO'] = pivot_display.sum(axis=1)

                    # Formatar valores
                    pivot_display = pivot_display.applymap(lambda x: formatar_moeda(x) if pd.notna(x) else '-')

                    st.dataframe(pivot_display)

                # Tabela resumo por fonte
                if 'fonte' in df_analise.columns:
                    st.write("**Resumo por Fonte de Dados:**")
                    resumo_fonte = df_analise.groupby('fonte').agg({
                        'cnpj': 'nunique',
                        'receita_12m': ['max', 'mean', 'sum']
                    }).round(2)
                    resumo_fonte.columns = ['Qtd CNPJs', 'Receita M√°x', 'Receita M√©dia', 'Receita Total']
                    for col in ['Receita M√°x', 'Receita M√©dia', 'Receita Total']:
                        resumo_fonte[col] = resumo_fonte[col].apply(formatar_moeda)
                    st.dataframe(resumo_fonte)

            else:
                st.warning("Dados de receitas insuficientes (PGDAS ou DIME)")
        
        # ===================================================================
        # TAB 4: AN√ÅLISE DE NOTAS FISCAIS
        # ===================================================================
        with tabs_similaridade[3]:
            st.subheader("Compartilhamento em Notas Fiscais")
            
            if not resultados['nfe'].empty and len(cnpjs_validos) > 1:
                nfe_checks = []
                
                # IPs de transmiss√£o compartilhados
                max_score_possivel += 3
                if 'nfe_ip_transmissao' in resultados['nfe'].columns:
                    ips_por_cnpj = {}
                    for cnpj in cnpjs_validos:
                        ips_emit = resultados['nfe'][resultados['nfe']['nfe_cnpj_cpf_emit'] == cnpj]['nfe_ip_transmissao'].dropna().unique()
                        if len(ips_emit) > 0:
                            ips_por_cnpj[cnpj] = set(ips_emit)
                    
                    if len(ips_por_cnpj) > 1:
                        all_ips = set()
                        for ips in ips_por_cnpj.values():
                            all_ips.update(ips)
                        
                        ips_compartilhados = []
                        for ip in all_ips:
                            cnpjs_com_ip = [cnpj for cnpj, ips in ips_por_cnpj.items() if ip in ips]
                            if len(cnpjs_com_ip) > 1:
                                ips_compartilhados.append(ip)
                        
                        if len(ips_compartilhados) > 0:
                            pontos_ip = min(len(ips_compartilhados), 3)
                            nfe_checks.append({
                                'Indicador': 'IPs de Transmiss√£o',
                                'Quantidade': len(ips_compartilhados),
                                'Status': '‚úÖ COMPARTILHADOS',
                                'Pontos': pontos_ip,
                                'Avalia√ß√£o': 'CR√çTICO - Mesma origem'
                            })
                            evidencias['ip_compartilhado'] = True
                            score_similaridade += pontos_ip
                            
                            st.write("**IPs Compartilhados:**")
                            for ip in ips_compartilhados[:5]:
                                cnpjs_ip = [cnpj for cnpj, ips in ips_por_cnpj.items() if ip in ips]
                                st.write(f"‚Ä¢ {ip}: {len(cnpjs_ip)} CNPJs")
                        else:
                            nfe_checks.append({
                                'Indicador': 'IPs de Transmiss√£o',
                                'Quantidade': 0,
                                'Status': '‚ùå N√ÉO COMPARTILHADOS',
                                'Pontos': 0,
                                'Avalia√ß√£o': '-'
                            })
                
                # Clientes compartilhados
                max_score_possivel += 2
                emitentes = resultados['nfe']['nfe_cnpj_cpf_emit'].isin(cnpjs_validos)
                if emitentes.any():
                    clientes_por_cnpj = {}
                    for cnpj in cnpjs_validos:
                        clientes = resultados['nfe'][resultados['nfe']['nfe_cnpj_cpf_emit'] == cnpj]['nfe_cnpj_cpf_dest'].dropna().unique()
                        clientes_por_cnpj[cnpj] = set(clientes)
                    
                    if len(clientes_por_cnpj) > 1:
                        clientes_compartilhados = set.intersection(*clientes_por_cnpj.values())
                        
                        if len(clientes_compartilhados) > 0:
                            pontos_clientes = min(len(clientes_compartilhados) / 10, 2)
                            nfe_checks.append({
                                'Indicador': 'Clientes Comuns',
                                'Quantidade': len(clientes_compartilhados),
                                'Status': '‚úÖ DETECTADOS',
                                'Pontos': pontos_clientes,
                                'Avalia√ß√£o': 'Mesma base de clientes'
                            })
                            evidencias['clientes_comuns'] = True
                            score_similaridade += pontos_clientes
                        else:
                            nfe_checks.append({
                                'Indicador': 'Clientes Comuns',
                                'Quantidade': 0,
                                'Status': '‚ùå N√ÉO DETECTADOS',
                                'Pontos': 0,
                                'Avalia√ß√£o': '-'
                            })
                
                # Fornecedores compartilhados
                max_score_possivel += 2
                destinatarios = resultados['nfe']['nfe_cnpj_cpf_dest'].isin(cnpjs_validos)
                if destinatarios.any():
                    fornecedores_por_cnpj = {}
                    for cnpj in cnpjs_validos:
                        fornecedores = resultados['nfe'][resultados['nfe']['nfe_cnpj_cpf_dest'] == cnpj]['nfe_cnpj_cpf_emit'].dropna().unique()
                        fornecedores_por_cnpj[cnpj] = set(fornecedores)
                    
                    if len(fornecedores_por_cnpj) > 1:
                        fornecedores_compartilhados = set.intersection(*fornecedores_por_cnpj.values())
                        
                        if len(fornecedores_compartilhados) > 0:
                            pontos_fornec = min(len(fornecedores_compartilhados) / 10, 2)
                            nfe_checks.append({
                                'Indicador': 'Fornecedores Comuns',
                                'Quantidade': len(fornecedores_compartilhados),
                                'Status': '‚úÖ DETECTADOS',
                                'Pontos': pontos_fornec,
                                'Avalia√ß√£o': 'Mesma cadeia de suprimentos'
                            })
                            evidencias['fornecedores_comuns'] = True
                            score_similaridade += pontos_fornec
                        else:
                            nfe_checks.append({
                                'Indicador': 'Fornecedores Comuns',
                                'Quantidade': 0,
                                'Status': '‚ùå N√ÉO DETECTADOS',
                                'Pontos': 0,
                                'Avalia√ß√£o': '-'
                            })
                
                # C√≥digos de produtos compartilhados
                max_score_possivel += 1
                if 'nfe_cd_produto' in resultados['nfe'].columns:
                    produtos_por_cnpj = {}
                    for cnpj in cnpjs_validos:
                        produtos = resultados['nfe'][resultados['nfe']['nfe_cnpj_cpf_emit'] == cnpj]['nfe_cd_produto'].dropna().unique()
                        produtos_por_cnpj[cnpj] = set(produtos)
                    
                    if len(produtos_por_cnpj) > 1:
                        produtos_compartilhados = set.intersection(*produtos_por_cnpj.values())
                        
                        if len(produtos_compartilhados) >= 5:
                            nfe_checks.append({
                                'Indicador': 'C√≥digos de Produto Comuns',
                                'Quantidade': len(produtos_compartilhados),
                                'Status': '‚úÖ DETECTADOS',
                                'Pontos': 1,
                                'Avalia√ß√£o': 'Mesmo cat√°logo'
                            })
                            evidencias['produtos_comuns'] = True
                            score_similaridade += 1
                        elif len(produtos_compartilhados) > 0:
                            nfe_checks.append({
                                'Indicador': 'C√≥digos de Produto Comuns',
                                'Quantidade': len(produtos_compartilhados),
                                'Status': '‚ö†Ô∏è POUCOS',
                                'Pontos': 0.5,
                                'Avalia√ß√£o': 'Alguma sobreposi√ß√£o'
                            })
                            score_similaridade += 0.5
                
                # Descri√ß√£o de produtos compartilhados
                max_score_possivel += 1
                if 'nfe_de_produto' in resultados['nfe'].columns:
                    desc_por_cnpj = {}
                    for cnpj in cnpjs_validos:
                        desc = resultados['nfe'][resultados['nfe']['nfe_cnpj_cpf_emit'] == cnpj]['nfe_de_produto'].dropna().unique()
                        desc_por_cnpj[cnpj] = set(desc)
                    
                    if len(desc_por_cnpj) > 1:
                        desc_compartilhadas = set.intersection(*desc_por_cnpj.values())
                        
                        if len(desc_compartilhadas) >= 5:
                            nfe_checks.append({
                                'Indicador': 'Descri√ß√µes de Produto Comuns',
                                'Quantidade': len(desc_compartilhadas),
                                'Status': '‚úÖ DETECTADOS',
                                'Pontos': 1,
                                'Avalia√ß√£o': 'Mesmo portf√≥lio'
                            })
                            evidencias['desc_produtos_comuns'] = True
                            score_similaridade += 1
                
                # Telefones do emitente compartilhados
                max_score_possivel += 2
                if 'nfe_emit_telefone' in resultados['nfe'].columns:
                    tel_emit_por_cnpj = {}
                    for cnpj in cnpjs_validos:
                        tels = resultados['nfe'][resultados['nfe']['nfe_cnpj_cpf_emit'] == cnpj]['nfe_emit_telefone'].dropna().unique()
                        if len(tels) > 0:
                            tel_emit_por_cnpj[cnpj] = set(tels)
                    
                    if len(tel_emit_por_cnpj) > 1:
                        all_tels = set()
                        for tels in tel_emit_por_cnpj.values():
                            all_tels.update(tels)
                        
                        tels_compartilhados = [tel for tel in all_tels if sum(1 for tels in tel_emit_por_cnpj.values() if tel in tels) > 1]
                        
                        if len(tels_compartilhados) > 0:
                            pontos_tel = min(len(tels_compartilhados), 2)
                            nfe_checks.append({
                                'Indicador': 'Telefones Emitente',
                                'Quantidade': len(tels_compartilhados),
                                'Status': '‚úÖ COMPARTILHADOS',
                                'Pontos': pontos_tel,
                                'Avalia√ß√£o': 'CR√çTICO - Mesmo contato'
                            })
                            evidencias['tel_emit_compartilhado'] = True
                            score_similaridade += pontos_tel
                
                # E-mails de destinat√°rio compartilhados
                max_score_possivel += 1
                if 'nfe_dest_email' in resultados['nfe'].columns:
                    emails_por_cnpj = {}
                    for cnpj in cnpjs_validos:
                        emails = resultados['nfe'][resultados['nfe']['nfe_cnpj_cpf_emit'] == cnpj]['nfe_dest_email'].dropna().unique()
                        if len(emails) > 0:
                            emails_por_cnpj[cnpj] = set(emails)
                    
                    if len(emails_por_cnpj) > 1:
                        emails_compartilhados = set.intersection(*emails_por_cnpj.values())
                        
                        if len(emails_compartilhados) > 0:
                            nfe_checks.append({
                                'Indicador': 'E-mails Destinat√°rio',
                                'Quantidade': len(emails_compartilhados),
                                'Status': '‚úÖ COMPARTILHADOS',
                                'Pontos': 1,
                                'Avalia√ß√£o': 'Mesmos contatos'
                            })
                            evidencias['email_dest_compartilhado'] = True
                            score_similaridade += 1
                
                # Endere√ßos de emiss√£o compartilhados
                max_score_possivel += 2
                if 'nfe_emit_end_completo' in resultados['nfe'].columns:
                    enderecos_emit = resultados['nfe'][resultados['nfe']['nfe_cnpj_cpf_emit'].isin(cnpjs_validos)]['nfe_emit_end_completo'].dropna().unique()
                    if len(enderecos_emit) == 1 and len(enderecos_emit[0]) > 10:
                        nfe_checks.append({
                            'Indicador': 'Endere√ßo de Emiss√£o',
                            'Quantidade': 1,
                            'Status': '‚úÖ MESMO ENDERE√áO',
                            'Pontos': 2,
                            'Avalia√ß√£o': 'CR√çTICO - Mesmo local'
                        })
                        evidencias['endereco_nfe_emit'] = True
                        score_similaridade += 2
                    elif len(enderecos_emit) > 1:
                        nfe_checks.append({
                            'Indicador': 'Endere√ßo de Emiss√£o',
                            'Quantidade': len(enderecos_emit),
                            'Status': '‚ùå DIFERENTES',
                            'Pontos': 0,
                            'Avalia√ß√£o': '-'
                        })
                
                # Endere√ßos de destino compartilhados
                max_score_possivel += 2
                if 'nfe_dest_end_completo' in resultados['nfe'].columns:
                    enderecos_dest = resultados['nfe'][resultados['nfe']['nfe_cnpj_cpf_dest'].isin(cnpjs_validos)]['nfe_dest_end_completo'].dropna().unique()
                    if len(enderecos_dest) == 1 and len(enderecos_dest[0]) > 10:
                        nfe_checks.append({
                            'Indicador': 'Endere√ßo de Destino',
                            'Quantidade': 1,
                            'Status': '‚úÖ MESMO ENDERE√áO',
                            'Pontos': 2,
                            'Avalia√ß√£o': 'CR√çTICO - Mesmo local'
                        })
                        evidencias['endereco_nfe_dest'] = True
                        score_similaridade += 2
                    elif len(enderecos_dest) > 1:
                        nfe_checks.append({
                            'Indicador': 'Endere√ßo de Destino',
                            'Quantidade': len(enderecos_dest),
                            'Status': '‚ùå DIFERENTES',
                            'Pontos': 0,
                            'Avalia√ß√£o': '-'
                        })
                
                if nfe_checks:
                    df_nfe = pd.DataFrame(nfe_checks)
                    st.dataframe(df_nfe, width='stretch', hide_index=True)
                    
                    pontos_nfe = df_nfe['Pontos'].sum()
                    if pontos_nfe >= 5:
                        st.error(f"üî¥ CR√çTICO: {pontos_nfe:.1f} pontos - Opera√ß√µes fortemente interligadas")
                    elif pontos_nfe >= 3:
                        st.warning(f"üü° ALTO: {pontos_nfe:.1f} pontos")
                    else:
                        st.info(f"üü¢ MODERADO: {pontos_nfe:.1f} pontos")
            else:
                st.warning("Dados de notas fiscais insuficientes")
        
        # ===================================================================
        # TAB 5: AN√ÅLISE DE CONV√äNIO 115
        # ===================================================================
        with tabs_similaridade[4]:
            st.subheader("An√°lise Conv√™nio 115 - Identificadores Compartilhados")
            
            if not resultados['c115'].empty and len(cnpjs_validos) > 1:
                c115_checks = []
                
                # Identificadores de tomador compartilhados
                max_score_possivel += 3
                identificadores = resultados['c115'].groupby('nu_identificador_tomador')['cnpj_tomador'].nunique()
                identificadores_compart = identificadores[identificadores > 1]
                
                if len(identificadores_compart) > 0:
                    pontos_id = min(len(identificadores_compart), 3)
                    c115_checks.append({
                        'Indicador': 'Identificadores Compartilhados',
                        'Quantidade': len(identificadores_compart),
                        'Status': '‚úÖ DETECTADOS',
                        'Pontos': pontos_id,
                        'Avalia√ß√£o': 'CR√çTICO - Mesmo identificador'
                    })
                    evidencias['c115_identificador'] = True
                    score_similaridade += pontos_id
                    
                    st.write("**Identificadores Compartilhados:**")
                    for identificador, qtd in identificadores_compart.head(10).items():
                        st.write(f"‚Ä¢ {identificador}: {qtd} CNPJs")
                else:
                    c115_checks.append({
                        'Indicador': 'Identificadores Compartilhados',
                        'Quantidade': 0,
                        'Status': '‚ùå N√ÉO DETECTADOS',
                        'Pontos': 0,
                        'Avalia√ß√£o': '-'
                    })
                
                # Telefones de contato compartilhados
                max_score_possivel += 2
                if 'nu_tel_contato' in resultados['c115'].columns:
                    telefones = resultados['c115'].groupby('nu_tel_contato')['cnpj_tomador'].nunique()
                    telefones_compart = telefones[telefones > 1]
                    
                    if len(telefones_compart) > 0:
                        pontos_tel = min(len(telefones_compart), 2)
                        c115_checks.append({
                            'Indicador': 'Telefones Compartilhados',
                            'Quantidade': len(telefones_compart),
                            'Status': '‚úÖ DETECTADOS',
                            'Pontos': pontos_tel,
                            'Avalia√ß√£o': 'Alto - Mesmo contato'
                        })
                        evidencias['c115_telefone'] = True
                        score_similaridade += pontos_tel
                    else:
                        c115_checks.append({
                            'Indicador': 'Telefones Compartilhados',
                            'Quantidade': 0,
                            'Status': '‚ùå N√ÉO DETECTADOS',
                            'Pontos': 0,
                            'Avalia√ß√£o': '-'
                        })
                
                if c115_checks:
                    df_c115 = pd.DataFrame(c115_checks)
                    st.dataframe(df_c115, width='stretch', hide_index=True)
            else:
                st.warning("Dados do Conv√™nio 115 insuficientes")
        
        # ===================================================================
        # TAB 6: AN√ÅLISE DE CONTAS BANC√ÅRIAS (CCS)
        # ===================================================================
        with tabs_similaridade[5]:
            st.subheader("An√°lise de Contas Banc√°rias - CCS")
            
            if not resultados['ccs'].empty and len(cnpjs_validos) > 1:
                ccs_checks = []
                
                # CPFs compartilhando acesso a contas
                max_score_possivel += 4
                cpfs_contas = resultados['ccs'].groupby('nr_cpf')['cnpj'].nunique()
                cpfs_compartilhados = cpfs_contas[cpfs_contas > 1]
                
                if len(cpfs_compartilhados) > 0:
                    pontos_cpf = min(len(cpfs_compartilhados) * 2, 4)
                    ccs_checks.append({
                        'Indicador': 'CPFs com M√∫ltiplas Contas',
                        'Quantidade': len(cpfs_compartilhados),
                        'Status': '‚úÖ DETECTADOS',
                        'Pontos': pontos_cpf,
                        'Avalia√ß√£o': 'CR√çTICO - Gest√£o financeira comum'
                    })
                    evidencias['ccs_cpf_compartilhado'] = True
                    score_similaridade += pontos_cpf
                    
                    st.write("**CPFs com Acesso a M√∫ltiplas Contas:**")
                    for cpf, qtd in cpfs_compartilhados.head(10).items():
                        st.write(f"‚Ä¢ CPF {cpf}: Acesso a contas de {qtd} CNPJs")
                        contas_cpf = resultados['ccs'][resultados['ccs']['nr_cpf'] == cpf]
                        for _, conta in contas_cpf.iterrows():
                            st.write(f"  - {conta['cnpj']}: {conta.get('nm_banco', 'N/A')} - Ag: {conta.get('cd_agencia', 'N/A')}")
                else:
                    ccs_checks.append({
                        'Indicador': 'CPFs com M√∫ltiplas Contas',
                        'Quantidade': 0,
                        'Status': '‚ùå N√ÉO DETECTADOS',
                        'Pontos': 0,
                        'Avalia√ß√£o': '-'
                    })
                
                # Bancos e ag√™ncias comuns
                max_score_possivel += 1
                bancos_agencias = resultados['ccs'].groupby(['nm_banco', 'cd_agencia'])['cnpj'].nunique()
                bancos_comuns = bancos_agencias[bancos_agencias > 1]
                
                if len(bancos_comuns) > 0:
                    ccs_checks.append({
                        'Indicador': 'Banco/Ag√™ncia Comuns',
                        'Quantidade': len(bancos_comuns),
                        'Status': '‚úÖ DETECTADOS',
                        'Pontos': 1,
                        'Avalia√ß√£o': 'Mesma pra√ßa banc√°ria'
                    })
                    score_similaridade += 1
                
                if ccs_checks:
                    df_ccs = pd.DataFrame(ccs_checks)
                    st.dataframe(df_ccs, width='stretch', hide_index=True)
            else:
                st.warning("Dados de contas banc√°rias insuficientes")
        
        # ===================================================================
        # TAB 7: AN√ÅLISE DE FUNCION√ÅRIOS
        # ===================================================================
        with tabs_similaridade[6]:
            st.subheader("An√°lise de Funcion√°rios - RAIS/CAGED")
            
            if not resultados['funcionarios'].empty:
                func_checks = []
                
                # Baixo n√∫mero de funcion√°rios vs receita
                max_score_possivel += 3
                for _, row in resultados['funcionarios'].iterrows():
                    cnpj = row['cnpj']
                    funcionarios = row['total_funcionarios']

                    # Buscar receita m√°xima do CNPJ (PGDAS ou DIME)
                    receita = None
                    fonte_receita = None

                    if not resultados['pgdas'].empty:
                        receita_pgdas = resultados['pgdas'][resultados['pgdas']['cnpj'] == cnpj]['receita_12m'].max()
                        if pd.notna(receita_pgdas) and receita_pgdas > 0:
                            receita = receita_pgdas
                            fonte_receita = 'PGDAS'

                    if not resultados.get('dime', pd.DataFrame()).empty:
                        receita_dime = resultados['dime'][resultados['dime']['cnpj'] == cnpj]['receita_12m'].max()
                        if pd.notna(receita_dime) and receita_dime > 0:
                            if receita is None or receita_dime > receita:
                                receita = receita_dime
                                fonte_receita = 'DIME'

                    if receita is not None and receita > 0:
                        receita_por_func = receita / (funcionarios + 1)  # +1 para evitar divis√£o por zero

                        if receita_por_func > 500000:  # R$ 500k por funcion√°rio
                            func_checks.append({
                                'CNPJ': cnpj,
                                'Funcion√°rios': int(funcionarios),
                                'Receita': formatar_moeda(receita),
                                'Fonte': fonte_receita,
                                'Receita/Func': formatar_moeda(receita_por_func),
                                'Status': '‚ö†Ô∏è DESPROPORCIONAL',
                                'Avalia√ß√£o': 'Poss√≠vel terceiriza√ß√£o ou opera√ß√£o concentrada'
                            })
                            score_similaridade += 1
                
                # Total de funcion√°rios do grupo
                total_funcionarios = resultados['funcionarios']['total_funcionarios'].sum()
                st.metric("Total de Funcion√°rios no Grupo", int(total_funcionarios))
                
                if func_checks:
                    st.write("**An√°lise Receita vs Funcion√°rios:**")
                    df_func = pd.DataFrame(func_checks)
                    st.dataframe(df_func, width='stretch', hide_index=True)
                else:
                    st.success("‚úÖ Propor√ß√£o receita/funcion√°rios dentro do esperado")
            else:
                st.warning("Dados de funcion√°rios insuficientes")
        
        # ===================================================================
        # TAB 8: AN√ÅLISE DE MEIOS DE PAGAMENTO
        # ===================================================================
        with tabs_similaridade[7]:
            st.subheader("An√°lise de Meios de Pagamento")
            
            if not resultados['pagamentos'].empty:
                pag_checks = []
                
                # Separar pagamentos por tipo
                pag_cnpj = resultados['pagamentos'][resultados['pagamentos']['tipo_identificador'] == 'CNPJ']
                pag_cpf = resultados['pagamentos'][resultados['pagamentos']['tipo_identificador'] == 'CPF']
                
                # An√°lise de valores das empresas
                max_score_possivel += 2
                if not pag_cnpj.empty:
                    valores_empresas = pag_cnpj.groupby('identificador')['valor_total'].sum()
                    
                    st.write("**Valores de Meios de Pagamento por CNPJ:**")
                    for cnpj, valor in valores_empresas.items():
                        st.write(f"‚Ä¢ {cnpj}: {formatar_moeda(valor)}")
                
                # An√°lise de valores dos s√≥cios
                if not pag_cpf.empty:
                    valores_socios = pag_cpf.groupby('identificador')['valor_total'].sum()
                    
                    st.write("**Valores de Meios de Pagamento dos S√≥cios (CPF):**")
                    
                    # Verificar se h√° s√≥cios compartilhados com meios de pagamento
                    if not resultados.get('socios_cpf', pd.DataFrame()).empty:
                        cpfs_com_pagamento = set(valores_socios.index)
                        
                        # Ver quais CPFs est√£o em m√∫ltiplos CNPJs
                        cpfs_por_cnpj = resultados['socios_cpf'].groupby('cpf_socio')['cnpj'].nunique()
                        cpfs_compartilhados_com_pag = cpfs_por_cnpj[cpfs_por_cnpj > 1]
                        cpfs_compartilhados_com_pag = cpfs_compartilhados_com_pag[cpfs_compartilhados_com_pag.index.isin(cpfs_com_pagamento)]
                        
                        if len(cpfs_compartilhados_com_pag) > 0:
                            pontos_pag_socios = min(len(cpfs_compartilhados_com_pag), 2)
                            pag_checks.append({
                                'Indicador': 'S√≥cios com Meios Pagamento',
                                'Quantidade': len(cpfs_compartilhados_com_pag),
                                'Status': '‚úÖ DETECTADOS',
                                'Pontos': pontos_pag_socios,
                                'Avalia√ß√£o': 'Alto - Gest√£o financeira comum'
                            })
                            evidencias['socios_meios_pagamento'] = True
                            score_similaridade += pontos_pag_socios
                            
                            st.write(f"**‚ö†Ô∏è {len(cpfs_compartilhados_com_pag)} s√≥cios compartilhados com meios de pagamento:**")
                            for cpf, qtd_cnpj in cpfs_compartilhados_com_pag.items():
                                valor_socio = valores_socios.get(cpf, 0)
                                st.write(f"‚Ä¢ CPF {cpf}: S√≥cio de {qtd_cnpj} CNPJs - Pagamentos: {formatar_moeda(valor_socio)}")
                    
                    # Mostrar top s√≥cios por valor
                    st.write("**Top 10 S√≥cios por Valor de Pagamentos:**")
                    top_socios = valores_socios.sort_values(ascending=False).head(10)
                    for cpf, valor in top_socios.items():
                        st.write(f"‚Ä¢ CPF {cpf}: {formatar_moeda(valor)}")
                
                if pag_checks:
                    df_pag = pd.DataFrame(pag_checks)
                    st.dataframe(df_pag, width='stretch', hide_index=True)
                else:
                    st.info("An√°lise de meios de pagamento requer dados adicionais de s√≥cios.")
            else:
                st.warning("Dados de meios de pagamento insuficientes")
        
        # ===================================================================
        # TAB 9: SCORE FINAL E CONCLUS√ÉO
        # ===================================================================
        with tabs_similaridade[8]:
            st.subheader("üìä Score Final de Similaridade")
            
            # M√©tricas principais
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("Score Total", f"{score_similaridade:.1f}", 
                         help="Pontua√ß√£o total baseada em todas as evid√™ncias")
            
            with col2:
                st.metric("Score M√°ximo Poss√≠vel", f"{max_score_possivel:.1f}",
                         help="Pontua√ß√£o m√°xima com base nos dados dispon√≠veis")
            
            with col3:
                percentual = (score_similaridade / max_score_possivel * 100) if max_score_possivel > 0 else 0
                st.metric("Percentual", f"{percentual:.1f}%",
                         help="Percentual do score em rela√ß√£o ao m√°ximo")
            
            with col4:
                total_evidencias = len([v for v in evidencias.values() if v])
                st.metric("Evid√™ncias", total_evidencias,
                         help="N√∫mero de evid√™ncias positivas encontradas")
            
            # Determina√ß√£o do n√≠vel de risco
            st.divider()
            
            if score_similaridade >= 15:
                nivel_risco = "üî¥ CR√çTICO"
                cor_risco = "error"
                conclusao = """
                **FORTE EVID√äNCIA DE GRUPO ECON√îMICO**
                
                Os CNPJs analisados apresentam m√∫ltiplas e graves evid√™ncias de pertencerem ao mesmo 
                grupo econ√¥mico. As similaridades detectadas em dados cadastrais, v√≠nculos societ√°rios, 
                padr√µes operacionais e indicadores fiscais sugerem fortemente opera√ß√£o coordenada e 
                gest√£o centralizada.
                
                **RECOMENDA√á√ÉO URGENTE:**
                - Cria√ß√£o imediata de grupo GEI para monitoramento integrado
                - An√°lise aprofundada de poss√≠vel planejamento tribut√°rio abusivo
                - Verifica√ß√£o de fraude √† lei (fracionamento artificial)
                - Intima√ß√£o dos contribuintes para esclarecimentos
                - Considerar procedimento fiscal conjunto
                """
            elif score_similaridade >= 10:
                nivel_risco = "üü° ALTO"
                cor_risco = "warning"
                conclusao = """
                **EVID√äNCIA SIGNIFICATIVA DE GRUPO ECON√îMICO**
                
                Os CNPJs apresentam v√°rias caracter√≠sticas compat√≠veis com grupo econ√¥mico. 
                As evid√™ncias encontradas justificam investiga√ß√£o mais aprofundada.
                
                **RECOMENDA√á√ÉO:**
                - Cria√ß√£o de grupo GEI para monitoramento
                - An√°lise complementar com dados adicionais
                - Solicitar documenta√ß√£o adicional aos contribuintes
                - Monitoramento refor√ßado nos pr√≥ximos per√≠odos
                - Verificar hist√≥rico de altera√ß√µes cadastrais
                """
            elif score_similaridade >= 5:
                nivel_risco = "üü† MODERADO"
                cor_risco = "info"
                conclusao = """
                **IND√çCIOS MODERADOS DE GRUPO ECON√îMICO**
                
                Alguns ind√≠cios sugerem poss√≠vel vincula√ß√£o entre os CNPJs, mas n√£o s√£o conclusivos.
                Recomenda-se monitoramento e coleta de evid√™ncias adicionais.
                
                **RECOMENDA√á√ÉO:**
                - Monitoramento peri√≥dico dos CNPJs
                - Aten√ß√£o a novos ind√≠cios que possam surgir
                - Cruzamento com outras bases de dados
                - Acompanhar evolu√ß√£o das receitas
                """
            else:
                nivel_risco = "üü¢ BAIXO"
                cor_risco = "success"
                conclusao = """
                **BAIXA EVID√äNCIA DE GRUPO ECON√îMICO**
                
                Com base nos dados analisados, n√£o foram encontradas evid√™ncias significativas de que 
                os CNPJs perten√ßam ao mesmo grupo econ√¥mico. As similaridades detectadas podem ser 
                coincid√™ncias ou caracter√≠sticas comuns do setor.
                
                **RECOMENDA√á√ÉO:**
                - Monitoramento de rotina conforme procedimentos padr√£o
                - Aten√ß√£o caso surjam novos ind√≠cios futuramente
                """
            
            # Exibir n√≠vel de risco
            if cor_risco == "error":
                st.error(f"**N√≠vel de Risco: {nivel_risco}**")
            elif cor_risco == "warning":
                st.warning(f"**N√≠vel de Risco: {nivel_risco}**")
            elif cor_risco == "info":
                st.info(f"**N√≠vel de Risco: {nivel_risco}**")
            else:
                st.success(f"**N√≠vel de Risco: {nivel_risco}**")
            
            # Conclus√£o detalhada
            st.markdown("### üéØ Conclus√£o da An√°lise")
            st.markdown(conclusao)
            
            # Tabela resumo de evid√™ncias
            if evidencias:
                st.markdown("### üìã Resumo das Evid√™ncias Encontradas")
                
                categorias_evidencias = {
                    'Cadastrais': ['razao_social', 'fantasia', 'cnae', 'contador', 'endereco'],
                    'Societ√°rias': ['socios_compartilhados'],
                    'Fiscais': ['receita_excesso', 'receita_uniforme', 'receita_correlacao'],
                    'Operacionais': ['ip_compartilhado', 'clientes_comuns', 'fornecedores_comuns', 'produtos_comuns', 'desc_produtos_comuns', 'tel_emit_compartilhado', 'email_dest_compartilhado', 'endereco_nfe_emit', 'endereco_nfe_dest'],
                    'C115': ['c115_identificador', 'c115_telefone'],
                    'Financeiras': ['ccs_cpf_compartilhado', 'socios_meios_pagamento']
                }
                
                resumo_evidencias = []
                for categoria, chaves in categorias_evidencias.items():
                    evidencias_categoria = [k for k in chaves if evidencias.get(k, False)]
                    if evidencias_categoria:
                        resumo_evidencias.append({
                            'Categoria': categoria,
                            'Quantidade': len(evidencias_categoria),
                            'Evid√™ncias': ', '.join([k.replace('_', ' ').title() for k in evidencias_categoria])
                        })
                
                if resumo_evidencias:
                    df_resumo = pd.DataFrame(resumo_evidencias)
                    st.dataframe(df_resumo, width='stretch', hide_index=True)
            
            # Gr√°fico de distribui√ß√£o de pontos
            st.markdown("### üìà Distribui√ß√£o de Pontos por Categoria")
            
            categorias_pontos = {
                'Cadastro': sum([2 if evidencias.get('razao_social') else 0,
                                1 if evidencias.get('fantasia') else 0,
                                1 if evidencias.get('cnae') else 0,
                                2 if evidencias.get('contador') else 0,
                                3 if evidencias.get('endereco') else 0]),
                'S√≥cios': 5 if evidencias.get('socios_compartilhados') else 0,
                'Receitas': sum([5 if evidencias.get('receita_excesso') else 0,
                                2 if evidencias.get('receita_uniforme') else 0,
                                3 if evidencias.get('receita_correlacao') else 0]),
                'NFe': sum([3 if evidencias.get('ip_compartilhado') else 0,
                           2 if evidencias.get('clientes_comuns') else 0,
                           2 if evidencias.get('fornecedores_comuns') else 0,
                           1 if evidencias.get('produtos_comuns') else 0,
                           2 if evidencias.get('endereco_nfe') else 0]),
                'C115': sum([3 if evidencias.get('c115_identificador') else 0,
                            2 if evidencias.get('c115_telefone') else 0]),
                'CCS': 4 if evidencias.get('ccs_cpf_compartilhado') else 0
            }
            
            df_categorias = pd.DataFrame([
                {'Categoria': k, 'Pontos': v}
                for k, v in categorias_pontos.items() if v > 0
            ])
            
            if not df_categorias.empty:
                fig = px.bar(df_categorias, x='Categoria', y='Pontos',
                            title="Pontos por Categoria de Evid√™ncia",
                            template=filtros['tema'],
                            color='Pontos',
                            color_continuous_scale='Reds')
                st.plotly_chart(fig, use_container_width=True)
        
        # BOT√ÉO DE EXPORTA√á√ÉO
        st.divider()
        st.subheader("Exporta√ß√£o de Relat√≥rio")
        
        st.write("""
        Clique no bot√£o abaixo para gerar um relat√≥rio em PDF com todas as informa√ß√µes 
        consolidadas desta an√°lise pontual.
        """)
        
        col1, col2, col3 = st.columns([1, 1, 1])
        
        with col2:
            if st.button("üìÑ Gerar PDF da An√°lise", type="primary", width='stretch', key="gerar_pdf_analise"):
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                try:
                    status_text.text("Iniciando gera√ß√£o do PDF...")
                    progress_bar.progress(10)
                    
                    status_text.text("Coletando dados da an√°lise...")
                    progress_bar.progress(30)
                    
                    status_text.text("Organizando informa√ß√µes...")
                    progress_bar.progress(50)
                    
                    status_text.text("Gerando documento PDF...")
                    progress_bar.progress(70)
                    
                    pdf_buffer = gerar_pdf_analise_pontual(cnpjs_validos, resultados)
                    
                    progress_bar.progress(90)
                    status_text.text("Finalizando...")
                    
                    progress_bar.progress(100)
                    status_text.text("PDF gerado com sucesso!")
                    
                    st.success("PDF gerado com sucesso!")
                    
                    st.download_button(
                        label="‚¨áÔ∏è Download PDF",
                        data=pdf_buffer,
                        file_name=f"analise_pontual_{datetime.now().strftime('%Y%m%d_%H%M')}.pdf",
                        mime="application/pdf",
                        width='stretch',
                        key="download_pdf_analise_auto"
                    )
                    
                    import time
                    time.sleep(2)
                    progress_bar.empty()
                    status_text.empty()
                    
                except Exception as e:
                    st.error(f"Erro ao gerar PDF: {e}")
                    progress_bar.empty()
                    status_text.empty()
        
        st.divider()
        
        st.write("**O que inclui o relat√≥rio PDF:**")
        st.write("‚Ä¢ Resumo executivo com m√©tricas principais")
        st.write("‚Ä¢ Alertas cr√≠ticos identificados")
        st.write("‚Ä¢ Dados cadastrais completos de todos os CNPJs")
        st.write("‚Ä¢ V√≠nculos societ√°rios detalhados")
        st.write("‚Ä¢ An√°lise de s√≥cios compartilhados")
        st.write("‚Ä¢ Receitas declaradas (PGDAS)")
        st.write("‚Ä¢ Notas fiscais emitidas e recebidas")
        st.write("‚Ä¢ Dados do Conv√™nio 115")
        st.write("‚Ä¢ Contas banc√°rias (CCS)")
        st.write("‚Ä¢ Informa√ß√µes de funcion√°rios")
        st.write("‚Ä¢ Meios de pagamento")
        st.write("‚Ä¢ Ind√≠cios fiscais identificados")
        st.write("‚Ä¢ Verifica√ß√£o de grupos GEI existentes")
        st.write("‚Ä¢ Conclus√µes e recomenda√ß√µes")

def dashboard_executivo(dados, filtros):
    """Dashboard executivo principal"""
    st.markdown("<h1 class='main-header'>Dashboard Executivo</h1>", unsafe_allow_html=True)
    
    df = aplicar_filtros(dados['percent'], filtros)
    
    if df.empty:
        st.warning("Nenhum dado encontrado.")
        return
    
    # Panorama Geral
    st.subheader("Panorama Geral")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Total de Grupos", f"{len(df):,}")
    with col2:
        st.metric("Total de CNPJs", f"{int(df['qntd_cnpj'].sum()):,}")
    with col3:
        score_col = 'score_final_ccs' if 'score_final_ccs' in df.columns else 'score_final_avancado'
        st.metric("Score M√©dio", f"{df[score_col].mean():.2f}")
    with col4:
        score_col = 'score_final_ccs' if 'score_final_ccs' in df.columns else 'score_final_avancado'
        st.metric("Grupos Cr√≠ticos", f"{len(df[df[score_col] >= 20]):,}")
    
    # An√°lises gr√°ficas
    st.subheader("An√°lises")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        score_col = 'score_final_ccs' if 'score_final_ccs' in df.columns else 'score_final_avancado'
        fig = px.histogram(df, x=score_col, nbins=20, 
                          title="Distribui√ß√£o de Scores", template=filtros['tema'])
        fig.update_layout(height=300)
        st.plotly_chart(fig)
    
    with col2:
        if 'nivel_risco_grupo_economico' in df.columns:
            dist = df['nivel_risco_grupo_economico'].value_counts()
            fig = px.pie(values=dist.values, names=dist.index, 
                        title="Distribui√ß√£o C115", template=filtros['tema'])
            fig.update_layout(height=300)
            st.plotly_chart(fig)
    
    with col3:
        if not dados['contador'].empty:
            top = dados['contador'].head(10).sort_values('media', ascending=True)
            fig = px.bar(top, x='media', y='nm_contador', orientation='h',
                         title="Top 10 Contadores", template=filtros['tema'])
            fig.update_layout(height=300)
            st.plotly_chart(fig)
    
    # Top grupos cr√≠ticos
    st.subheader("Top 15 Grupos Cr√≠ticos")
    score_col = 'score_final_ccs' if 'score_final_ccs' in df.columns else 'score_final_avancado'
    df_top = df.nlargest(15, score_col).copy()
    
    if 'valor_max' in df_top.columns:
        df_top['Receita'] = df_top['valor_max'].apply(formatar_moeda)
    
    colunas = ['num_grupo', score_col, 'qntd_cnpj',
               'Receita', 'qtd_total_indicios', 'nivel_risco_grupo_economico']
    colunas_exist = [c for c in colunas if c in df_top.columns]

    st.dataframe(df_top[colunas_exist], width='stretch', hide_index=True)

    # =========================================================================
    # IMPACTO FISCAL - GRUPOS DE ALTO RISCO
    # =========================================================================
    st.divider()
    st.subheader("Impacto Fiscal - Grupos de Alto Risco")

    st.info("""
    Esta an√°lise identifica grupos com **score alto** que potencialmente operam de forma fragmentada
    para permanecer no Simples Nacional, evitando a tributa√ß√£o do Regime Normal.
    """)

    # Definir threshold para "alto risco"
    col1, col2 = st.columns(2)
    with col1:
        score_threshold = st.slider(
            "Score m√≠nimo para considerar alto risco:",
            min_value=10.0,
            max_value=50.0,
            value=20.0,
            step=1.0,
            key="score_threshold_impacto"
        )
    with col2:
        receita_min = st.slider(
            "Receita m√≠nima (em milh√µes):",
            min_value=1.0,
            max_value=10.0,
            value=4.8,
            step=0.5,
            key="receita_threshold_impacto"
        ) * 1e6

    # Filtrar grupos de alto risco
    df_alto_risco = df[
        (df[score_col] >= score_threshold) &
        (df['valor_max'] >= receita_min)
    ].copy()

    if df_alto_risco.empty:
        st.warning("Nenhum grupo encontrado com os crit√©rios selecionados.")
    else:
        # M√©tricas principais
        col1, col2, col3, col4 = st.columns(4)

        qtd_grupos_risco = len(df_alto_risco)
        qtd_cnpjs_risco = int(df_alto_risco['qntd_cnpj'].sum())
        soma_faturamento = df_alto_risco['valor_max'].sum()

        # C√°lculo do impacto fiscal estimado - APENAS PARA EMPRESAS DO SIMPLES
        # Diferen√ßa entre Regime Normal e Simples Nacional (ICMS SC)
        # Normal: 17% | Simples: ~10% => Diferen√ßa: 7%
        DIFERENCA_ALIQUOTA = 0.07  # 7% de diferen√ßa

        # Calcular faturamento apenas de empresas no Simples Nacional
        if 'qntd_sn' in df_alto_risco.columns and 'qntd_normal' in df_alto_risco.columns:
            # Propor√ß√£o de empresas no Simples por grupo
            total_cnpjs = df_alto_risco['qntd_sn'].fillna(0) + df_alto_risco['qntd_normal'].fillna(0)
            df_alto_risco['prop_simples'] = df_alto_risco['qntd_sn'].fillna(0) / total_cnpjs.replace(0, 1)
            # Faturamento estimado do Simples = valor_max * propor√ß√£o de empresas no Simples
            df_alto_risco['faturamento_simples'] = df_alto_risco['valor_max'] * df_alto_risco['prop_simples']
            soma_faturamento_simples = df_alto_risco['faturamento_simples'].sum()
            qtd_cnpjs_simples = int(df_alto_risco['qntd_sn'].fillna(0).sum())
        else:
            # Se n√£o tiver a coluna, assume todo faturamento √© do Simples
            soma_faturamento_simples = soma_faturamento
            df_alto_risco['faturamento_simples'] = df_alto_risco['valor_max']
            qtd_cnpjs_simples = qtd_cnpjs_risco

        # Impacto calculado apenas sobre faturamento do Simples Nacional
        impacto_fiscal_estimado = soma_faturamento_simples * DIFERENCA_ALIQUOTA

        with col1:
            st.metric("Grupos de Alto Risco", f"{qtd_grupos_risco:,}")
        with col2:
            st.metric("CNPJs no Simples", f"{qtd_cnpjs_simples:,}")
        with col3:
            st.metric("Faturamento Simples", formatar_moeda(soma_faturamento_simples))
        with col4:
            st.metric("Impacto Fiscal Estimado", formatar_moeda(impacto_fiscal_estimado), delta="potencial n√£o arrecadado")

        st.divider()

        # Detalhamento do c√°lculo
        st.write("**Metodologia do C√°lculo de Impacto Fiscal:**")
        st.markdown(f"""
        - **Simples Nacional:** Al√≠quota m√©dia de **10%**
        - **Regime Normal:** ICMS de **17%** (SC)
        - **Diferen√ßa:** **7%** de tributo n√£o recolhido
        - **F√≥rmula:** Faturamento do Simples √ó 7% = Impacto Estimado

        > **Nota:** O c√°lculo considera apenas o faturamento das empresas do Simples Nacional.
        > Empresas j√° no Regime Normal n√£o s√£o consideradas no impacto.
        """)

        st.divider()

        # Tabela detalhada dos grupos de alto risco
        st.write("**Grupos Identificados:**")

        df_display = df_alto_risco.copy()
        df_display['Faturamento'] = df_display['valor_max'].apply(formatar_moeda)
        df_display['Impacto_Estimado'] = (df_display['valor_max'] * DIFERENCA_ALIQUOTA).apply(formatar_moeda)
        df_display['Acima_Limite_SN'] = df_display['valor_max'].apply(lambda x: 'SIM' if x > 4800000 else 'N√ÉO')

        colunas_exibir = ['num_grupo', score_col, 'qntd_cnpj', 'Faturamento',
                         'Impacto_Estimado', 'Acima_Limite_SN']
        if 'nivel_risco_grupo_economico' in df_display.columns:
            colunas_exibir.append('nivel_risco_grupo_economico')
        if 'nivel_risco_ccs' in df_display.columns:
            colunas_exibir.append('nivel_risco_ccs')

        colunas_exibir = [c for c in colunas_exibir if c in df_display.columns]

        st.dataframe(
            df_display[colunas_exibir].sort_values(score_col, ascending=False),
            width='stretch',
            hide_index=True
        )

        # Gr√°fico de distribui√ß√£o
        col1, col2 = st.columns(2)

        with col1:
            fig = px.histogram(
                df_alto_risco,
                x='valor_max',
                nbins=20,
                title="Distribui√ß√£o de Faturamento - Grupos de Alto Risco",
                template=filtros['tema'],
                labels={'valor_max': 'Faturamento (R$)'}
            )
            st.plotly_chart(fig, use_container_width=True)

        with col2:
            # Top 10 por impacto
            df_top_impacto = df_alto_risco.nlargest(10, 'valor_max').copy()
            df_top_impacto['Impacto'] = df_top_impacto['valor_max'] * DIFERENCA_ALIQUOTA / 1e6

            fig = px.bar(
                df_top_impacto,
                x='num_grupo',
                y='Impacto',
                title="Top 10 Grupos por Impacto Fiscal (em milh√µes)",
                template=filtros['tema'],
                labels={'Impacto': 'Impacto Fiscal (R$ milh√µes)', 'num_grupo': 'Grupo'}
            )
            st.plotly_chart(fig, use_container_width=True)

        # Download
        csv = df_display[colunas_exibir].to_csv(index=False).encode('utf-8')
        st.download_button(
            label="Download Grupos Alto Risco (CSV)",
            data=csv,
            file_name="grupos_alto_risco_impacto_fiscal.csv",
            mime="text/csv"
        )

def ranking_grupos(dados, filtros):
    """P√°gina de ranking de grupos"""
    st.markdown("<h1 class='main-header'>Ranking de Grupos</h1>", unsafe_allow_html=True)
    
    df = aplicar_filtros(dados['percent'], filtros)
    
    if df.empty:
        st.warning("Nenhum dado encontrado.")
        return
    
    # Controles de pagina√ß√£o
    col1, col2 = st.columns(2)
    with col1:
        registros = st.selectbox("Registros/p√°gina", [10, 25, 50, 100], index=1)
    with col2:
        score_col = 'score_final_ccs' if 'score_final_ccs' in df.columns else 'score_final_avancado'
        ordenacao = st.selectbox("Ordenar por", [score_col, 'valor_max', 'qntd_cnpj'])
    
    df_sorted = df.sort_values(ordenacao, ascending=False).reset_index(drop=True)
    df_sorted.insert(0, 'Posi√ß√£o', range(1, len(df_sorted) + 1))
    
    total_pag = max(1, (len(df_sorted) - 1) // registros + 1)
    pag = st.number_input("P√°gina", min_value=1, max_value=total_pag, value=1) - 1
    
    inicio = pag * registros
    fim = min(inicio + registros, len(df_sorted))
    
    df_pag = df_sorted.iloc[inicio:fim].copy()
    
    if 'valor_max' in df_pag.columns:
        df_pag['valor_max'] = df_pag['valor_max'].apply(formatar_moeda)
    
    st.dataframe(df_pag, width='stretch', hide_index=True)
    st.info(f"Mostrando {inicio+1} a {fim} de {len(df_sorted)}")

# ====================================================================================
# FUN√á√ïES PARA O MENU CONTADORES - ADICIONAR AP√ìS AS OUTRAS FUN√á√ïES DE CONSULTA
# ====================================================================================

def listar_contadores():
    """Lista todos os contadores dispon√≠veis para sele√ß√£o"""
    query = """
    SELECT DISTINCT 
        cod_contador,
        contador
    FROM schema.tabela_principal
    WHERE cod_contador IS NOT NULL
    ORDER BY contador
    """
    df = execute_query(query)
    return df

def obter_grupos_contador(cod_contador):
    """Obt√©m todos os grupos econ√¥micos de um contador espec√≠fico"""
    query = f"""
    SELECT DISTINCT
        num_grupo,
        cnpj,
        razao_social,
        nome_fantasia,
        endereco_completo,
        municipio,
        uf,
        cep,
        telefone,
        email,
        data_abertura,
        situacao_cadastral,
        cnae_principal,
        descricao_cnae,
        porte_empresa,
        score_geral,
        score_regularidade,
        score_movimentacao,
        score_consistencia
    FROM schema.tabela_principal
    WHERE cod_contador = {cod_contador}
    ORDER BY num_grupo, razao_social
    """
    df = execute_query(query)
    return df

def analisar_riscos_contador(cod_contador):
    """Gera insights sobre os riscos dos grupos de um contador"""
    
    # Query para an√°lise de categorias de risco
    query_categorias = f"""
    SELECT 
        categoria_risco,
        COUNT(DISTINCT num_grupo) as qtd_grupos,
        ROUND(AVG(score_geral), 2) as score_medio,
        COUNT(*) as total_empresas
    FROM schema.tabela_principal
    WHERE cod_contador = {cod_contador}
    GROUP BY categoria_risco
    ORDER BY qtd_grupos DESC
    """
    
    # Query para an√°lise de CNAEs mais comuns
    query_cnaes = f"""
    SELECT 
        cnae_principal,
        descricao_cnae,
        COUNT(DISTINCT num_grupo) as qtd_grupos,
        COUNT(*) as qtd_empresas,
        ROUND(AVG(score_geral), 2) as score_medio
    FROM schema.tabela_principal
    WHERE cod_contador = {cod_contador}
    GROUP BY cnae_principal, descricao_cnae
    ORDER BY qtd_grupos DESC
    LIMIT 10
    """
    
    # Query para an√°lise de pr√°ticas recorrentes
    query_praticas = f"""
    SELECT 
        pratica_identificada,
        COUNT(DISTINCT num_grupo) as qtd_grupos,
        ROUND(AVG(score_geral), 2) as score_medio,
        COUNT(*) as total_ocorrencias
    FROM schema.tabela_praticas
    WHERE cod_contador = {cod_contador}
    GROUP BY pratica_identificada
    ORDER BY qtd_grupos DESC
    LIMIT 10
    """
    
    df_categorias = execute_query(query_categorias)
    df_cnaes = execute_query(query_cnaes)
    df_praticas = execute_query(query_praticas)
    
    return df_categorias, df_cnaes, df_praticas

def get_grupos_por_contador(engine, nm_contador):
    """
    Obt√©m os grupos econ√¥micos vinculados a um contador espec√≠fico.
    """
    query = """
    SELECT DISTINCT 
        g.num_grupo, 
        g.cnpj, 
        c.nm_razao_social, 
        c.nm_fantasia, 
        CONCAT_WS(', ', c.nm_logradouro, c.nu_logradouro, c.tx_complemento, c.nm_bairro) as endereco,
        c.cd_cnae, 
        c.nm_munic as nm_municipio, 
        c.cd_uf as sg_uf, 
        c.cd_cep as nu_cep,
        c.cd_sit_cadastral, 
        c.dt_sit_cadastral, 
        p.score_final_ccs, 
        p.score_final_avancado, 
        p.score_final_completo, 
        p.nivel_risco_ccs, 
        p.indice_interconexao, 
        p.indice_risco_indicios, 
        p.indice_risco_pagamentos, 
        p.indice_risco_fat_func, 
        p.indice_risco_ccs, 
        p.qntd_cnpj, 
        p.valor_max, 
        p.total_funcionarios 
    FROM gessimples.gei_cnpj g 
    JOIN gessimples.gei_cadastro c ON g.cnpj = c.nu_cnpj 
    LEFT JOIN gessimples.gei_percent p ON CAST(g.num_grupo AS STRING) = CAST(p.num_grupo AS STRING) 
    WHERE c.nm_contador = '{}'
    ORDER BY p.score_final_ccs DESC NULLS LAST
    """.format(nm_contador)
    
    return pd.read_sql(query, engine)

def analisar_riscos_contador(engine, nm_contador):
    """
    Analisa os riscos e padr√µes dos grupos econ√¥micos de um contador.
    """
    query = """
    WITH grupos_contador AS (
        SELECT DISTINCT 
            g.num_grupo, 
            g.cnpj, 
            c.cd_cnae,
            SUBSTR(CAST(c.cd_cnae AS STRING), 1, 2) AS secao_cnae,
            p.score_final_ccs, 
            p.nivel_risco_ccs, 
            p.indice_interconexao, 
            p.indice_risco_indicios, 
            p.indice_risco_ccs, 
            p.qntd_cnpj
        FROM gessimples.gei_cnpj g 
        JOIN gessimples.gei_cadastro c ON g.cnpj = c.nu_cnpj 
        LEFT JOIN gessimples.gei_percent p ON CAST(g.num_grupo AS STRING) = CAST(p.num_grupo AS STRING) 
        WHERE c.nm_contador = '{}'
    ),
    metricas_cnae AS (
        SELECT 
            secao_cnae, 
            COUNT(DISTINCT num_grupo) AS qtd_grupos, 
            ROUND(AVG(score_final_ccs), 2) AS media_score, 
            ROUND(AVG(indice_risco_ccs), 2) AS media_risco_ccs, 
            SUM(qntd_cnpj) AS total_cnpjs
        FROM grupos_contador 
        WHERE secao_cnae IS NOT NULL 
        GROUP BY secao_cnae
    ),
    praticas_concorrentes AS (
        SELECT 
            secao_cnae, 
            COUNT(DISTINCT num_grupo) AS grupos_mesma_secao, 
            ROUND(AVG(indice_interconexao), 4) AS media_interconexao
        FROM grupos_contador 
        WHERE secao_cnae IS NOT NULL 
        GROUP BY secao_cnae 
        HAVING COUNT(DISTINCT num_grupo) > 1
    )
    SELECT 
        m.*, 
        pc.grupos_mesma_secao, 
        pc.media_interconexao
    FROM metricas_cnae m 
    LEFT JOIN praticas_concorrentes pc ON m.secao_cnae = pc.secao_cnae 
    ORDER BY m.media_score DESC
    """.format(nm_contador)
    
    return pd.read_sql(query, engine)

def get_distribuicao_niveis_risco(engine, nm_contador):
    """Retorna distribui√ß√£o dos n√≠veis de risco CCS dos grupos do contador"""
    query = f"""
    SELECT 
        COALESCE(p.nivel_risco_ccs, 'SEM DADOS') AS nivel_risco,
        COUNT(DISTINCT g.num_grupo) AS qtd_grupos,
        ROUND(AVG(p.score_final_ccs), 2) AS score_medio
    FROM gessimples.gei_cnpj g
    JOIN gessimples.gei_cadastro c ON g.cnpj = c.nu_cnpj
    LEFT JOIN gessimples.gei_percent p ON CAST(g.num_grupo AS STRING) = CAST(p.num_grupo AS STRING)
    WHERE c.nm_contador = '{nm_contador}'
    GROUP BY p.nivel_risco_ccs
    ORDER BY score_medio DESC NULLS LAST
    """
    return pd.read_sql(query, engine)

def renderizar_detalhe_contador(engine, nm_contador, nm_gerfe, filtros):
    """Renderiza a p√°gina detalhada de um contador espec√≠fico"""
    st.markdown(f"<h1 class='main-header'>üìä An√°lise Detalhada: {nm_contador}</h1>", unsafe_allow_html=True)
    st.caption(f"Unidade Fiscal: {nm_gerfe}")
    
    # Buscar dados
    with st.spinner("Carregando grupos econ√¥micos..."):
        df_grupos = get_grupos_por_contador(engine, nm_contador)
        df_insights = analisar_riscos_contador(engine, nm_contador)
        df_niveis = get_distribuicao_niveis_risco(engine, nm_contador)
    
    if df_grupos.empty:
        st.warning("Nenhum grupo econ√¥mico encontrado para este contador.")
        return
    
    # M√©tricas gerais
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("Total de Grupos", len(df_grupos['num_grupo'].unique()))
    with col2:
        st.metric("Score M√©dio CCS", f"{df_grupos['score_final_ccs'].mean():.2f}")
    with col3:
        st.metric("Total de CNPJs", int(df_grupos['qntd_cnpj'].sum()))
    with col4:
        alto_risco = len(df_grupos[df_grupos['nivel_risco_ccs'].isin(['CR√çTICO', 'ALTO'])])
        st.metric("Grupos Alto Risco", alto_risco)
    
    # Distribui√ß√£o de n√≠veis de risco
    st.subheader("üìà Distribui√ß√£o de N√≠veis de Risco")
    if not df_niveis.empty:
        col1, col2 = st.columns([2, 1])
        with col1:
            fig_niveis = px.bar(df_niveis, 
                               x='nivel_risco', 
                               y='qtd_grupos',
                               title='Grupos por N√≠vel de Risco CCS',
                               color='score_medio',
                               template=filtros['tema'],
                               color_continuous_scale='RdYlGn_r')
            st.plotly_chart(fig_niveis, use_container_width=True)
        with col2:
            st.dataframe(df_niveis, use_container_width=True, hide_index=True)
    
    # Insights por categoria
    st.subheader("üéØ Insights por Categoria (CNAE)")
    if not df_insights.empty:
        # Adicionar descri√ß√µes de se√ß√£o CNAE
        secoes_cnae = {
            '01': 'Agricultura', '02': 'Pecu√°ria', '03': 'Pesca',
            '05': 'Minera√ß√£o', '10': 'Alimentos', '11': 'Bebidas',
            '13': 'T√™xtil', '14': 'Vestu√°rio', '15': 'Couro',
            '16': 'Madeira', '17': 'Papel', '18': 'Impress√£o',
            '19': 'Petr√≥leo', '20': 'Qu√≠mica', '21': 'Farmac√™utica',
            '22': 'Borracha', '23': 'Minerais', '24': 'Metalurgia',
            '25': 'Metal', '26': 'Eletr√¥nicos', '27': 'El√©tricos',
            '28': 'M√°quinas', '29': 'Ve√≠culos', '30': 'Transporte',
            '31': 'M√≥veis', '32': 'Produtos Diversos', '33': 'Manuten√ß√£o',
            '35': 'Energia', '36': '√Ågua', '37': 'Esgoto',
            '41': 'Constru√ß√£o', '42': 'Constru√ß√£o', '43': 'Constru√ß√£o',
            '45': 'Com√©rcio Ve√≠culos', '46': 'Com√©rcio Atacado', '47': 'Com√©rcio Varejo',
            '49': 'Transporte', '50': 'Transporte', '51': 'Transporte',
            '52': 'Armazenamento', '53': 'Correio', '55': 'Alojamento',
            '56': 'Alimenta√ß√£o', '58': 'Edi√ß√£o', '59': 'Cinema',
            '60': 'TV', '61': 'Telecomunica√ß√µes', '62': 'TI',
            '63': 'Informa√ß√£o', '64': 'Financeiro', '65': 'Seguros',
            '66': 'Financeiro', '68': 'Imobili√°rio', '69': 'Jur√≠dico',
            '70': 'Consultoria', '71': 'Arquitetura', '72': 'Pesquisa',
            '73': 'Publicidade', '74': 'Design', '75': 'Veterin√°rio',
            '77': 'Aluguel', '78': 'Emprego', '79': 'Turismo',
            '80': 'Seguran√ßa', '81': 'Limpeza', '82': 'Administrativo',
            '84': 'P√∫blico', '85': 'Educa√ß√£o', '86': 'Sa√∫de',
            '87': 'Social', '88': 'Social', '90': 'Artes',
            '91': 'Cultura', '92': 'Jogos', '93': 'Esportes',
            '94': 'Organiza√ß√µes', '95': 'Repara√ß√£o', '96': 'Servi√ßos',
            '97': 'Dom√©sticos', '99': 'Organismos'
        }
        
        df_insights['descricao_cnae'] = df_insights['secao_cnae'].map(secoes_cnae)
        df_insights['categoria'] = df_insights['secao_cnae'] + ' - ' + df_insights['descricao_cnae'].fillna('Outros')
        
        # Categorias com maior risco
        st.markdown("**üî¥ Categorias com Maior Risco M√©dio:**")
        top_riscos = df_insights.nlargest(5, 'media_score')[['categoria', 'qtd_grupos', 'media_score', 'media_risco_ccs', 'total_cnpjs']]
        top_riscos.columns = ['Categoria', 'Qtd Grupos', 'Score M√©dio', 'Risco CCS M√©dio', 'Total CNPJs']
        st.dataframe(top_riscos, use_container_width=True, hide_index=True)
        
        # Pr√°ticas concorrentes
        st.markdown("**‚ö†Ô∏è Categorias com Maior Concorr√™ncia (Grupos na mesma se√ß√£o CNAE):**")
        concorrentes = df_insights[df_insights['grupos_mesma_secao'].notna()].nlargest(5, 'grupos_mesma_secao')
        if not concorrentes.empty:
            concorrentes_view = concorrentes[['categoria', 'grupos_mesma_secao', 'media_interconexao', 'media_score']]
            concorrentes_view.columns = ['Categoria', 'Grupos Concorrentes', '√çndice Interconex√£o', 'Score M√©dio']
            st.dataframe(concorrentes_view, use_container_width=True, hide_index=True)
            
            st.info(f"""
            üí° **Insight:** O contador possui {int(concorrentes['grupos_mesma_secao'].max())} grupos atuando 
            na mesma categoria ({concorrentes.iloc[0]['categoria']}), com √≠ndice de interconex√£o de 
            {concorrentes.iloc[0]['media_interconexao']:.4f}. Isso pode indicar especializa√ß√£o ou 
            poss√≠vel relacionamento entre empresas concorrentes.
            """)
    
    # Tabela principal de grupos
    st.subheader("üìã Grupos Econ√¥micos")
    
    # Filtros
    col1, col2, col3 = st.columns(3)
    with col1:
        filtro_risco = st.multiselect(
            "Filtrar por N√≠vel de Risco CCS",
            options=df_grupos['nivel_risco_ccs'].unique(),
            default=None
        )
    with col2:
        score_min = st.number_input("Score CCS M√≠nimo", 
                                     min_value=0.0, 
                                     max_value=float(df_grupos['score_final_ccs'].max()),
                                     value=0.0)
    with col3:
        filtro_cnae = st.text_input("Filtrar por CNAE (primeiros d√≠gitos)")
    
    # Aplicar filtros
    df_filtrado = df_grupos.copy()
    if filtro_risco:
        df_filtrado = df_filtrado[df_filtrado['nivel_risco_ccs'].isin(filtro_risco)]
    if score_min > 0:
        df_filtrado = df_filtrado[df_filtrado['score_final_ccs'] >= score_min]
    if filtro_cnae:
        df_filtrado = df_filtrado[df_filtrado['cd_cnae'].str.startswith(filtro_cnae, na=False)]
    
    # Preparar dataframe para exibi√ß√£o
    df_display = df_filtrado[[
        'num_grupo', 'cnpj', 'nm_razao_social', 'nm_fantasia', 
        'endereco', 'cd_cnae', 'nm_municipio', 'sg_uf',
        'score_final_ccs', 'nivel_risco_ccs', 'qntd_cnpj',
        'indice_risco_ccs', 'valor_max'
    ]].copy()
    
    df_display.columns = [
        'Grupo', 'CNPJ', 'Raz√£o Social', 'Nome Fantasia',
        'Endere√ßo', 'CNAE', 'Munic√≠pio', 'UF',
        'Score CCS', 'N√≠vel Risco', 'Qtd CNPJs',
        '√çndice CCS', 'Faturamento M√°x'
    ]
    
    # Formatar valores
    df_display['Score CCS'] = df_display['Score CCS'].apply(lambda x: f"{x:.2f}" if pd.notna(x) else "-")
    df_display['√çndice CCS'] = df_display['√çndice CCS'].apply(lambda x: f"{x:.4f}" if pd.notna(x) else "-")
    df_display['Faturamento M√°x'] = df_display['Faturamento M√°x'].apply(
        lambda x: f"R$ {x:,.2f}" if pd.notna(x) else "-"
    )
    
    st.dataframe(df_display, use_container_width=True, hide_index=True)
    
    # Download
    csv = df_display.to_csv(index=False).encode('utf-8-sig')
    st.download_button(
        label="üì• Baixar dados em CSV",
        data=csv,
        file_name=f"grupos_{nm_contador.replace(' ', '_')}.csv",
        mime="text/csv"
    )

def menu_contadores(engine, dados, filtros):
    """An√°lise de contadores"""
    
    # Verificar se h√° um contador selecionado na sess√£o
    if 'contador_selecionado' not in st.session_state:
        st.session_state.contador_selecionado = None
    
    # Bot√£o para voltar (se estiver em detalhe)
    if st.session_state.contador_selecionado:
        if st.button("‚¨ÖÔ∏è Voltar para lista de contadores"):
            st.session_state.contador_selecionado = None
            st.rerun()
        
        # Renderizar detalhe do contador
        contador_info = st.session_state.contador_selecionado
        renderizar_detalhe_contador(engine, contador_info['nm_contador'], contador_info['nm_gerfe'], filtros)
        return
    
    # Lista de contadores (c√≥digo original mantido)
    st.markdown("<h1 class='main-header'>An√°lise de Contadores</h1>", unsafe_allow_html=True)
    
    if dados['contador'].empty:
        st.warning("Nenhum dado de contador dispon√≠vel.")
        return
    
    df_cont = dados['contador'].copy()
    
    # Panorama Geral
    st.subheader("Panorama Geral")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Total Contadores", len(df_cont))
    with col2:
        st.metric("M√©dia Score", f"{df_cont['media'].mean():.2f}")
    with col3:
        st.metric("Total Grupos", int(df_cont['qntd_grupos'].sum()))
    with col4:
        st.metric("GERFEs Distintas", df_cont['nm_gerfe'].nunique())
    
    # Top Contadores por Risco
    st.subheader("Top 20 Contadores por Score M√©dio")
    top_20 = df_cont.nlargest(20, 'media')
    
    fig = px.bar(top_20, x='media', y='nm_contador', orientation='h',
                title="Score M√©dio dos Grupos por Contador",
                template=filtros['tema'],
                hover_data=['qntd_grupos', 'nm_gerfe'])
    st.plotly_chart(fig, use_container_width=True)
    
    # Tabela Detalhada com bot√µes
    st.subheader("Detalhamento Completo")
    
    # Filtros
    col1, col2, col3 = st.columns(3)
    with col1:
        min_grupos = st.number_input("M√≠nimo de Grupos", min_value=1, value=3)
    with col2:
        min_score = st.number_input("Score M√©dio M√≠nimo", min_value=0.0, value=5.0, step=0.5)
    with col3:
        search_contador = st.text_input("Buscar contador")
    
    df_filtrado = df_cont[
        (df_cont['qntd_grupos'] >= min_grupos) &
        (df_cont['media'] >= min_score)
    ].sort_values('media', ascending=False)
    
    if search_contador:
        df_filtrado = df_filtrado[
            df_filtrado['nm_contador'].str.contains(search_contador, case=False, na=False)
        ]
    
    # Exibir com bot√µes de a√ß√£o
    st.write(f"**{len(df_filtrado)} contadores encontrados**")
    
    for idx, row in df_filtrado.iterrows():
        col1, col2, col3, col4, col5 = st.columns([3, 2, 1, 1, 1])
        with col1:
            st.write(f"**{row['nm_contador']}**")
        with col2:
            st.write(row['nm_gerfe'])
        with col3:
            st.metric("Grupos", int(row['qntd_grupos']), label_visibility="collapsed")
        with col4:
            st.metric("Score", f"{row['media']:.2f}", label_visibility="collapsed")
        with col5:
            if st.button("üìä Detalhes", key=f"btn_{idx}"):
                st.session_state.contador_selecionado = {
                    'nm_contador': row['nm_contador'],
                    'nm_gerfe': row['nm_gerfe']
                }
                st.rerun()
    
    # Download
    csv = df_filtrado.to_csv(index=False).encode('utf-8-sig')
    st.download_button(
        label="üì• Download CSV",
        data=csv,
        file_name="contadores_analise.csv",
        mime="text/csv"
    )
            
def menu_pagamentos(engine, dados, filtros):
    """An√°lise de meios de pagamento"""
    st.markdown("<h1 class='main-header'>An√°lise de Meios de Pagamento</h1>", unsafe_allow_html=True)
    
    if dados['pagamentos_metricas'].empty:
        st.warning("Nenhum dado de pagamento dispon√≠vel.")
        return
    
    # Merge com percent para ter scores
    score_col = 'score_final_ccs' if 'score_final_ccs' in dados['percent'].columns else 'score_final_avancado'
    df_pag = dados['pagamentos_metricas'].merge(
        dados['percent'][['num_grupo', score_col, 'qntd_cnpj', 'indice_risco_pagamentos']],
        on='num_grupo',
        how='left'
    )
    
    # Limpar valores NaN para os gr√°ficos
    df_pag = df_pag.dropna(subset=[score_col, 'indice_risco_pagamentos', 'qntd_cnpj'])
    
    # Panorama Geral
    st.subheader("Panorama Geral")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Grupos com Dados", len(df_pag))
    with col2:
        total_empresas = df_pag['valor_meios_pagamento_empresas'].sum()
        st.metric("Total Empresas", formatar_moeda(total_empresas))
    with col3:
        total_socios = df_pag['valor_meios_pagamento_socios'].sum()
        st.metric("Total S√≥cios", formatar_moeda(total_socios))
    with col4:
        media_risco = df_pag['indice_risco_pagamentos'].mean()
        st.metric("√çndice Risco M√©dio", f"{media_risco:.3f}")
    
    # Gr√°ficos
    col1, col2 = st.columns(2)
    
    with col1:
        # Distribui√ß√£o do √≠ndice de risco
        fig = px.histogram(df_pag, x='indice_risco_pagamentos', nbins=30,
                          title="Distribui√ß√£o do √çndice de Risco Pagamentos",
                          template=filtros['tema'])
        st.plotly_chart(fig)
    
    with col2:
        # Scatter: Score vs Risco Pagamentos
        fig = px.scatter(df_pag, x=score_col, y='indice_risco_pagamentos',
                        hover_data=['num_grupo', 'qntd_cnpj'],
                        title="Score Total vs Risco Pagamentos",
                        template=filtros['tema'])
        st.plotly_chart(fig)
    
    # Top grupos por risco de confus√£o patrimonial
    st.subheader("Top 20 Grupos - Maior Risco de Confus√£o Patrimonial")
    
    df_top = df_pag[df_pag['valor_meios_pagamento_empresas'] > 0].nlargest(20, 'indice_risco_pagamentos').copy()
    df_top['Valor Empresas'] = df_top['valor_meios_pagamento_empresas'].apply(formatar_moeda)
    df_top['Valor S√≥cios'] = df_top['valor_meios_pagamento_socios'].apply(formatar_moeda)
    
    st.dataframe(df_top[['num_grupo', 'indice_risco_pagamentos', 'Valor Empresas', 'Valor S√≥cios',
                         'qntd_cnpj', score_col]],
                width='stretch', hide_index=True)

    # =========================================================================
    # DRILL DOWN POR GRUPO
    # =========================================================================
    st.divider()
    st.subheader("Detalhes por Grupo")

    grupo_selecionado = st.selectbox(
        "Selecione um grupo para ver detalhes:",
        options=['Selecione...'] + sorted(df_pag['num_grupo'].unique().tolist()),
        key="pagamentos_drill_down"
    )

    if grupo_selecionado and grupo_selecionado != 'Selecione...':
        info_grupo = df_pag[df_pag['num_grupo'] == grupo_selecionado].iloc[0]

        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("Grupo", grupo_selecionado)
        with col2:
            st.metric("CNPJs", int(info_grupo['qntd_cnpj']))
        with col3:
            st.metric("Valor Empresas", formatar_moeda(info_grupo['valor_meios_pagamento_empresas']))
        with col4:
            st.metric("Valor S√≥cios", formatar_moeda(info_grupo['valor_meios_pagamento_socios']))

        st.write(f"**√çndice de Risco Pagamentos:** {info_grupo['indice_risco_pagamentos']:.4f}")
        st.write(f"**Score Final:** {info_grupo[score_col]:.2f}")

        # Buscar detalhes dos CNPJs do grupo
        try:
            cnpjs_grupo = dados['cnpj'][dados['cnpj']['num_grupo'] == grupo_selecionado]['cnpj'].tolist()
            if cnpjs_grupo:
                st.write(f"**CNPJs do grupo:** {', '.join(cnpjs_grupo[:10])}{'...' if len(cnpjs_grupo) > 10 else ''}")
        except:
            pass

def menu_funcionarios(engine, dados, filtros):
    """An√°lise de funcion√°rios"""
    st.markdown("<h1 class='main-header'>An√°lise de Funcion√°rios</h1>", unsafe_allow_html=True)
    
    if dados['funcionarios_metricas'].empty:
        st.warning("Nenhum dado de funcion√°rios dispon√≠vel.")
        return
    
    # Merge com percent
    score_col = 'score_final_ccs' if 'score_final_ccs' in dados['percent'].columns else 'score_final_avancado'
    df_func = dados['funcionarios_metricas'].merge(
        dados['percent'][['num_grupo', score_col, 'qntd_cnpj', 'valor_max', 'indice_risco_fat_func']],
        on='num_grupo',
        how='left'
    )
    
    # Limpar valores NaN para os gr√°ficos
    df_func = df_func.dropna(subset=[score_col, 'total_funcionarios', 'valor_max'])
    
    # Panorama Geral
    st.subheader("Panorama Geral")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Grupos com Dados", len(df_func))
    with col2:
        st.metric("Total Funcion√°rios", f"{int(df_func['total_funcionarios'].sum()):,}")
    with col3:
        media_func = df_func['total_funcionarios'].mean()
        st.metric("M√©dia Funcion√°rios/Grupo", f"{media_func:.1f}")
    with col4:
        if 'indice_risco_fat_func' in df_func.columns:
            media_risco = df_func['indice_risco_fat_func'].mean()
            st.metric("√çndice Risco M√©dio", f"{media_risco:.3f}")
    
    # Gr√°ficos
    col1, col2 = st.columns(2)
    
    with col1:
        # Distribui√ß√£o de funcion√°rios
        fig = px.histogram(df_func, x='total_funcionarios', nbins=30,
                          title="Distribui√ß√£o de Funcion√°rios por Grupo",
                          template=filtros['tema'])
        st.plotly_chart(fig)
    
    with col2:
        # Scatter: Faturamento vs Funcion√°rios
        fig = px.scatter(df_func, x='total_funcionarios', y='valor_max',
                        hover_data=['num_grupo', 'qntd_cnpj'],
                        title="Faturamento vs Funcion√°rios",
                        template=filtros['tema'],
                        labels={'valor_max': 'Faturamento', 'total_funcionarios': 'Funcion√°rios'})
        st.plotly_chart(fig)
    
    # Top grupos com maior despropor√ß√£o
    st.subheader("Top 20 Grupos - Alta Receita / Poucos Funcion√°rios")
    
    if 'indice_risco_fat_func' in df_func.columns:
        df_top = df_func[
            (df_func['valor_max'] > 1000000) & 
            (df_func['total_funcionarios'] <= 10)
        ].nlargest(20, 'indice_risco_fat_func').copy()
        
        df_top['Faturamento'] = df_top['valor_max'].apply(formatar_moeda)
        
        st.dataframe(df_top[['num_grupo', 'indice_risco_fat_func', 'Faturamento', 
                             'total_funcionarios', 'qntd_cnpj', score_col]], 
                    width='stretch', hide_index=True)
    else:
        # Fallback se n√£o tiver o √≠ndice
        df_top = df_func[
            (df_func['valor_max'] > 1000000) & 
            (df_func['total_funcionarios'] <= 10)
        ].nlargest(20, 'valor_max').copy()
        
        df_top['Faturamento'] = df_top['valor_max'].apply(formatar_moeda)
        df_top['Receita_por_Funcionario'] = df_top['valor_max'] / df_top['total_funcionarios']
        
        st.dataframe(df_top[['num_grupo', 'Faturamento', 'total_funcionarios',
                             'Receita_por_Funcionario', 'qntd_cnpj', score_col]],
                    width='stretch', hide_index=True)

    # =========================================================================
    # DRILL DOWN POR GRUPO
    # =========================================================================
    st.divider()
    st.subheader("Detalhes por Grupo")

    grupo_selecionado = st.selectbox(
        "Selecione um grupo para ver detalhes:",
        options=['Selecione...'] + sorted(df_func['num_grupo'].unique().tolist()),
        key="funcionarios_drill_down"
    )

    if grupo_selecionado and grupo_selecionado != 'Selecione...':
        info_grupo = df_func[df_func['num_grupo'] == grupo_selecionado].iloc[0]

        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("Grupo", grupo_selecionado)
        with col2:
            st.metric("CNPJs", int(info_grupo['qntd_cnpj']))
        with col3:
            st.metric("Total Funcion√°rios", int(info_grupo['total_funcionarios']))
        with col4:
            st.metric("Faturamento", formatar_moeda(info_grupo['valor_max']))

        if 'indice_risco_fat_func' in info_grupo:
            st.write(f"**√çndice de Risco Fat/Func:** {info_grupo['indice_risco_fat_func']:.4f}")
        st.write(f"**Score Final:** {info_grupo[score_col]:.2f}")

        # C√°lculo de receita por funcion√°rio
        if info_grupo['total_funcionarios'] > 0:
            receita_por_func = info_grupo['valor_max'] / info_grupo['total_funcionarios']
            st.write(f"**Receita por Funcion√°rio:** {formatar_moeda(receita_por_func)}")

def menu_c115(engine, dados, filtros):
    """An√°lise Conv√™nio 115"""
    st.markdown("<h1 class='main-header'>An√°lise Conv√™nio 115</h1>", unsafe_allow_html=True)
    
    if dados['c115_ranking'].empty:
        st.warning("Nenhum dado C115 dispon√≠vel.")
        return
    
    df_c115 = dados['c115_ranking'].copy()
    
    # Panorama Geral
    st.subheader("Panorama Geral")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Grupos Monitorados", len(df_c115))
    with col2:
        criticos = len(df_c115[df_c115['nivel_risco_grupo_economico'] == 'CR√çTICO'])
        st.metric("Grupos Cr√≠ticos", criticos)
    with col3:
        media_indice = df_c115['indice_risco_grupo_economico'].mean()
        st.metric("√çndice Risco M√©dio", f"{media_indice:.2f}")
    with col4:
        total_tomadores = df_c115['total_tomadores'].sum()
        st.metric("Total Tomadores", f"{int(total_tomadores):,}")
    
    # Distribui√ß√£o por N√≠vel de Risco
    st.subheader("Distribui√ß√£o por N√≠vel de Risco")
    
    col1, col2 = st.columns(2)
    
    with col1:
        dist_risco = df_c115['nivel_risco_grupo_economico'].value_counts()
        fig = px.pie(values=dist_risco.values, names=dist_risco.index,
                    title="Distribui√ß√£o de Grupos por N√≠vel de Risco C115",
                    template=filtros['tema'])
        st.plotly_chart(fig)
    
    with col2:
        fig = px.histogram(df_c115, x='indice_risco_grupo_economico', nbins=30,
                          title="Distribui√ß√£o do √çndice de Risco",
                          template=filtros['tema'])
        st.plotly_chart(fig)
    
    # Top 30 Grupos por Risco C115
    st.subheader("Top 30 Grupos - Maior Risco C115")
    
    df_top = df_c115.nlargest(30, 'indice_risco_grupo_economico')
    
    st.dataframe(df_top[['num_grupo', 'ranking_risco', 'nivel_risco_grupo_economico',
                         'indice_risco_grupo_economico', 'total_cnpjs', 'qtd_cnpjs_relacionados',
                         'perc_cnpjs_relacionados', 'pares_com_tres_tipos_comum']], 
                width='stretch', hide_index=True)
    
    # An√°lise Detalhada
    st.subheader("An√°lise Detalhada por Grupo")
    
    grupos_disponiveis = sorted(df_c115['num_grupo'].unique())
    grupo_selecionado = st.selectbox("Selecione um grupo:", grupos_disponiveis, key="c115_grupo")
    
    if grupo_selecionado:
        info = df_c115[df_c115['num_grupo'] == grupo_selecionado].iloc[0]
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("Ranking", int(info['ranking_risco']))
        with col2:
            st.metric("N√≠vel Risco", info['nivel_risco_grupo_economico'])
        with col3:
            st.metric("√çndice Risco", f"{info['indice_risco_grupo_economico']:.2f}")
        with col4:
            st.metric("CNPJs Relacionados", int(info['qtd_cnpjs_relacionados']))

def menu_ccs(engine, dados, filtros):
    """An√°lise de Procura√ß√£o Banc√°ria (CCS)"""
    st.markdown("<h1 class='main-header'>Procura√ß√£o Banc√°ria (CCS)</h1>", unsafe_allow_html=True)
    
    st.info("An√°lise de contas banc√°rias compartilhadas entre CNPJs do mesmo grupo econ√¥mico.")
    
    if dados['ccs_metricas'].empty:
        st.warning("Nenhum dado CCS dispon√≠vel.")
        return
    
    # Merge com percent para ter scores E nivel_risco_ccs
    score_col = 'score_final_ccs' if 'score_final_ccs' in dados['percent'].columns else 'score_final_avancado'
    
    # Incluir nivel_risco_ccs no merge
    colunas_merge = ['num_grupo', score_col, 'qntd_cnpj']
    if 'nivel_risco_ccs' in dados['percent'].columns:
        colunas_merge.append('nivel_risco_ccs')
    
    df_ccs = dados['ccs_metricas'].merge(
        dados['percent'][colunas_merge],
        on='num_grupo',
        how='left'
    )
    
    # Panorama Geral
    st.subheader("Panorama Geral")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Grupos com Dados CCS", len(df_ccs))
    with col2:
        grupos_compartilhamento = len(df_ccs[df_ccs['qtd_contas_compartilhadas'] > 0])
        st.metric("Grupos com Compartilhamento", grupos_compartilhamento)
    with col3:
        total_compartilhadas = df_ccs['qtd_contas_compartilhadas'].sum()
        st.metric("Total Contas Compartilhadas", int(total_compartilhadas))
    with col4:
        media_indice = df_ccs['indice_risco_ccs'].mean()
        st.metric("√çndice Risco CCS M√©dio", f"{media_indice:.4f}")
    
    # Gr√°ficos
    st.subheader("An√°lises Visuais")
    col1, col2 = st.columns(2)
    
    with col1:
        # Distribui√ß√£o do √≠ndice de risco CCS
        fig = px.histogram(df_ccs, x='indice_risco_ccs', nbins=30,
                          title="Distribui√ß√£o do √çndice de Risco CCS",
                          template=filtros['tema'])
        st.plotly_chart(fig)
    
    with col2:
        # Distribui√ß√£o por n√≠vel de risco
        if 'nivel_risco_ccs' in df_ccs.columns:
            dist_nivel = df_ccs['nivel_risco_ccs'].value_counts()
            fig = px.pie(values=dist_nivel.values, names=dist_nivel.index,
                        title="Distribui√ß√£o por N√≠vel de Risco CCS",
                        template=filtros['tema'])
            st.plotly_chart(fig)
    
    # An√°lise de Compartilhamento
    st.subheader("An√°lise de Compartilhamento de Contas")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # Scatter: Contas compartilhadas vs Score
        fig = px.scatter(df_ccs, x='qtd_contas_compartilhadas', y=score_col,
                        hover_data=['num_grupo', 'qntd_cnpj'],
                        title="Contas Compartilhadas vs Score Total",
                        template=filtros['tema'])
        st.plotly_chart(fig)
    
    with col2:
        # Max CNPJs por conta
        fig = px.histogram(df_ccs, x='max_cnpjs_por_conta', nbins=20,
                          title="Distribui√ß√£o - M√°x CNPJs por Conta",
                          template=filtros['tema'])
        st.plotly_chart(fig)
    
    # Top Grupos por Risco CCS
    st.subheader("Top 30 Grupos - Maior Risco CCS")
    
    df_top = df_ccs[df_ccs['qtd_contas_compartilhadas'] > 0].nlargest(30, 'indice_risco_ccs')
    
    # Montar lista de colunas dinamicamente
    colunas_exibir = ['num_grupo', 'indice_risco_ccs']
    if 'nivel_risco_ccs' in df_top.columns:
        colunas_exibir.append('nivel_risco_ccs')
    colunas_exibir.extend(['qtd_contas_compartilhadas', 'perc_contas_compartilhadas',
                          'max_cnpjs_por_conta', 'qtd_sobreposicoes_responsaveis',
                          'media_dias_sobreposicao', 'qntd_cnpj', score_col])
    
    st.dataframe(df_top[colunas_exibir])
    
    # An√°lise Detalhada por Grupo
    st.subheader("An√°lise Detalhada por Grupo")
    
    grupos_disponiveis = sorted(df_ccs['num_grupo'].unique())
    grupo_selecionado = st.selectbox("Selecione um grupo para an√°lise detalhada:", 
                                     grupos_disponiveis, key="ccs_grupo_detalhe")
    
    if grupo_selecionado:
        info_grupo = df_ccs[df_ccs['num_grupo'] == grupo_selecionado].iloc[0]
        
        st.write("### M√©tricas do Grupo")
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("√çndice Risco CCS", f"{info_grupo['indice_risco_ccs']:.4f}")
        with col2:
            st.metric("N√≠vel Risco", info_grupo.get('nivel_risco_ccs', 'N/A'))
        with col3:
            st.metric("Contas Compartilhadas", int(info_grupo['qtd_contas_compartilhadas']))
        with col4:
            st.metric("Max CNPJs/Conta", int(info_grupo['max_cnpjs_por_conta']))
        
        st.divider()
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Sobreposi√ß√µes", int(info_grupo['qtd_sobreposicoes_responsaveis']))
        with col2:
            st.metric("M√©dia Dias Sobreposi√ß√£o", f"{info_grupo['media_dias_sobreposicao']:.0f}")
        with col3:
            st.metric("Aberturas Coordenadas", int(info_grupo['qtd_datas_abertura_coordenada']))
        
        # Carregar dados detalhados
        try:
            # Contas compartilhadas do grupo
            query_compartilhadas = f"""
            SELECT * FROM {DATABASE}.gei_ccs_cpf_compartilhado
            WHERE CAST(num_grupo AS INT) = {grupo_selecionado}
            ORDER BY qtd_cnpjs_usando_conta DESC
            """
            df_compartilhadas = pd.read_sql(query_compartilhadas, engine)
            
            if not df_compartilhadas.empty:
                st.write("### Contas Compartilhadas")
                st.dataframe(df_compartilhadas[['nr_cpf', 'nm_banco', 'cd_agencia', 'nr_conta',
                                               'qtd_cnpjs_usando_conta', 'qtd_vinculos',
                                               'qtd_vinculos_ativos', 'status_conta']].head(20),
                            width='stretch', hide_index=True)
            
            # Sobreposi√ß√µes de respons√°veis
            query_sobreposicoes = f"""
            SELECT * FROM {DATABASE}.gei_ccs_sobreposicao_responsaveis
            WHERE CAST(num_grupo AS INT) = {grupo_selecionado}
            ORDER BY dias_sobreposicao DESC
            """
            df_sobreposicoes = pd.read_sql(query_sobreposicoes, engine)
            
            if not df_sobreposicoes.empty:
                st.write("### Sobreposi√ß√µes de Respons√°veis")
                st.dataframe(df_sobreposicoes[['nr_cpf', 'cnpj1', 'cnpj2', 
                                               'dias_sobreposicao', 'inicio1', 'fim1']].head(20),
                            width='stretch', hide_index=True)
            
            # Padr√µes coordenados
            query_padroes = f"""
            SELECT * FROM {DATABASE}.gei_ccs_padroes_coordenados
            WHERE CAST(num_grupo AS INT) = {grupo_selecionado}
            ORDER BY dt_evento DESC
            """
            df_padroes = pd.read_sql(query_padroes, engine)
            
            if not df_padroes.empty:
                st.write("### Padr√µes Coordenados de Abertura/Encerramento")
                st.dataframe(df_padroes[['tipo_evento', 'dt_evento', 'qtd_cnpjs',
                                        'qtd_contas', 'qtd_cpfs_distintos']].head(20),
                            width='stretch', hide_index=True)
                
        except Exception as e:
            st.error(f"Erro ao carregar detalhes: {e}")


def menu_financeiro(engine, dados, filtros):
    """An√°lise financeira detalhada"""
    st.markdown("<h1 class='main-header'>An√°lise Financeira Detalhada</h1>", unsafe_allow_html=True)
    
    df = aplicar_filtros(dados['percent'], filtros)
    
    if df.empty:
        st.warning("Nenhum dado encontrado.")
        return
    
    # Panorama Geral
    st.subheader("Indicadores Financeiros")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        receita = df['valor_max'].sum()
        st.metric("Receita Total Monitorada", formatar_moeda(receita))
    
    with col2:
        acima = len(df[df['valor_max'] > 4800000])
        perc = (acima / len(df) * 100) if len(df) > 0 else 0
        st.metric("Acima Limite SN", f"{acima:,}", f"{perc:.1f}%")
    
    with col3:
        if 'total_funcionarios' in df.columns:
            df_v = df[(df['valor_max'] > 0) & (df['total_funcionarios'] > 0)]
            if not df_v.empty:
                media = (df_v['valor_max'] / df_v['total_funcionarios']).mean()
                st.metric("Receita/Funcion√°rio", formatar_moeda(media))
    
    with col4:
        media_score = df[df['valor_max'] > 4800000]['score_final_ccs' if 'score_final_ccs' in df.columns else 'score_final_avancado'].mean()
        st.metric("Score M√©dio (>Limite)", f"{media_score:.2f}")
    
    # Distribui√ß√£o por Faixas de Receita
    st.subheader("Distribui√ß√£o por Faixa de Receita")
    
    faixas = {
        '0-1M': (0, 1e6),
        '1-2M': (1e6, 2e6),
        '2-3M': (2e6, 3e6),
        '3-4M': (3e6, 4e6),
        '4-4.8M': (4e6, 4.8e6),
        '>4.8M': (4.8e6, float('inf'))
    }
    
    contagens = []
    scores_medios = []
    score_col = 'score_final_ccs' if 'score_final_ccs' in df.columns else 'score_final_avancado'
    
    for nome, (inicio, fim) in faixas.items():
        grupos_faixa = df[(df['valor_max'] >= inicio) & (df['valor_max'] < fim)]
        contagens.append(len(grupos_faixa))
        scores_medios.append(grupos_faixa[score_col].mean() if len(grupos_faixa) > 0 else 0)
    
    col1, col2 = st.columns(2)
    
    with col1:
        fig = px.bar(x=list(faixas.keys()), y=contagens, 
                    title="Grupos por Faixa de Receita",
                    template=filtros['tema'],
                    labels={'x': 'Faixa', 'y': 'Quantidade de Grupos'})
        st.plotly_chart(fig)
    
    with col2:
        fig = px.bar(x=list(faixas.keys()), y=scores_medios,
                    title="Score M√©dio por Faixa de Receita",
                    template=filtros['tema'],
                    labels={'x': 'Faixa', 'y': 'Score M√©dio'})
        st.plotly_chart(fig)
    
    # An√°lise Temporal (PGDAS + DIME consolidado)
    st.subheader("Evolu√ß√£o Temporal")

    try:
        # Query consolidada PGDAS + DIME
        query_temporal = """
        WITH pgdas_data AS (
            SELECT
                gc.num_grupo,
                COALESCE(pg.jan2025, 0) as jan2025,
                COALESCE(pg.fev2025, 0) as fev2025,
                COALESCE(pg.mar2025, 0) as mar2025,
                COALESCE(pg.abr2025, 0) as abr2025,
                COALESCE(pg.mai2025, 0) as mai2025,
                COALESCE(pg.jun2025, 0) as jun2025,
                COALESCE(pg.jul2025, 0) as jul2025,
                COALESCE(pg.ago2025, 0) as ago2025,
                COALESCE(pg.set2025, 0) as set2025,
                'PGDAS' as fonte
            FROM gessimples.gei_cnpj gc
            JOIN gessimples.gei_pgdas pg ON gc.cnpj = pg.cnpj
        ),
        dime_data AS (
            SELECT
                gc.num_grupo,
                COALESCE(dm.jan2025, 0) as jan2025,
                COALESCE(dm.fev2025, 0) as fev2025,
                COALESCE(dm.mar2025, 0) as mar2025,
                COALESCE(dm.abr2025, 0) as abr2025,
                COALESCE(dm.mai2025, 0) as mai2025,
                COALESCE(dm.jun2025, 0) as jun2025,
                COALESCE(dm.jul2025, 0) as jul2025,
                COALESCE(dm.ago2025, 0) as ago2025,
                COALESCE(dm.set2025, 0) as set2025,
                'DIME' as fonte
            FROM gessimples.gei_cnpj gc
            JOIN gessimples.gei_dime dm ON gc.cnpj = dm.cnpj
        ),
        consolidado AS (
            SELECT * FROM pgdas_data
            UNION ALL
            SELECT * FROM dime_data
        )
        SELECT
            num_grupo,
            SUM(jan2025) as jan2025,
            SUM(fev2025) as fev2025,
            SUM(mar2025) as mar2025,
            SUM(abr2025) as abr2025,
            SUM(mai2025) as mai2025,
            SUM(jun2025) as jun2025,
            SUM(jul2025) as jul2025,
            SUM(ago2025) as ago2025,
            SUM(set2025) as set2025
        FROM consolidado
        GROUP BY num_grupo
        LIMIT 20
        """
        df_temp = pd.read_sql(query_temporal, engine)

        if not df_temp.empty:
            # Pegar top 10 grupos por receita total
            df_temp['total'] = df_temp[[c for c in df_temp.columns if c != 'num_grupo']].sum(axis=1)
            df_temp = df_temp.nlargest(10, 'total')

            # Transformar para formato long
            meses = ['jan2025', 'fev2025', 'mar2025', 'abr2025', 'mai2025',
                    'jun2025', 'jul2025', 'ago2025', 'set2025']

            df_long = df_temp.melt(id_vars=['num_grupo'],
                                  value_vars=meses,
                                  var_name='mes',
                                  value_name='receita')

            fig = px.line(df_long, x='mes', y='receita', color='num_grupo',
                         title="Evolu√ß√£o de Receita - Top 10 Grupos (PGDAS + DIME, 2025)",
                         template=filtros['tema'])
            st.plotly_chart(fig)
    except Exception as e:
        st.info(f"Dados temporais n√£o dispon√≠veis: {e}")
    
    # Top Grupos Financeiros
    st.subheader("Top 30 Grupos por Receita")
    df_top = df.nlargest(30, 'valor_max').copy()
    df_top['Receita'] = df_top['valor_max'].apply(formatar_moeda)

    st.dataframe(df_top[['num_grupo', 'Receita', 'qntd_cnpj', 'total_funcionarios',
                         score_col, 'nivel_risco_grupo_economico']],
                width='stretch', hide_index=True)

    # =========================================================================
    # DRILL DOWN POR GRUPO
    # =========================================================================
    st.divider()
    st.subheader("Detalhes por Grupo")

    grupo_selecionado = st.selectbox(
        "Selecione um grupo para ver detalhes:",
        options=['Selecione...'] + sorted(df['num_grupo'].unique().tolist()),
        key="financeiro_drill_down"
    )

    if grupo_selecionado and grupo_selecionado != 'Selecione...':
        info_grupo = df[df['num_grupo'] == grupo_selecionado].iloc[0]

        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("Grupo", grupo_selecionado)
        with col2:
            st.metric("CNPJs", int(info_grupo['qntd_cnpj']))
        with col3:
            st.metric("Receita M√°xima", formatar_moeda(info_grupo['valor_max']))
        with col4:
            st.metric("Per√≠odo M√°ximo", str(info_grupo.get('periodo_max', 'N/A')))

        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("1¬∫ Excesso Limite", str(info_grupo.get('periodo', 'Nunca')))
        with col2:
            func = info_grupo.get('total_funcionarios', 0)
            st.metric("Funcion√°rios", int(func) if pd.notna(func) else 0)
        with col3:
            st.metric("Score Final", f"{info_grupo[score_col]:.2f}")

        # Indicar se est√° acima do limite do Simples
        if info_grupo['valor_max'] > 4800000:
            st.error(f"ATEN√á√ÉO: Receita acima do limite do Simples Nacional (R$ 4,8M)")
            excesso = info_grupo['valor_max'] - 4800000
            st.write(f"**Excesso sobre o limite:** {formatar_moeda(excesso)}")

def inconsistencias_nfe(engine, dados, filtros):
    """An√°lise de inconsist√™ncias de NFe"""
    st.markdown("<h1 class='main-header'>Inconsist√™ncias de NFe</h1>", unsafe_allow_html=True)
    
    st.info("Esta an√°lise identifica valores compartilhados entre m√∫ltiplos CNPJs do mesmo grupo.")
    
    # Sele√ß√£o de Grupo
    st.subheader("An√°lise por Grupo")
    
    grupos_disponiveis = sorted(dados['percent']['num_grupo'].unique())
    grupo_selecionado = st.selectbox(
        "Selecione um grupo para an√°lise detalhada:",
        grupos_disponiveis,
        key="incons_grupo"
    )
    
    if grupo_selecionado:
        # Carregar dados do grupo com CAMPOS CORRETOS
        try:
            query_incons = f"""
            SELECT 
                nfe_nu_chave_acesso,
                nfe_dt_emissao,
                nfe_cnpj_cpf_emit,
                nfe_cnpj_cpf_dest,
                nfe_dest_email,
                nfe_dest_telefone,
                nfe_emit_telefone,
                nfe_cd_produto,
                nfe_de_produto,
                nfe_emit_end_completo,
                nfe_dest_end_completo,
                nfe_ip_transmissao,
                cliente_incons,
                email_incons,
                tel_dest_incons,
                tel_emit_incons,
                codigo_produto_incons,
                fornecedor_incons,
                end_emit_incons,
                end_dest_incons,
                descricao_produto_incons,
                ip_transmissao_incons
            FROM {DATABASE}.gei_nfe_completo
            WHERE CAST(grupo_emit AS INT) = {grupo_selecionado}
               OR CAST(grupo_dest AS INT) = {grupo_selecionado}
            LIMIT 5000
            """
            df_incons = pd.read_sql(query_incons, engine)
            
            if df_incons.empty:
                st.warning("Nenhuma inconsist√™ncia encontrada para este grupo.")
                return
            
            # Informa√ß√µes do Grupo
            info_grupo = dados['percent'][dados['percent']['num_grupo'] == grupo_selecionado].iloc[0]
            score_col = 'score_final_ccs' if 'score_final_ccs' in info_grupo.index else 'score_final_avancado'
            
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("Score Final", f"{info_grupo[score_col]:.2f}")
            with col2:
                st.metric("Documentos Analisados", f"{len(df_incons):,}")
            with col3:
                st.metric("CNPJs no Grupo", int(info_grupo['qntd_cnpj']))
            with col4:
                st.metric("Score Inconsist√™ncias", f"{info_grupo['total']:.2f}")
            
            # Resumo de Inconsist√™ncias
            st.subheader("Resumo de Inconsist√™ncias")
            
            tipos_incons = {
                'Clientes': 'cliente_incons',
                'E-mails': 'email_incons',
                'Tel. Destinat√°rio': 'tel_dest_incons',
                'Tel. Emitente': 'tel_emit_incons',
                'C√≥digos Produto': 'codigo_produto_incons',
                'Fornecedores': 'fornecedor_incons',
                'End. Emitente': 'end_emit_incons',
                'End. Destinat√°rio': 'end_dest_incons',
                'Desc. Produto': 'descricao_produto_incons',
                'IP Transmiss√£o': 'ip_transmissao_incons'
            }
            
            resumo = []
            for nome, coluna in tipos_incons.items():
                total = len(df_incons[df_incons[coluna] == 'S'])
                perc = (total / len(df_incons) * 100) if len(df_incons) > 0 else 0
                resumo.append({
                    'Tipo': nome,
                    'Quantidade': total,
                    'Percentual': f"{perc:.1f}%"
                })
            
            df_resumo = pd.DataFrame(resumo).sort_values('Quantidade', ascending=False)
            
            col1, col2 = st.columns([1, 1])
            
            with col1:
                st.dataframe(df_resumo, hide_index=True)
            
            with col2:
                fig = px.bar(df_resumo, x='Tipo', y='Quantidade',
                           title="Inconsist√™ncias por Tipo",
                           template=filtros['tema'])
                fig.update_xaxes(tickangle=45)
                st.plotly_chart(fig)
            
            # Detalhamento por Tipo com at√© 3 exemplos
            st.subheader("Detalhamento por Tipo de Inconsist√™ncia (at√© 3 exemplos por tipo)")
            
            # Mapeamento CORRETO baseado no SQL
            mapeamento_campos = {
                'cliente_incons': {
                    'nome': 'Clientes',
                    'campos': [
                        ('nfe_cnpj_cpf_dest', 'Cliente (Destinat√°rio)'),
                        ('nfe_cnpj_cpf_emit', 'Emitente'),
                        ('nfe_cnpj_cpf_dest', 'Destinat√°rio')
                    ]
                },
                'email_incons': {
                    'nome': 'E-mails',
                    'campos': [
                        ('nfe_dest_email', 'Email Destinat√°rio'),
                        ('nfe_cnpj_cpf_emit', 'Emitente'),
                        ('nfe_cnpj_cpf_dest', 'Destinat√°rio')
                    ]
                },
                'tel_dest_incons': {
                    'nome': 'Tel. Destinat√°rio',
                    'campos': [
                        ('nfe_dest_telefone', 'Telefone Destinat√°rio'),
                        ('nfe_cnpj_cpf_emit', 'Emitente'),
                        ('nfe_cnpj_cpf_dest', 'Destinat√°rio')
                    ]
                },
                'tel_emit_incons': {
                    'nome': 'Tel. Emitente',
                    'campos': [
                        ('nfe_emit_telefone', 'Telefone Emitente'),
                        ('nfe_cnpj_cpf_emit', 'Emitente'),
                        ('nfe_cnpj_cpf_dest', 'Destinat√°rio')
                    ]
                },
                'codigo_produto_incons': {
                    'nome': 'C√≥digos Produto',
                    'campos': [
                        ('nfe_cd_produto', 'C√≥digo Produto'),
                        ('nfe_cnpj_cpf_emit', 'Emitente')
                    ]
                },
                'fornecedor_incons': {
                    'nome': 'Fornecedores',
                    'campos': [
                        ('nfe_cnpj_cpf_emit', 'Fornecedor (Emitente)'),
                        ('nfe_cnpj_cpf_dest', 'Destinat√°rio')
                    ]
                },
                'end_emit_incons': {
                    'nome': 'End. Emitente',
                    'campos': [
                        ('nfe_emit_end_completo', 'Endere√ßo Emitente'),
                        ('nfe_cnpj_cpf_emit', 'Emitente'),
                        ('nfe_cnpj_cpf_dest', 'Destinat√°rio')
                    ]
                },
                'end_dest_incons': {
                    'nome': 'End. Destinat√°rio',
                    'campos': [
                        ('nfe_dest_end_completo', 'Endere√ßo Destinat√°rio'),
                        ('nfe_cnpj_cpf_emit', 'Emitente'),
                        ('nfe_cnpj_cpf_dest', 'Destinat√°rio')
                    ]
                },
                'descricao_produto_incons': {
                    'nome': 'Desc. Produto',
                    'campos': [
                        ('nfe_de_produto', 'Descri√ß√£o Produto'),
                        ('nfe_cnpj_cpf_emit', 'Emitente')
                    ]
                },
                'ip_transmissao_incons': {
                    'nome': 'IP Transmiss√£o',
                    'campos': [
                        ('nfe_ip_transmissao', 'IP Transmiss√£o'),
                        ('nfe_cnpj_cpf_emit', 'Emitente')
                    ]
                }
            }
            
            for coluna_incons, info_campo in mapeamento_campos.items():
                if coluna_incons in df_incons.columns:
                    df_tipo = df_incons[df_incons[coluna_incons] == 'S'].head(3)
                    
                    if not df_tipo.empty:
                        total_tipo = len(df_incons[df_incons[coluna_incons] == 'S'])
                        with st.expander(f"{info_campo['nome']} ({total_tipo} ocorr√™ncias)"):
                            for idx, row in df_tipo.iterrows():
                                st.write(f"**Nota Fiscal {idx + 1}:**")
                                st.write(f"- **Chave NFe:** {row.get('nfe_nu_chave_acesso', 'N/A')}")
                                st.write(f"- **Data Emiss√£o:** {row.get('nfe_dt_emissao', 'N/A')}")
                                
                                # Mostrar campos espec√≠ficos sem duplica√ß√£o
                                campos_exibidos = set()
                                for campo_bd, label in info_campo['campos']:
                                    if campo_bd in row.index and pd.notna(row.get(campo_bd)):
                                        valor = row.get(campo_bd)
                                        chave_unica = f"{label}:{valor}"
                                        if chave_unica not in campos_exibidos:
                                            st.write(f"- **{label}:** {valor}")
                                            campos_exibidos.add(chave_unica)
                                
                                st.divider()
            
            # Download
            csv = df_incons.to_csv(index=False).encode('utf-8')
            st.download_button(
                label="Download CSV Completo",
                data=csv,
                file_name=f"inconsistencias_grupo_{grupo_selecionado}.csv",
                mime="text/csv"
            )
            
        except Exception as e:
            st.error(f"Erro ao carregar inconsist√™ncias: {e}")

def indicios_fiscais(dados, filtros):
    """An√°lise de ind√≠cios fiscais"""
    st.markdown("<h1 class='main-header'>Ind√≠cios Fiscais</h1>", unsafe_allow_html=True)
    st.info("Ind√≠cios fiscais identificados no sistema por grupo econ√¥mico.")
    
    # An√°lise geral
    df = dados['percent']
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        grupos_com = len(df[df['qtd_total_indicios'] > 0])
        st.metric("Grupos com Ind√≠cios", grupos_com)
    with col2:
        total = df['qtd_total_indicios'].sum()
        st.metric("Total de Ind√≠cios", f"{int(total):,}")
    with col3:
        media = df['qtd_total_indicios'].mean()
        st.metric("M√©dia por Grupo", f"{media:.1f}")
    with col4:
        maximo = df['qtd_total_indicios'].max()
        st.metric("M√°ximo em um Grupo", int(maximo))
    
    # Top grupos
    st.subheader("Top 30 Grupos com Mais Ind√≠cios")
    df_top = df.nlargest(30, 'qtd_total_indicios')
    score_col = 'score_final_ccs' if 'score_final_ccs' in df.columns else 'score_final_avancado'
    st.dataframe(df_top[['num_grupo', 'qtd_total_indicios', 'qtd_tipos_indicios_distintos',
                        score_col, 'qntd_cnpj']],
                width='stretch', hide_index=True)

    # =========================================================================
    # DRILL DOWN POR GRUPO
    # =========================================================================
    st.divider()
    st.subheader("Detalhes por Grupo")

    df_com_indicios = df[df['qtd_total_indicios'] > 0]
    if df_com_indicios.empty:
        st.info("Nenhum grupo com ind√≠cios para detalhar.")
    else:
        grupo_selecionado = st.selectbox(
            "Selecione um grupo para ver detalhes dos ind√≠cios:",
            options=['Selecione...'] + sorted(df_com_indicios['num_grupo'].unique().tolist()),
            key="indicios_drill_down"
        )

        if grupo_selecionado and grupo_selecionado != 'Selecione...':
            info_grupo = df[df['num_grupo'] == grupo_selecionado].iloc[0]

            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("Grupo", grupo_selecionado)
            with col2:
                st.metric("Total Ind√≠cios", int(info_grupo['qtd_total_indicios']))
            with col3:
                st.metric("Tipos Distintos", int(info_grupo['qtd_tipos_indicios_distintos']))
            with col4:
                st.metric("CNPJs", int(info_grupo['qntd_cnpj']))

            col1, col2 = st.columns(2)
            with col1:
                perc = info_grupo.get('perc_cnpjs_com_indicios', 0)
                st.metric("% CNPJs com Ind√≠cios", f"{perc:.1f}%" if pd.notna(perc) else "N/A")
            with col2:
                st.metric("Score Final", f"{info_grupo[score_col]:.2f}")

            # Mostrar detalhes dos ind√≠cios se dispon√≠vel
            if 'indicios' in dados and not dados['indicios'].empty:
                df_indicios_grupo = dados['indicios'][dados['indicios']['num_grupo'] == grupo_selecionado]
                if not df_indicios_grupo.empty:
                    st.write("**Ind√≠cios encontrados:**")
                    st.dataframe(df_indicios_grupo, hide_index=True, use_container_width=True)

def vinculos_societarios(dados, filtros):
    """An√°lise de v√≠nculos societ√°rios"""
    st.markdown("<h1 class='main-header'>V√≠nculos Societ√°rios</h1>", unsafe_allow_html=True)
    
    df = aplicar_filtros(dados['percent'], filtros)
    
    if df.empty:
        st.warning("Nenhum dado encontrado.")
        return
    
    st.subheader("M√©tricas")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        grupos = len(df[df['qtd_socios_compartilhados'] > 0])
        perc = (grupos / len(df) * 100) if len(df) > 0 else 0
        st.metric("Grupos c/ S√≥cios Compartilhados", f"{grupos:,}", f"{perc:.1f}%")
    
    with col2:
        media = df['qtd_socios_compartilhados'].mean()
        st.metric("M√©dia de S√≥cios", f"{media:.1f}")
    
    with col3:
        if 'indice_interconexao' in df.columns:
            st.metric("√çndice M√©dio", f"{df['indice_interconexao'].mean():.3f}")
    
    grupo = st.selectbox("Selecione um grupo:", df['num_grupo'].tolist())
    
    if grupo:
        info = df[df['num_grupo'] == grupo].iloc[0]
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("CNPJs", f"{int(info['qntd_cnpj'])}")
        with col2:
            st.metric("S√≥cios Compartilhados", f"{int(info['qtd_socios_compartilhados'])}")
        with col3:
            if 'indice_interconexao' in info:
                st.metric("√çndice", f"{info['indice_interconexao']:.3f}")
        
        df_socios = dados['socios_compartilhados'][
            dados['socios_compartilhados']['num_grupo'] == grupo
        ]
        
        if not df_socios.empty:
            st.write("**S√≥cios:**")
            st.dataframe(df_socios.head(20), width='stretch', hide_index=True)

def dossie_grupo(engine, dados, filtros):
    """Dossi√™ completo do grupo"""
    st.markdown("<h1 class='main-header'>Dossi√™ Completo do Grupo</h1>", unsafe_allow_html=True)
    
    st.info("Visualize e exporte todas as informa√ß√µes consolidadas de um grupo.")
    
    # Sele√ß√£o do grupo
    if dados['percent'].empty:
        st.warning("Nenhum grupo dispon√≠vel.")
        return
    
    grupos_disponiveis = sorted(dados['percent']['num_grupo'].unique())
    
    # Adiciona op√ß√£o "Selecione..." como padr√£o
    grupo_selecionado = st.selectbox(
        "Selecione o grupo para visualizar o dossi√™ completo:",
        options=['Selecione um grupo...'] + grupos_disponiveis,
        key="grupo_dossie"
    )
    
    # S√≥ carrega se um grupo v√°lido foi selecionado
    if not grupo_selecionado or grupo_selecionado == 'Selecione um grupo...':
        st.info("üëÜ Selecione um grupo acima para visualizar o dossi√™ completo")
        return
    
    # Carregar dossi√™ completo
    with st.spinner(f"Carregando dossi√™ completo do Grupo {grupo_selecionado}..."):
        dossie = carregar_dossie_completo(engine, grupo_selecionado)
    
    # Informa√ß√µes principais
    st.header(f"Grupo {grupo_selecionado}")
    
    if not dossie['principal'].empty:
        info = dossie['principal'].iloc[0]
        score_col = 'score_final_ccs' if 'score_final_ccs' in info.index else 'score_final_avancado'
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            score_val = info.get(score_col, 0)
            st.metric("Score Final", f"{score_val:.2f}" if pd.notna(score_val) else "N/A")
        with col2:
            cnpj_val = info.get('qntd_cnpj', 0)
            st.metric("Quantidade de CNPJs", int(cnpj_val) if pd.notna(cnpj_val) else 0)
        with col3:
            receita_val = info.get('valor_max', 0)
            st.metric("Receita M√°xima", formatar_moeda(receita_val) if pd.notna(receita_val) else "R$ 0,00")
        with col4:
            func_val = info.get('total_funcionarios', 0)
            st.metric("Total Funcion√°rios", int(func_val) if pd.notna(func_val) else 0)
        
        st.divider()
        
        # M√©tricas adicionais
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("N√≠vel Risco C115", str(info.get('nivel_risco_grupo_economico', 'N/A')))
        with col2:
            st.metric("N√≠vel Risco CCS", str(info.get('nivel_risco_ccs', 'N/A')))
        with col3:
            indicios_val = info.get('qtd_total_indicios', 0)
            st.metric("Total Ind√≠cios", int(indicios_val) if pd.notna(indicios_val) else 0)
        with col4:
            socios_val = info.get('qtd_socios_compartilhados', 0)
            st.metric("S√≥cios Compartilhados", int(socios_val) if pd.notna(socios_val) else 0)
    
    # Tabs para organizar informa√ß√µes
    tab1, tab2, tab3, tab4, tab5, tab6, tab7, tab8, tab9, tab10, tab11, tab12, tab13, tab14 = st.tabs([
        "CNPJs e Cadastro",
        "Receita/Faturamento",
        "S√≥cios",
        "Ind√≠cios",
        "Inconsist√™ncias NFe",
        "C115",
        "CCS",
        "Funcion√°rios",
        "Pagamentos",
        "M√©tricas Detalhadas",
        "Energia El√©trica",
        "Telecomunica√ß√µes",
        "An√°lise de Similaridade",
        "Exporta√ß√£o"
    ])
    
    # =========================================================================
    # TAB 1: CNPJs E CADASTRO
    # =========================================================================
    with tab1:
        st.subheader("CNPJs do Grupo")
        
        if not dossie['cnpjs'].empty:
            st.write(f"**Total de {len(dossie['cnpjs'])} CNPJs**")
            
            # Garantir que todas as colunas sejam string para evitar erro Arrow
            df_display = dossie['cnpjs'].copy()
            for col in df_display.columns:
                df_display[col] = df_display[col].astype(str)
            
            st.dataframe(df_display, hide_index=True, width='stretch')
            
            # Download
            csv = df_display.to_csv(index=False).encode('utf-8')
            st.download_button(
                label="üì• Download CNPJs (CSV)",
                data=csv,
                file_name=f"cnpjs_grupo_{grupo_selecionado}.csv",
                mime="text/csv"
            )
        else:
            st.error("‚ùå Nenhum CNPJ encontrado para este grupo.")

    # =========================================================================
    # TAB 2: RECEITA/FATURAMENTO (PGDAS + DIME)
    # =========================================================================
    with tab2:
        st.subheader("Receita/Faturamento (PGDAS + DIME)")

        # M√©tricas do gei_percent
        if not dossie['principal'].empty:
            info = dossie['principal'].iloc[0]

            col1, col2, col3, col4 = st.columns(4)
            with col1:
                valor_max = info.get('valor_max', 0)
                st.metric("Receita M√°xima (12m)", formatar_moeda(valor_max) if pd.notna(valor_max) else "R$ 0,00")
            with col2:
                periodo_max = info.get('periodo_max', 'N/A')
                st.metric("Per√≠odo M√°ximo", str(periodo_max) if pd.notna(periodo_max) else "N/A")
            with col3:
                periodo_exc = info.get('periodo', 'N/A')
                st.metric("1¬∫ Excesso Limite SN", str(periodo_exc) if pd.notna(periodo_exc) else "Nunca")
            with col4:
                acima_limite = "SIM" if pd.notna(valor_max) and valor_max > 4800000 else "N√ÉO"
                st.metric("Acima R$ 4,8M?", acima_limite)

            st.divider()

        # Dados de faturamento detalhado
        if 'faturamento' in dossie and not dossie['faturamento'].empty:
            df_fat = dossie['faturamento'].copy()

            # Resumo por fonte
            col1, col2 = st.columns(2)
            with col1:
                qtd_pgdas = len(df_fat[df_fat['fonte'] == 'PGDAS'])
                st.metric("CNPJs com PGDAS (Simples)", qtd_pgdas)
            with col2:
                qtd_dime = len(df_fat[df_fat['fonte'] == 'DIME'])
                st.metric("CNPJs com DIME (Normal)", qtd_dime)

            st.divider()

            # Sub-tabs para PGDAS e DIME
            sub_tab1, sub_tab2, sub_tab3 = st.tabs(["Consolidado", "PGDAS (Simples)", "DIME (Normal)"])

            with sub_tab1:
                st.write("**Faturamento Consolidado (√∫ltimos meses de 2025):**")

                # Calcular √∫ltimo valor de cada CNPJ
                meses_cols = ['set2025', 'ago2025', 'jul2025', 'jun2025', 'mai2025', 'abr2025', 'mar2025', 'fev2025', 'jan2025']
                df_consolidado = df_fat.copy()

                # Pegar o √∫ltimo valor n√£o-zero para cada CNPJ
                def get_ultimo_valor(row):
                    for mes in meses_cols:
                        if mes in row and pd.notna(row[mes]) and row[mes] > 0:
                            return row[mes]
                    return 0

                df_consolidado['ultimo_valor_12m'] = df_consolidado.apply(get_ultimo_valor, axis=1)

                # Agrupar por CNPJ pegando o maior valor (caso tenha PGDAS e DIME)
                df_resumo = df_consolidado.groupby('cnpj').agg({
                    'ultimo_valor_12m': 'max',
                    'fonte': lambda x: ', '.join(x.unique())
                }).reset_index()
                df_resumo.columns = ['CNPJ', 'Receita 12m', 'Fonte']
                df_resumo['Acima Limite'] = df_resumo['Receita 12m'].apply(lambda x: 'SIM' if x > 4800000 else 'N√ÉO')
                df_resumo['Receita 12m Formatada'] = df_resumo['Receita 12m'].apply(formatar_moeda)

                # Totais
                total_receita = df_resumo['Receita 12m'].sum()
                cnpjs_acima = len(df_resumo[df_resumo['Receita 12m'] > 4800000])

                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("Total CNPJs", len(df_resumo))
                with col2:
                    st.metric("Receita Total (soma)", formatar_moeda(total_receita))
                with col3:
                    st.metric("CNPJs Acima Limite", cnpjs_acima)

                st.dataframe(
                    df_resumo.sort_values('Receita 12m', ascending=False)[['CNPJ', 'Receita 12m Formatada', 'Fonte', 'Acima Limite']],
                    hide_index=True,
                    use_container_width=True
                )

                # Gr√°fico de evolu√ß√£o consolidada
                st.divider()
                st.write("**Evolu√ß√£o do Faturamento por M√™s:**")
                try:
                    # Transformar dados de wide para long
                    meses_disponiveis = [m for m in meses_cols if m in df_fat.columns]
                    df_chart = df_fat.melt(
                        id_vars=['cnpj', 'fonte'],
                        value_vars=meses_disponiveis,
                        var_name='periodo',
                        value_name='receita'
                    )
                    df_chart = df_chart[df_chart['receita'].notna() & (df_chart['receita'] > 0)]

                    if not df_chart.empty:
                        # Ordenar per√≠odos cronologicamente
                        ordem_meses = {'jan2025': 1, 'fev2025': 2, 'mar2025': 3, 'abr2025': 4,
                                      'mai2025': 5, 'jun2025': 6, 'jul2025': 7, 'ago2025': 8, 'set2025': 9}
                        df_chart['ordem'] = df_chart['periodo'].map(ordem_meses)
                        df_chart = df_chart.sort_values('ordem')

                        # Gr√°fico 1: Receita TOTAL do grupo (soma de todos os CNPJs)
                        df_total_grupo = df_chart.groupby('periodo').agg({
                            'receita': 'sum',
                            'ordem': 'first'
                        }).reset_index().sort_values('ordem')

                        fig_total = px.line(
                            df_total_grupo,
                            x='periodo',
                            y='receita',
                            title="Receita TOTAL do Grupo (soma de todos os CNPJs)",
                            labels={'receita': 'Receita Total (R$)', 'periodo': 'Per√≠odo'},
                            markers=True
                        )
                        fig_total.add_hline(y=4800000, line_dash="dash", line_color="red",
                                           annotation_text="Limite SN (R$ 4,8M)")
                        fig_total.update_traces(line=dict(width=3, color='#1f77b4'), marker=dict(size=10))
                        st.plotly_chart(fig_total, use_container_width=True)

                        # Verificar se ultrapassou limite em algum m√™s
                        meses_acima = df_total_grupo[df_total_grupo['receita'] > 4800000]
                        if not meses_acima.empty:
                            primeiro_mes = meses_acima.iloc[0]['periodo']
                            valor_primeiro = meses_acima.iloc[0]['receita']
                            st.error(f"‚ö†Ô∏è **ALERTA:** Receita total do grupo ultrapassou o limite do Simples Nacional em **{primeiro_mes}** (R$ {valor_primeiro:,.2f})")

                        st.divider()

                        # Gr√°fico 2: Evolu√ß√£o individual por CNPJ
                        st.write("**Evolu√ß√£o por CNPJ (individual):**")
                        fig = px.line(
                            df_chart,
                            x='periodo',
                            y='receita',
                            color='cnpj',
                            line_dash='fonte',
                            title="Evolu√ß√£o do Faturamento por CNPJ",
                            labels={'receita': 'Receita (R$)', 'periodo': 'Per√≠odo', 'fonte': 'Fonte', 'cnpj': 'CNPJ'},
                            markers=True
                        )
                        fig.add_hline(y=4800000, line_dash="dash", line_color="red",
                                     annotation_text="Limite SN (R$ 4,8M)")
                        st.plotly_chart(fig, use_container_width=True)
                    else:
                        st.info("Sem dados suficientes para gerar o gr√°fico.")
                except Exception as e:
                    st.warning(f"N√£o foi poss√≠vel gerar o gr√°fico: {e}")

            with sub_tab2:
                df_pgdas = df_fat[df_fat['fonte'] == 'PGDAS'].copy()
                if not df_pgdas.empty:
                    st.write(f"**{len(df_pgdas)} CNPJs com dados PGDAS (Simples Nacional):**")

                    # Gr√°fico PGDAS (antes de formatar)
                    try:
                        meses_disponiveis = [m for m in meses_cols if m in df_pgdas.columns]
                        df_chart_pgdas = df_pgdas.melt(
                            id_vars=['cnpj'],
                            value_vars=meses_disponiveis,
                            var_name='periodo',
                            value_name='receita'
                        )
                        df_chart_pgdas = df_chart_pgdas[df_chart_pgdas['receita'].notna() & (df_chart_pgdas['receita'] > 0)]

                        if not df_chart_pgdas.empty:
                            ordem_meses = {'jan2025': 1, 'fev2025': 2, 'mar2025': 3, 'abr2025': 4,
                                          'mai2025': 5, 'jun2025': 6, 'jul2025': 7, 'ago2025': 8, 'set2025': 9}
                            df_chart_pgdas['ordem'] = df_chart_pgdas['periodo'].map(ordem_meses)
                            df_chart_pgdas = df_chart_pgdas.sort_values('ordem')

                            fig_pgdas = px.line(
                                df_chart_pgdas,
                                x='periodo',
                                y='receita',
                                color='cnpj',
                                title="Evolu√ß√£o da Receita PGDAS (Simples Nacional)",
                                labels={'receita': 'Receita (R$)', 'periodo': 'Per√≠odo', 'cnpj': 'CNPJ'},
                                markers=True
                            )
                            fig_pgdas.add_hline(y=4800000, line_dash="dash", line_color="red",
                                               annotation_text="Limite SN (R$ 4,8M)")
                            st.plotly_chart(fig_pgdas, use_container_width=True)
                    except Exception as e:
                        st.warning(f"N√£o foi poss√≠vel gerar o gr√°fico PGDAS: {e}")

                    st.divider()
                    st.write("**Tabela Detalhada:**")
                    df_pgdas_display = df_pgdas.copy()
                    for col in df_pgdas_display.columns:
                        if col not in ['cnpj', 'fonte']:
                            df_pgdas_display[col] = df_pgdas_display[col].apply(lambda x: formatar_moeda(x) if pd.notna(x) else 'R$ 0,00')
                    st.dataframe(df_pgdas_display, hide_index=True, use_container_width=True)
                else:
                    st.info("Nenhum CNPJ com dados PGDAS encontrado.")

            with sub_tab3:
                df_dime = df_fat[df_fat['fonte'] == 'DIME'].copy()
                if not df_dime.empty:
                    st.write(f"**{len(df_dime)} CNPJs com dados DIME (Regime Normal):**")

                    # Gr√°fico DIME (antes de formatar)
                    try:
                        meses_disponiveis = [m for m in meses_cols if m in df_dime.columns]
                        df_chart_dime = df_dime.melt(
                            id_vars=['cnpj'],
                            value_vars=meses_disponiveis,
                            var_name='periodo',
                            value_name='faturamento'
                        )
                        df_chart_dime = df_chart_dime[df_chart_dime['faturamento'].notna() & (df_chart_dime['faturamento'] > 0)]

                        if not df_chart_dime.empty:
                            ordem_meses = {'jan2025': 1, 'fev2025': 2, 'mar2025': 3, 'abr2025': 4,
                                          'mai2025': 5, 'jun2025': 6, 'jul2025': 7, 'ago2025': 8, 'set2025': 9}
                            df_chart_dime['ordem'] = df_chart_dime['periodo'].map(ordem_meses)
                            df_chart_dime = df_chart_dime.sort_values('ordem')

                            fig_dime = px.line(
                                df_chart_dime,
                                x='periodo',
                                y='faturamento',
                                color='cnpj',
                                title="Evolu√ß√£o do Faturamento DIME (Regime Normal)",
                                labels={'faturamento': 'Faturamento (R$)', 'periodo': 'Per√≠odo', 'cnpj': 'CNPJ'},
                                markers=True
                            )
                            st.plotly_chart(fig_dime, use_container_width=True)
                    except Exception as e:
                        st.warning(f"N√£o foi poss√≠vel gerar o gr√°fico DIME: {e}")

                    st.divider()
                    st.write("**Tabela Detalhada:**")
                    df_dime_display = df_dime.copy()
                    for col in df_dime_display.columns:
                        if col not in ['cnpj', 'fonte']:
                            df_dime_display[col] = df_dime_display[col].apply(lambda x: formatar_moeda(x) if pd.notna(x) else 'R$ 0,00')
                    st.dataframe(df_dime_display, hide_index=True, use_container_width=True)
                else:
                    st.info("Nenhum CNPJ com dados DIME encontrado.")
        else:
            st.info("Nenhum dado de faturamento dispon√≠vel para este grupo.")

    # =========================================================================
    # TAB 3: S√ìCIOS
    # =========================================================================
    with tab3:
        st.subheader("S√≥cios Compartilhados")
        
        if not dossie['socios'].empty:
            st.write(f"**Total de {len(dossie['socios'])} registros**")
            
            # Converter para string
            df_display = dossie['socios'].copy()
            for col in df_display.columns:
                df_display[col] = df_display[col].astype(str)
            
            st.dataframe(df_display, width='stretch', hide_index=True)
            
            # An√°lise
            if 'cpf_socio' in dossie['socios'].columns:
                st.write("**An√°lise de S√≥cios:**")
                col1, col2 = st.columns(2)
                
                with col1:
                    st.metric("S√≥cios √önicos", dossie['socios']['cpf_socio'].nunique())
                
                with col2:
                    if 'qtd_empresas' in dossie['socios'].columns:
                        max_empresas = dossie['socios']['qtd_empresas'].max()
                        st.metric("Max Empresas/S√≥cio", int(max_empresas) if pd.notna(max_empresas) else 0)
        else:
            st.info("Nenhum s√≥cio compartilhado encontrado.")
    
    # =========================================================================
    # TAB 4: IND√çCIOS
    # =========================================================================
    with tab4:
        st.subheader("Ind√≠cios Fiscais")
        
        if not dossie['indicios'].empty:
            st.write(f"**Total de {len(dossie['indicios'])} ind√≠cios**")
            
            # Resumo por tipo
            resumo_tipos = dossie['indicios'].groupby('tx_descricao_indicio').size().reset_index(name='Quantidade')
            resumo_tipos = resumo_tipos.sort_values('Quantidade', ascending=False)
            
            # TABELA EM LARGURA TOTAL
            st.write("**Resumo por Tipo:**")
            st.dataframe(resumo_tipos, width='stretch', hide_index=True)
            
            # GR√ÅFICO ABAIXO DA TABELA
            fig = px.bar(resumo_tipos.head(10), x='Quantidade', y='tx_descricao_indicio',
                       orientation='h', title="Top 10 Tipos de Ind√≠cios",
                       template=filtros['tema'])
            st.plotly_chart(fig, use_container_width=True)
            
            st.divider()
            
            st.write("**Lista Completa:**")
            
            # Converter para string
            df_display = dossie['indicios'].copy()
            for col in df_display.columns:
                df_display[col] = df_display[col].astype(str)
            
            st.dataframe(df_display, width='stretch', hide_index=True)
            
            # Download
            csv = df_display.to_csv(index=False).encode('utf-8')
            st.download_button(
                label="Download Ind√≠cios (CSV)",
                data=csv,
                file_name=f"indicios_grupo_{grupo_selecionado}.csv",
                mime="text/csv"
            )
        else:
            st.info("Nenhum ind√≠cio encontrado.")
    
    # =========================================================================
    # TAB 5: INCONSIST√äNCIAS NFE
    # =========================================================================
    with tab5:
        st.subheader("Inconsist√™ncias em Notas Fiscais")
        
        if not dossie['inconsistencias'].empty:
            st.write(f"**Total de {len(dossie['inconsistencias'])} documentos analisados**")
            
            # Calcular estat√≠sticas
            tipos_incons = {
                'cliente_incons': 'Cliente',
                'email_incons': 'E-mail',
                'tel_dest_incons': 'Telefone Destinat√°rio',
                'tel_emit_incons': 'Telefone Emitente',
                'codigo_produto_incons': 'C√≥digo Produto',
                'fornecedor_incons': 'Fornecedor',
                'end_emit_incons': 'Endere√ßo Emitente',
                'end_dest_incons': 'Endere√ßo Destinat√°rio',
                'descricao_produto_incons': 'Descri√ß√£o Produto',
                'ip_transmissao_incons': 'IP Transmiss√£o'
            }
            
            # Resumo geral
            resumo = []
            for campo, label in tipos_incons.items():
                if campo in dossie['inconsistencias'].columns:
                    total = len(dossie['inconsistencias'][dossie['inconsistencias'][campo] == 'S'])
                    if total > 0:  # S√≥ adiciona se houver inconsist√™ncias
                        resumo.append({
                            'Tipo': label,
                            'Quantidade': total
                        })
            
            if resumo:
                df_resumo = pd.DataFrame(resumo).sort_values('Quantidade', ascending=False)
                
                # Gr√°fico resumo
                st.write("**Resumo Geral:**")
                col1, col2 = st.columns([1, 2])
                
                with col1:
                    st.dataframe(df_resumo, hide_index=True, use_container_width=True)
                
                with col2:
                    fig = px.bar(df_resumo, x='Tipo', y='Quantidade',
                               title="Inconsist√™ncias por Tipo",
                               template=filtros['tema'])
                    fig.update_xaxes(tickangle=45)
                    st.plotly_chart(fig, use_container_width=True)
                
                st.divider()
                
                # Detalhamento por tipo de inconsist√™ncia
                st.write("**Detalhamento por Tipo de Inconsist√™ncia:**")
                
                # Criar abas para cada tipo de inconsist√™ncia
                tipo_tabs = st.tabs([label for label in df_resumo['Tipo'].tolist()])
                
                for idx, (campo, label) in enumerate(tipos_incons.items()):
                    if campo in dossie['inconsistencias'].columns:
                        # Filtrar apenas as notas com esta inconsist√™ncia
                        df_filtrado = dossie['inconsistencias'][
                            dossie['inconsistencias'][campo] == 'S'
                        ].copy()
                        
                        if not df_filtrado.empty:
                            # Encontrar a aba correspondente
                            tab_idx = df_resumo[df_resumo['Tipo'] == label].index
                            if len(tab_idx) > 0:
                                with tipo_tabs[tab_idx[0]]:
                                    st.write(f"**{len(df_filtrado)} notas com inconsist√™ncia em {label}**")
                                    
                                    # Selecionar colunas relevantes para exibi√ß√£o
                                    colunas_exibir = []
                                    
                                    # Colunas b√°sicas sempre presentes
                                    if 'chave_nfe' in df_filtrado.columns:
                                        colunas_exibir.append('chave_nfe')
                                    if 'num_nota' in df_filtrado.columns:
                                        colunas_exibir.append('num_nota')
                                    if 'cnpj_emit' in df_filtrado.columns:
                                        colunas_exibir.append('cnpj_emit')
                                    if 'cnpj_dest' in df_filtrado.columns:
                                        colunas_exibir.append('cnpj_dest')
                                    if 'dt_emissao' in df_filtrado.columns:
                                        colunas_exibir.append('dt_emissao')
                                    if 'vl_total_nf' in df_filtrado.columns:
                                        colunas_exibir.append('vl_total_nf')
                                    
                                    # Adicionar colunas espec√≠ficas da inconsist√™ncia
                                    # (removendo o sufixo _incons para pegar os valores reais)
                                    campo_base = campo.replace('_incons', '')
                                    if campo_base in df_filtrado.columns:
                                        colunas_exibir.append(campo_base)
                                    
                                    # Filtrar apenas as colunas que existem
                                    colunas_exibir = [col for col in colunas_exibir if col in df_filtrado.columns]
                                    
                                    if colunas_exibir:
                                        df_display = df_filtrado[colunas_exibir].head(100).copy()
                                        
                                        # Formatar valores
                                        for col in df_display.columns:
                                            if col == 'vl_total_nf':
                                                df_display[col] = df_display[col].apply(
                                                    lambda x: formatar_moeda(x) if pd.notna(x) else 'N/A'
                                                )
                                            elif 'dt_' in col:
                                                df_display[col] = pd.to_datetime(df_display[col], errors='coerce').dt.strftime('%d/%m/%Y')
                                            else:
                                                df_display[col] = df_display[col].astype(str)
                                        
                                        # Renomear colunas para melhor visualiza√ß√£o
                                        rename_dict = {
                                            'chave_nfe': 'Chave NFe',
                                            'num_nota': 'N√∫mero',
                                            'cnpj_emit': 'CNPJ Emitente',
                                            'cnpj_dest': 'CNPJ Destinat√°rio',
                                            'dt_emissao': 'Data Emiss√£o',
                                            'vl_total_nf': 'Valor Total',
                                            campo_base: label
                                        }
                                        df_display.rename(columns=rename_dict, inplace=True)
                                        
                                        st.dataframe(df_display, hide_index=True, use_container_width=True)
                                        
                                        # Bot√£o de download
                                        csv = df_filtrado.to_csv(index=False).encode('utf-8')
                                        st.download_button(
                                            label=f"üì• Download CSV - {label}",
                                            data=csv,
                                            file_name=f"inconsistencias_{campo_base}_grupo_{grupo_selecionado}.csv",
                                            mime="text/csv",
                                            key=f"download_{campo}"
                                        )
                                    else:
                                        st.dataframe(df_filtrado.head(100), hide_index=True, use_container_width=True)
            else:
                st.success("‚úÖ Nenhuma inconsist√™ncia encontrada!")
        else:
            st.info("Nenhum documento analisado.")
    
    # =========================================================================
    # TAB 6: CONV√äNIO 115
    # =========================================================================
    with tab6:
        st.subheader("Dados Conv√™nio 115")
        
        if not dossie['c115'].empty:
            info_c115 = dossie['c115'].iloc[0]
            
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                ranking = info_c115.get('ranking_risco', 0)
                st.metric("Ranking Risco", int(ranking) if pd.notna(ranking) else 'N/A')
            with col2:
                st.metric("N√≠vel Risco", info_c115.get('nivel_risco_grupo_economico', 'N/A'))
            with col3:
                indice = info_c115.get('indice_risco_grupo_economico', 0)
                st.metric("√çndice Risco", f"{indice:.4f}" if pd.notna(indice) else 'N/A')
            with col4:
                qtd = info_c115.get('qtd_cnpjs_relacionados', 0)
                st.metric("CNPJs Relacionados", int(qtd) if pd.notna(qtd) else 0)
            
            st.divider()
            
            # Converter para string
            df_display = dossie['c115'].copy()
            for col in df_display.columns:
                df_display[col] = df_display[col].astype(str)
            
            st.dataframe(df_display, width='stretch', hide_index=True)
        else:
            st.info("Nenhum dado C115 dispon√≠vel para este grupo.")
    
    # =========================================================================
    # TAB 7: CCS
    # =========================================================================
    with tab7:
        st.subheader("Dados CCS (Contas Compartilhadas)")
        
        # M√©tricas principais do gei_percent
        if not dossie['principal'].empty:
            info = dossie['principal'].iloc[0]
            
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                indice = info.get('indice_risco_ccs', 0)
                st.metric("√çndice Risco CCS", f"{indice:.4f}" if pd.notna(indice) else 'N/A')
            with col2:
                st.metric("N√≠vel Risco CCS", info.get('nivel_risco_ccs', 'N/A'))
            with col3:
                qtd = info.get('ccs_qtd_contas_compartilhadas', 0)
                st.metric("Contas Compartilhadas", int(qtd) if pd.notna(qtd) else 0)
            with col4:
                max_cnpj = info.get('ccs_max_cnpjs_por_conta', 0)
                st.metric("Max CNPJs/Conta", int(max_cnpj) if pd.notna(max_cnpj) else 0)
            
            st.divider()
            
            col1, col2, col3 = st.columns(3)
            with col1:
                sobr = info.get('ccs_qtd_sobreposicoes_responsaveis', 0)
                st.metric("Sobreposi√ß√µes", int(sobr) if pd.notna(sobr) else 0)
            with col2:
                media = info.get('ccs_media_dias_sobreposicao', 0)
                st.metric("M√©dia Dias Sobreposi√ß√£o", f"{media:.0f}" if pd.notna(media) else '0')
            with col3:
                aber = info.get('ccs_qtd_datas_abertura_coordenada', 0)
                st.metric("Aberturas Coordenadas", int(aber) if pd.notna(aber) else 0)
        
        # Contas compartilhadas
        if not dossie['ccs_compartilhadas'].empty:
            st.write("**Contas Compartilhadas:**")
            
            df_display = dossie['ccs_compartilhadas'].copy()
            for col in df_display.columns:
                df_display[col] = df_display[col].astype(str)
            
            st.dataframe(df_display.head(50), width='stretch', hide_index=True)
        else:
            st.info("Nenhuma conta compartilhada encontrada.")
        
        # Sobreposi√ß√µes
        if not dossie['ccs_sobreposicoes'].empty:
            st.write("**Sobreposi√ß√µes de Respons√°veis:**")
            
            df_display = dossie['ccs_sobreposicoes'].copy()
            for col in df_display.columns:
                df_display[col] = df_display[col].astype(str)
            
            st.dataframe(df_display.head(50), width='stretch', hide_index=True)
        else:
            st.info("Nenhuma sobreposi√ß√£o encontrada.")
        
        # Padr√µes coordenados
        if not dossie['ccs_padroes'].empty:
            st.write("**Padr√µes Coordenados:**")
            
            df_display = dossie['ccs_padroes'].copy()
            for col in df_display.columns:
                df_display[col] = df_display[col].astype(str)
            
            st.dataframe(df_display, width='stretch', hide_index=True)
        else:
            st.info("Nenhum padr√£o coordenado encontrado.")
    
    # =========================================================================
    # TAB 8: FUNCION√ÅRIOS
    # =========================================================================
    with tab8:
        st.subheader("Dados de Funcion√°rios")
        
        if not dossie['funcionarios'].empty:
            info_func = dossie['funcionarios'].iloc[0]
            
            col1, col2 = st.columns(2)
            with col1:
                total = info_func.get('total_funcionarios', 0)
                st.metric("Total Funcion√°rios", int(total) if pd.notna(total) else 0)
            with col2:
                cnpjs = info_func.get('cnpjs_com_funcionarios', 0)
                st.metric("CNPJs com Funcion√°rios", int(cnpjs) if pd.notna(cnpjs) else 0)
            
            st.divider()
            
            # Converter para string
            df_display = dossie['funcionarios'].copy()
            for col in df_display.columns:
                df_display[col] = df_display[col].astype(str)
            
            st.dataframe(df_display, width='stretch', hide_index=True)
        else:
            st.info("Nenhum dado de funcion√°rios dispon√≠vel.")
    
    # =========================================================================
    # TAB 9: PAGAMENTOS
    # =========================================================================
    with tab9:
        st.subheader("Dados de Meios de Pagamento")
        
        if not dossie['pagamentos'].empty:
            info_pag = dossie['pagamentos'].iloc[0]
            
            col1, col2 = st.columns(2)
            with col1:
                valor_empresas = info_pag.get('valor_meios_pagamento_empresas', 0)
                st.metric("Pagamentos Empresas", formatar_moeda(valor_empresas) if pd.notna(valor_empresas) else 'R$ 0,00')
            with col2:
                valor_socios = info_pag.get('valor_meios_pagamento_socios', 0)
                st.metric("Pagamentos S√≥cios", formatar_moeda(valor_socios) if pd.notna(valor_socios) else 'R$ 0,00')
            
            st.divider()
            
            # Converter para string
            df_display = dossie['pagamentos'].copy()
            for col in df_display.columns:
                df_display[col] = df_display[col].astype(str)
            
            st.dataframe(df_display, width='stretch', hide_index=True)
        else:
            st.info("Nenhum dado de pagamentos dispon√≠vel.")
    
    # =========================================================================
    # TAB 10: M√âTRICAS DETALHADAS
    # =========================================================================
    with tab10:
        st.subheader("M√©tricas Detalhadas")
        
        if not dossie['principal'].empty:
            info = dossie['principal'].iloc[0]
            
            # Criar dataframe com todas as m√©tricas
            metricas = []
            for col in info.index:
                if pd.notna(info[col]):
                    metricas.append({
                        'M√©trica': col,
                        'Valor': str(info[col])
                    })
            
            df_metricas = pd.DataFrame(metricas)
            st.dataframe(df_metricas, width='stretch', hide_index=True)

    # =========================================================================
    # TAB 11: ENERGIA EL√âTRICA (NF3e)
    # =========================================================================
    with tab11:
        st.subheader("‚ö° Consumo de Energia El√©trica")

        # Verificar se h√° dados de NF3e
        if 'nf3e' in dossie and not dossie['nf3e'].empty:
            df_nf3e = dossie['nf3e'].copy()

            # M√©tricas do grupo
            if 'nf3e_metricas' in dossie and not dossie['nf3e_metricas'].empty:
                metricas = dossie['nf3e_metricas'].iloc[0]
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("Empresas Consumidoras", int(metricas.get('qt_empresas_consumidoras', 0)))
                with col2:
                    st.metric("Valor Total Energia", formatar_moeda(metricas.get('vl_energia_grupo', 0)))
                with col3:
                    st.metric("Qtd. Notas", int(metricas.get('qt_notas_grupo', 0)))

                st.divider()

            # Resumo por CNPJ
            st.write("**Consumo de Energia por CNPJ (acumulado 12 meses):**")

            # Pegar o √∫ltimo valor dispon√≠vel
            meses_cols = ['set2025', 'ago2025', 'jul2025', 'jun2025', 'mai2025', 'abr2025',
                         'mar2025', 'fev2025', 'jan2025', 'dez2024', 'nov2024', 'out2024']

            def get_ultimo_valor_energia(row):
                for mes in meses_cols:
                    if mes in row and pd.notna(row[mes]) and row[mes] > 0:
                        return row[mes]
                return 0

            df_nf3e['ultimo_valor_12m'] = df_nf3e.apply(get_ultimo_valor_energia, axis=1)

            # Resumo
            df_resumo_energia = df_nf3e[['cnpj', 'ultimo_valor_12m']].copy()
            df_resumo_energia.columns = ['CNPJ', 'Energia 12m (R$)']
            df_resumo_energia['Energia Formatada'] = df_resumo_energia['Energia 12m (R$)'].apply(formatar_moeda)

            total_energia = df_resumo_energia['Energia 12m (R$)'].sum()

            col1, col2 = st.columns(2)
            with col1:
                st.metric("Total CNPJs com Energia", len(df_resumo_energia))
            with col2:
                st.metric("Consumo Total (soma)", formatar_moeda(total_energia))

            st.dataframe(
                df_resumo_energia.sort_values('Energia 12m (R$)', ascending=False)[['CNPJ', 'Energia Formatada']],
                hide_index=True,
                use_container_width=True
            )

            # Gr√°fico de evolu√ß√£o
            st.divider()
            st.write("**Evolu√ß√£o do Consumo de Energia:**")
            try:
                meses_disponiveis = [m for m in meses_cols if m in df_nf3e.columns]
                df_chart = df_nf3e.melt(
                    id_vars=['cnpj'],
                    value_vars=meses_disponiveis,
                    var_name='periodo',
                    value_name='consumo'
                )
                df_chart = df_chart[df_chart['consumo'].notna() & (df_chart['consumo'] > 0)]

                if not df_chart.empty:
                    ordem_meses = {'jan2024': 1, 'fev2024': 2, 'mar2024': 3, 'abr2024': 4, 'mai2024': 5, 'jun2024': 6,
                                  'jul2024': 7, 'ago2024': 8, 'set2024': 9, 'out2024': 10, 'nov2024': 11, 'dez2024': 12,
                                  'jan2025': 13, 'fev2025': 14, 'mar2025': 15, 'abr2025': 16, 'mai2025': 17, 'jun2025': 18,
                                  'jul2025': 19, 'ago2025': 20, 'set2025': 21}
                    df_chart['ordem'] = df_chart['periodo'].map(ordem_meses)
                    df_chart = df_chart.sort_values('ordem')

                    # Gr√°fico de total do grupo
                    df_total = df_chart.groupby('periodo').agg({
                        'consumo': 'sum',
                        'ordem': 'first'
                    }).reset_index().sort_values('ordem')

                    fig = px.line(
                        df_total,
                        x='periodo',
                        y='consumo',
                        title="Consumo Total de Energia do Grupo (acumulado 12 meses)",
                        labels={'consumo': 'Valor (R$)', 'periodo': 'Per√≠odo'},
                        markers=True
                    )
                    fig.update_traces(line=dict(width=3, color='#f9a825'), marker=dict(size=10))
                    st.plotly_chart(fig, use_container_width=True)
                else:
                    st.info("Sem dados suficientes para gerar o gr√°fico.")
            except Exception as e:
                st.warning(f"N√£o foi poss√≠vel gerar o gr√°fico: {e}")

            # Detalhamento mensal
            if 'nf3e_detalhado' in dossie and not dossie['nf3e_detalhado'].empty:
                st.divider()
                st.write("**Detalhamento Mensal:**")
                df_det = dossie['nf3e_detalhado'].copy()
                df_det['Energia Mensal'] = df_det['vl_energia_mensal'].apply(formatar_moeda)
                st.dataframe(
                    df_det[['cnpj', 'ano_emissao', 'mes_emissao', 'Energia Mensal', 'qt_notas', 'qt_fornecedores']].rename(
                        columns={'cnpj': 'CNPJ', 'ano_emissao': 'Ano', 'mes_emissao': 'M√™s', 'qt_notas': 'Qtd. Notas', 'qt_fornecedores': 'Fornecedores'}
                    ),
                    hide_index=True,
                    use_container_width=True
                )
        else:
            st.info("Nenhum dado de consumo de energia el√©trica (NF3e) dispon√≠vel para este grupo.")

    # =========================================================================
    # TAB 12: TELECOMUNICA√á√ïES (NFCom)
    # =========================================================================
    with tab12:
        st.subheader("üì± Consumo de Telecomunica√ß√µes")

        # Verificar se h√° dados de NFCom
        if 'nfcom' in dossie and not dossie['nfcom'].empty:
            df_nfcom = dossie['nfcom'].copy()

            # M√©tricas do grupo
            if 'nfcom_metricas' in dossie and not dossie['nfcom_metricas'].empty:
                metricas = dossie['nfcom_metricas'].iloc[0]
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("Empresas Consumidoras", int(metricas.get('qt_empresas_consumidoras', 0)))
                with col2:
                    st.metric("Valor Total Telecom", formatar_moeda(metricas.get('vl_telecom_grupo', 0)))
                with col3:
                    st.metric("Qtd. Notas", int(metricas.get('qt_notas_grupo', 0)))

                st.divider()

            # Sub-tabs
            sub_tab1, sub_tab2, sub_tab3 = st.tabs(["Por CNPJ", "Por Operadora", "Detalhamento"])

            with sub_tab1:
                st.write("**Consumo de Telecomunica√ß√µes por CNPJ (acumulado 12 meses):**")

                # Pegar o √∫ltimo valor dispon√≠vel
                meses_cols = ['set2025', 'ago2025', 'jul2025', 'jun2025', 'mai2025', 'abr2025',
                             'mar2025', 'fev2025', 'jan2025', 'dez2024', 'nov2024', 'out2024']

                def get_ultimo_valor_telecom(row):
                    for mes in meses_cols:
                        if mes in row and pd.notna(row[mes]) and row[mes] > 0:
                            return row[mes]
                    return 0

                df_nfcom['ultimo_valor_12m'] = df_nfcom.apply(get_ultimo_valor_telecom, axis=1)

                # Resumo
                df_resumo_telecom = df_nfcom[['cnpj', 'ultimo_valor_12m']].copy()
                df_resumo_telecom.columns = ['CNPJ', 'Telecom 12m (R$)']
                df_resumo_telecom['Telecom Formatada'] = df_resumo_telecom['Telecom 12m (R$)'].apply(formatar_moeda)

                total_telecom = df_resumo_telecom['Telecom 12m (R$)'].sum()

                col1, col2 = st.columns(2)
                with col1:
                    st.metric("Total CNPJs com Telecom", len(df_resumo_telecom))
                with col2:
                    st.metric("Consumo Total (soma)", formatar_moeda(total_telecom))

                st.dataframe(
                    df_resumo_telecom.sort_values('Telecom 12m (R$)', ascending=False)[['CNPJ', 'Telecom Formatada']],
                    hide_index=True,
                    use_container_width=True
                )

                # Gr√°fico de evolu√ß√£o
                st.divider()
                st.write("**Evolu√ß√£o do Consumo de Telecomunica√ß√µes:**")
                try:
                    meses_disponiveis = [m for m in meses_cols if m in df_nfcom.columns]
                    df_chart = df_nfcom.melt(
                        id_vars=['cnpj'],
                        value_vars=meses_disponiveis,
                        var_name='periodo',
                        value_name='consumo'
                    )
                    df_chart = df_chart[df_chart['consumo'].notna() & (df_chart['consumo'] > 0)]

                    if not df_chart.empty:
                        ordem_meses = {'jan2024': 1, 'fev2024': 2, 'mar2024': 3, 'abr2024': 4, 'mai2024': 5, 'jun2024': 6,
                                      'jul2024': 7, 'ago2024': 8, 'set2024': 9, 'out2024': 10, 'nov2024': 11, 'dez2024': 12,
                                      'jan2025': 13, 'fev2025': 14, 'mar2025': 15, 'abr2025': 16, 'mai2025': 17, 'jun2025': 18,
                                      'jul2025': 19, 'ago2025': 20, 'set2025': 21}
                        df_chart['ordem'] = df_chart['periodo'].map(ordem_meses)
                        df_chart = df_chart.sort_values('ordem')

                        # Gr√°fico de total do grupo
                        df_total = df_chart.groupby('periodo').agg({
                            'consumo': 'sum',
                            'ordem': 'first'
                        }).reset_index().sort_values('ordem')

                        fig = px.line(
                            df_total,
                            x='periodo',
                            y='consumo',
                            title="Consumo Total de Telecomunica√ß√µes do Grupo (acumulado 12 meses)",
                            labels={'consumo': 'Valor (R$)', 'periodo': 'Per√≠odo'},
                            markers=True
                        )
                        fig.update_traces(line=dict(width=3, color='#2196f3'), marker=dict(size=10))
                        st.plotly_chart(fig, use_container_width=True)
                    else:
                        st.info("Sem dados suficientes para gerar o gr√°fico.")
                except Exception as e:
                    st.warning(f"N√£o foi poss√≠vel gerar o gr√°fico: {e}")

            with sub_tab2:
                # An√°lise por operadora
                if 'nfcom_operadoras' in dossie and not dossie['nfcom_operadoras'].empty:
                    st.write("**Consumo por Operadora de Telecomunica√ß√µes:**")
                    df_op = dossie['nfcom_operadoras'].copy()
                    df_op['Valor Total'] = df_op['vl_total'].apply(formatar_moeda)
                    st.dataframe(
                        df_op[['cnpj_operadora', 'nome_operadora', 'qt_empresas_clientes', 'Valor Total', 'qt_notas']].rename(
                            columns={
                                'cnpj_operadora': 'CNPJ Operadora',
                                'nome_operadora': 'Nome Operadora',
                                'qt_empresas_clientes': 'Empresas Clientes',
                                'qt_notas': 'Qtd. Notas'
                            }
                        ),
                        hide_index=True,
                        use_container_width=True
                    )

                    # Gr√°fico de pizza por operadora
                    try:
                        fig_pie = px.pie(
                            df_op,
                            values='vl_total',
                            names='nome_operadora',
                            title="Distribui√ß√£o do Consumo por Operadora"
                        )
                        st.plotly_chart(fig_pie, use_container_width=True)
                    except Exception as e:
                        st.warning(f"N√£o foi poss√≠vel gerar o gr√°fico: {e}")
                else:
                    st.info("Nenhum dado de operadoras dispon√≠vel.")

            with sub_tab3:
                # Detalhamento mensal
                if 'nfcom_detalhado' in dossie and not dossie['nfcom_detalhado'].empty:
                    st.write("**Detalhamento Mensal:**")
                    df_det = dossie['nfcom_detalhado'].copy()
                    df_det['Telecom Mensal'] = df_det['vl_telecom_mensal'].apply(formatar_moeda)
                    st.dataframe(
                        df_det[['cnpj', 'ano_emissao', 'mes_emissao', 'Telecom Mensal', 'qt_notas', 'qt_operadoras']].rename(
                            columns={'cnpj': 'CNPJ', 'ano_emissao': 'Ano', 'mes_emissao': 'M√™s', 'qt_notas': 'Qtd. Notas', 'qt_operadoras': 'Operadoras'}
                        ),
                        hide_index=True,
                        use_container_width=True
                    )
                else:
                    st.info("Nenhum detalhamento mensal dispon√≠vel.")
        else:
            st.info("Nenhum dado de consumo de telecomunica√ß√µes (NFCom) dispon√≠vel para este grupo.")

    # =========================================================================
    # TAB 13: AN√ÅLISE DE SIMILARIDADE - EVID√äNCIAS DE GRUPO ECON√îMICO
    # =========================================================================
    with tab13:
        st.subheader("üîç An√°lise de Similaridade - Evid√™ncias de Grupo Econ√¥mico")

        st.info("""
        Esta an√°lise verifica se os CNPJs do grupo compartilham informa√ß√µes que indicam
        forma√ß√£o de grupo econ√¥mico, conforme metodologia do Sistema GEI.
        """)

        # Inicializar vari√°veis de controle
        evidencias = {}
        score_similaridade = 0
        max_score_possivel = 0
        cnpjs_grupo = dossie['cnpjs']['cnpj'].tolist() if not dossie['cnpjs'].empty else []

        if len(cnpjs_grupo) < 2:
            st.warning("O grupo precisa ter pelo menos 2 CNPJs para an√°lise de similaridade.")
        else:
            # Criar abas para cada tipo de an√°lise
            tabs_similaridade = st.tabs([
                "üìã Cadastro",
                "üë• S√≥cios",
                "üìä Receitas",
                "üìÑ Notas Fiscais",
                "üì± Conv√™nio 115",
                "üè¶ Contas Banc√°rias",
                "üëî Funcion√°rios",
                "üí≥ Pagamentos",
                "üìä Score Final"
            ])

            # ===================================================================
            # TAB 1: AN√ÅLISE DE DADOS CADASTRAIS
            # ===================================================================
            with tabs_similaridade[0]:
                st.subheader("Consist√™ncia Cadastral")

                if not dossie['cnpjs'].empty and len(dossie['cnpjs']) > 1:
                    cadastro_checks = []

                    # Raz√£o Social
                    max_score_possivel += 2
                    if 'nm_razao_social' in dossie['cnpjs'].columns:
                        razoes = dossie['cnpjs']['nm_razao_social'].dropna().unique()
                        if len(razoes) == 1:
                            cadastro_checks.append({
                                'Atributo': 'Raz√£o Social',
                                'Status': '‚úÖ ID√äNTICA',
                                'Quantidade': '1',
                                'Pontos': 2,
                                'Avalia√ß√£o': 'CR√çTICO - Forte ind√≠cio'
                            })
                            evidencias['razao_social'] = True
                            score_similaridade += 2
                        elif len(razoes) > 1:
                            cadastro_checks.append({
                                'Atributo': 'Raz√£o Social',
                                'Status': '‚ùå DIFERENTES',
                                'Quantidade': str(len(razoes)),
                                'Pontos': 0,
                                'Avalia√ß√£o': '-'
                            })

                    # Nome Fantasia
                    max_score_possivel += 1
                    if 'nm_fantasia' in dossie['cnpjs'].columns:
                        fantasias = dossie['cnpjs']['nm_fantasia'].dropna().unique()
                        if len(fantasias) == 1 and len(str(fantasias[0])) > 0:
                            cadastro_checks.append({
                                'Atributo': 'Nome Fantasia',
                                'Status': '‚úÖ ID√äNTICO',
                                'Quantidade': '1',
                                'Pontos': 1,
                                'Avalia√ß√£o': 'Alto ind√≠cio'
                            })
                            evidencias['fantasia'] = True
                            score_similaridade += 1
                        elif len(fantasias) > 1:
                            cadastro_checks.append({
                                'Atributo': 'Nome Fantasia',
                                'Status': '‚ùå DIFERENTES',
                                'Quantidade': str(len(fantasias)),
                                'Pontos': 0,
                                'Avalia√ß√£o': '-'
                            })

                    # CNAE
                    max_score_possivel += 1
                    if 'cd_cnae' in dossie['cnpjs'].columns:
                        cnaes = dossie['cnpjs']['cd_cnae'].dropna().unique()
                        if len(cnaes) == 1:
                            cadastro_checks.append({
                                'Atributo': 'CNAE',
                                'Status': '‚úÖ ID√äNTICO',
                                'Quantidade': '1',
                                'Pontos': 1,
                                'Avalia√ß√£o': 'Mesmo ramo'
                            })
                            evidencias['cnae'] = True
                            score_similaridade += 1
                        elif len(cnaes) > 1:
                            cadastro_checks.append({
                                'Atributo': 'CNAE',
                                'Status': '‚ùå DIFERENTES',
                                'Quantidade': str(len(cnaes)),
                                'Pontos': 0,
                                'Avalia√ß√£o': '-'
                            })

                    # Contador
                    max_score_possivel += 2
                    if 'nm_contador' in dossie['cnpjs'].columns:
                        contadores = dossie['cnpjs']['nm_contador'].dropna().unique()
                        if len(contadores) == 1 and len(str(contadores[0])) > 0:
                            cadastro_checks.append({
                                'Atributo': 'Contador',
                                'Status': '‚úÖ MESMO',
                                'Quantidade': '1',
                                'Pontos': 2,
                                'Avalia√ß√£o': 'CR√çTICO - Gest√£o comum'
                            })
                            evidencias['contador'] = True
                            score_similaridade += 2
                        elif len(contadores) > 1:
                            cadastro_checks.append({
                                'Atributo': 'Contador',
                                'Status': '‚ùå DIFERENTES',
                                'Quantidade': str(len(contadores)),
                                'Pontos': 0,
                                'Avalia√ß√£o': '-'
                            })

                    # Munic√≠pio
                    max_score_possivel += 0.5
                    if 'nm_municipio' in dossie['cnpjs'].columns:
                        municipios = dossie['cnpjs']['nm_municipio'].dropna().unique()
                        if len(municipios) == 1:
                            cadastro_checks.append({
                                'Atributo': 'Munic√≠pio',
                                'Status': '‚úÖ MESMO',
                                'Quantidade': '1',
                                'Pontos': 0.5,
                                'Avalia√ß√£o': 'Ind√≠cio leve'
                            })
                            score_similaridade += 0.5
                        elif len(municipios) > 1:
                            cadastro_checks.append({
                                'Atributo': 'Munic√≠pio',
                                'Status': '‚ùå DIFERENTES',
                                'Quantidade': str(len(municipios)),
                                'Pontos': 0,
                                'Avalia√ß√£o': '-'
                            })

                    # Regime de Apura√ß√£o
                    max_score_possivel += 1
                    if 'nm_reg_apuracao' in dossie['cnpjs'].columns:
                        regimes = dossie['cnpjs']['nm_reg_apuracao'].dropna().unique()
                        if len(regimes) == 1:
                            cadastro_checks.append({
                                'Atributo': 'Regime Tribut√°rio',
                                'Status': '‚úÖ MESMO',
                                'Quantidade': str(regimes[0]),
                                'Pontos': 1,
                                'Avalia√ß√£o': 'Mesmo regime'
                            })
                            score_similaridade += 1
                        elif len(regimes) > 1:
                            cadastro_checks.append({
                                'Atributo': 'Regime Tribut√°rio',
                                'Status': '‚ö†Ô∏è MISTO',
                                'Quantidade': str(len(regimes)),
                                'Pontos': 0,
                                'Avalia√ß√£o': 'Poss√≠vel planejamento'
                            })

                    if cadastro_checks:
                        df_cadastro = pd.DataFrame(cadastro_checks)
                        st.dataframe(df_cadastro, width='stretch', hide_index=True)

                        pontos_cadastro = df_cadastro['Pontos'].sum()
                        if pontos_cadastro >= 5:
                            st.error(f"üî¥ CR√çTICO: {pontos_cadastro:.1f} pontos - Forte evid√™ncia de grupo econ√¥mico")
                        elif pontos_cadastro >= 3:
                            st.warning(f"üü° ALTO: {pontos_cadastro:.1f} pontos - Evid√™ncia significativa")
                        elif pontos_cadastro >= 1:
                            st.info(f"üü† MODERADO: {pontos_cadastro:.1f} pontos")
                        else:
                            st.success(f"üü¢ BAIXO: {pontos_cadastro:.1f} pontos")
                else:
                    st.warning("Dados cadastrais insuficientes para an√°lise")

            # ===================================================================
            # TAB 2: AN√ÅLISE DE V√çNCULOS SOCIET√ÅRIOS
            # ===================================================================
            with tabs_similaridade[1]:
                st.subheader("An√°lise de V√≠nculos Societ√°rios")

                if not dossie['socios'].empty:
                    socios_checks = []

                    # S√≥cios compartilhados (j√° calculados no dossi√™)
                    max_score_possivel += 5
                    total_socios = len(dossie['socios'])

                    if total_socios > 0:
                        pontos_socios = min(total_socios * 2, 5)

                        socios_checks.append({
                            'Indicador': 'S√≥cios Compartilhados',
                            'Quantidade': str(total_socios),
                            'Status': '‚úÖ DETECTADOS',
                            'Pontos': str(pontos_socios),
                            'Avalia√ß√£o': 'CR√çTICO - V√≠nculos cruzados'
                        })

                        evidencias['socios_compartilhados'] = True
                        score_similaridade += pontos_socios

                        # Detalhar os s√≥cios compartilhados
                        st.write("**S√≥cios que participam de m√∫ltiplos CNPJs:**")
                        for _, row in dossie['socios'].iterrows():
                            cpf = row.get('cpf_socio', 'N/A')
                            qtd = row.get('qtd_empresas', 0)
                            st.write(f"‚Ä¢ **CPF {cpf}**: Presente em {qtd} empresas do grupo")
                    else:
                        socios_checks.append({
                            'Indicador': 'S√≥cios Compartilhados',
                            'Quantidade': '0',
                            'Status': '‚ùå N√ÉO DETECTADO',
                            'Pontos': '0',
                            'Avalia√ß√£o': '-'
                        })

                    df_socios = pd.DataFrame(socios_checks)
                    for col in df_socios.columns:
                        df_socios[col] = df_socios[col].astype(str)

                    st.dataframe(df_socios, hide_index=True)

                    # Calcular pontos
                    pontos_numericos = df_socios[df_socios['Pontos'] != '-']['Pontos'].astype(float)
                    pontos_socios_total = pontos_numericos.sum() if len(pontos_numericos) > 0 else 0

                    if pontos_socios_total >= 4:
                        st.error(f"üî¥ CR√çTICO: {pontos_socios_total:.1f} pontos - Controle societ√°rio compartilhado")
                    elif pontos_socios_total >= 2:
                        st.warning(f"üü° ALTO: {pontos_socios_total:.1f} pontos")
                    else:
                        st.info(f"üü¢ BAIXO: {pontos_socios_total:.1f} pontos")
                else:
                    st.warning("Dados de v√≠nculos societ√°rios insuficientes")

            # ===================================================================
            # TAB 3: AN√ÅLISE DE RECEITAS (PGDAS + DIME)
            # ===================================================================
            with tabs_similaridade[2]:
                st.subheader("An√°lise de Faturamento - PGDAS / DIME")

                if 'faturamento' in dossie and not dossie['faturamento'].empty:
                    df_fat = dossie['faturamento'].copy()
                    receitas_checks = []

                    # Informa√ß√£o sobre fontes de dados
                    fontes_disponiveis = df_fat['fonte'].unique().tolist() if 'fonte' in df_fat.columns else ['PGDAS']
                    st.info(f"**Fontes de dados utilizadas:** {', '.join(fontes_disponiveis)}")

                    # M√©tricas por fonte
                    col_f1, col_f2 = st.columns(2)
                    with col_f1:
                        cnpjs_pgdas = len(df_fat[df_fat['fonte'] == 'PGDAS']) if 'PGDAS' in fontes_disponiveis else 0
                        st.metric("CNPJs com PGDAS (Simples)", cnpjs_pgdas)
                    with col_f2:
                        cnpjs_dime = len(df_fat[df_fat['fonte'] == 'DIME']) if 'DIME' in fontes_disponiveis else 0
                        st.metric("CNPJs com DIME (Normal)", cnpjs_dime)

                    # Calcular receita m√°xima por CNPJ
                    meses_cols = ['set2025', 'ago2025', 'jul2025', 'jun2025', 'mai2025', 'abr2025', 'mar2025', 'fev2025', 'jan2025']
                    meses_disponiveis = [m for m in meses_cols if m in df_fat.columns]

                    if meses_disponiveis:
                        # Pegar o √∫ltimo valor n√£o-zero para cada CNPJ
                        def get_ultimo_valor(row):
                            for mes in meses_disponiveis:
                                if mes in row and pd.notna(row[mes]) and row[mes] > 0:
                                    return row[mes]
                            return 0

                        df_fat['receita_max'] = df_fat.apply(get_ultimo_valor, axis=1)
                        receitas_por_cnpj = df_fat.groupby('cnpj')['receita_max'].max()
                        receita_total_grupo = receitas_por_cnpj.sum()
                        receita_media = receitas_por_cnpj.mean() if len(receitas_por_cnpj) > 0 else 0

                        # Receita somada ultrapassa limite
                        max_score_possivel += 5
                        if receita_total_grupo > 4800000:
                            excesso = receita_total_grupo - 4800000
                            pontos_receita = 5
                            receitas_checks.append({
                                'Indicador': 'Receita Total do Grupo',
                                'Valor': formatar_moeda(receita_total_grupo),
                                'Status': 'üî¥ ACIMA DO LIMITE',
                                'Excesso': formatar_moeda(excesso),
                                'Pontos': str(pontos_receita),
                                'Avalia√ß√£o': 'CR√çTICO - Fracionamento'
                            })
                            evidencias['receita_excesso'] = True
                            score_similaridade += pontos_receita

                            st.error(f"""
                            **üî¥ ALERTA CR√çTICO - LIMITE ULTRAPASSADO**

                            Receita somada (PGDAS + DIME): **{formatar_moeda(receita_total_grupo)}**

                            Excesso: **{formatar_moeda(excesso)}** ({((excesso/4800000)*100):.1f}% acima do limite)
                            """)
                        else:
                            receitas_checks.append({
                                'Indicador': 'Receita Total do Grupo',
                                'Valor': formatar_moeda(receita_total_grupo),
                                'Status': '‚úÖ DENTRO DO LIMITE',
                                'Excesso': '-',
                                'Pontos': '0',
                                'Avalia√ß√£o': '-'
                            })

                        # Distribui√ß√£o equilibrada
                        max_score_possivel += 2
                        if len(receitas_por_cnpj) > 1:
                            desvio_padrao = receitas_por_cnpj.std()
                            coef_variacao = (desvio_padrao / receita_media) if receita_media > 0 else 0

                            if coef_variacao < 0.3:
                                receitas_checks.append({
                                    'Indicador': 'Distribui√ß√£o de Receitas',
                                    'Valor': f"CV: {coef_variacao:.2f}",
                                    'Status': '‚ö†Ô∏è MUITO UNIFORME',
                                    'Excesso': '-',
                                    'Pontos': '2',
                                    'Avalia√ß√£o': 'Poss√≠vel divis√£o planejada'
                                })
                                evidencias['receita_uniforme'] = True
                                score_similaridade += 2
                            else:
                                receitas_checks.append({
                                    'Indicador': 'Distribui√ß√£o de Receitas',
                                    'Valor': f"CV: {coef_variacao:.2f}",
                                    'Status': '‚úÖ VARIADA',
                                    'Excesso': '-',
                                    'Pontos': '0',
                                    'Avalia√ß√£o': '-'
                                })

                        # An√°lise de regimes mistos
                        if 'fonte' in df_fat.columns and len(df_fat['fonte'].unique()) > 1:
                            receitas_checks.append({
                                'Indicador': 'Regimes Tribut√°rios',
                                'Valor': f"{len(df_fat['fonte'].unique())} regimes",
                                'Status': '‚ö†Ô∏è MISTO',
                                'Excesso': '-',
                                'Pontos': '1',
                                'Avalia√ß√£o': 'Poss√≠vel planejamento tribut√°rio'
                            })
                            score_similaridade += 1

                        if receitas_checks:
                            df_receitas = pd.DataFrame(receitas_checks)
                            for col in df_receitas.columns:
                                df_receitas[col] = df_receitas[col].astype(str)
                            st.dataframe(df_receitas, hide_index=True)

                        # Gr√°fico de distribui√ß√£o
                        st.write("**Distribui√ß√£o de Receitas por CNPJ:**")
                        df_bar = df_fat.groupby(['cnpj', 'fonte'])['receita_max'].max().reset_index()

                        fig1 = px.bar(
                            df_bar,
                            x='cnpj',
                            y='receita_max',
                            color='fonte' if 'fonte' in df_bar.columns else None,
                            labels={'cnpj': 'CNPJ', 'receita_max': 'Receita (R$)', 'fonte': 'Fonte'},
                            title="Receita M√°xima por CNPJ e Fonte",
                            template=filtros['tema'],
                            barmode='group'
                        )
                        fig1.add_hline(y=4800000, line_dash="dash", line_color="red",
                                     annotation_text="Limite SN")
                        st.plotly_chart(fig1, use_container_width=True)
                else:
                    st.warning("Dados de receitas insuficientes (PGDAS ou DIME)")

            # ===================================================================
            # TAB 4: AN√ÅLISE DE NOTAS FISCAIS
            # ===================================================================
            with tabs_similaridade[3]:
                st.subheader("Compartilhamento em Notas Fiscais")

                if not dossie['inconsistencias'].empty:
                    nfe_checks = []
                    df_nfe = dossie['inconsistencias']

                    # Verificar inconsist√™ncias detectadas
                    tipos_incons = {
                        'ip_transmissao_incons': ('IPs de Transmiss√£o', 3),
                        'cliente_incons': ('Clientes Comuns', 2),
                        'fornecedor_incons': ('Fornecedores Comuns', 2),
                        'codigo_produto_incons': ('C√≥digos de Produto', 1),
                        'descricao_produto_incons': ('Descri√ß√µes de Produto', 1),
                        'tel_emit_incons': ('Telefones Emitente', 2),
                        'email_incons': ('E-mails Destinat√°rio', 1),
                        'end_emit_incons': ('Endere√ßo de Emiss√£o', 2),
                        'end_dest_incons': ('Endere√ßo de Destino', 2)
                    }

                    for campo, (label, pontos_max) in tipos_incons.items():
                        if campo in df_nfe.columns:
                            max_score_possivel += pontos_max
                            qtd_incons = len(df_nfe[df_nfe[campo] == 'S'])

                            if qtd_incons > 0:
                                pontos = min(qtd_incons / 10, pontos_max)
                                nfe_checks.append({
                                    'Indicador': label,
                                    'Quantidade': qtd_incons,
                                    'Status': '‚úÖ DETECTADOS',
                                    'Pontos': round(pontos, 1),
                                    'Avalia√ß√£o': 'Compartilhamento detectado'
                                })
                                evidencias[campo] = True
                                score_similaridade += pontos
                            else:
                                nfe_checks.append({
                                    'Indicador': label,
                                    'Quantidade': 0,
                                    'Status': '‚ùå N√ÉO DETECTADOS',
                                    'Pontos': 0,
                                    'Avalia√ß√£o': '-'
                                })

                    if nfe_checks:
                        df_nfe_check = pd.DataFrame(nfe_checks)
                        st.dataframe(df_nfe_check, width='stretch', hide_index=True)

                        pontos_nfe = df_nfe_check['Pontos'].sum()
                        if pontos_nfe >= 5:
                            st.error(f"üî¥ CR√çTICO: {pontos_nfe:.1f} pontos - Opera√ß√µes fortemente interligadas")
                        elif pontos_nfe >= 3:
                            st.warning(f"üü° ALTO: {pontos_nfe:.1f} pontos")
                        else:
                            st.info(f"üü¢ MODERADO: {pontos_nfe:.1f} pontos")
                else:
                    st.warning("Dados de notas fiscais insuficientes")

            # ===================================================================
            # TAB 5: AN√ÅLISE DE CONV√äNIO 115
            # ===================================================================
            with tabs_similaridade[4]:
                st.subheader("An√°lise Conv√™nio 115 - Identificadores Compartilhados")

                if not dossie['c115'].empty:
                    c115_checks = []
                    info_c115 = dossie['c115'].iloc[0]

                    # Verificar dados do C115
                    max_score_possivel += 3
                    total_compartilhamentos = info_c115.get('total_compartilhamentos', 0)

                    if pd.notna(total_compartilhamentos) and total_compartilhamentos > 0:
                        pontos_c115 = min(total_compartilhamentos / 5, 3)
                        c115_checks.append({
                            'Indicador': 'Compartilhamentos C115',
                            'Quantidade': int(total_compartilhamentos),
                            'Status': '‚úÖ DETECTADOS',
                            'Pontos': round(pontos_c115, 1),
                            'Avalia√ß√£o': 'CR√çTICO - Identificadores compartilhados'
                        })
                        evidencias['c115_compartilhamento'] = True
                        score_similaridade += pontos_c115
                    else:
                        c115_checks.append({
                            'Indicador': 'Compartilhamentos C115',
                            'Quantidade': 0,
                            'Status': '‚ùå N√ÉO DETECTADOS',
                            'Pontos': 0,
                            'Avalia√ß√£o': '-'
                        })

                    # N√≠vel de risco C115
                    nivel_risco = info_c115.get('nivel_risco_grupo_economico', 'N/A')
                    indice_risco = info_c115.get('indice_risco_grupo_economico', 0)

                    col1, col2 = st.columns(2)
                    with col1:
                        st.metric("N√≠vel de Risco C115", str(nivel_risco))
                    with col2:
                        st.metric("√çndice de Risco", f"{indice_risco:.4f}" if pd.notna(indice_risco) else "N/A")

                    if c115_checks:
                        df_c115 = pd.DataFrame(c115_checks)
                        st.dataframe(df_c115, width='stretch', hide_index=True)
                else:
                    st.warning("Dados do Conv√™nio 115 insuficientes")

            # ===================================================================
            # TAB 6: AN√ÅLISE DE CONTAS BANC√ÅRIAS (CCS)
            # ===================================================================
            with tabs_similaridade[5]:
                st.subheader("An√°lise de Contas Banc√°rias - CCS")

                if not dossie['ccs_compartilhadas'].empty:
                    ccs_checks = []

                    # CPFs compartilhando acesso a contas
                    max_score_possivel += 4
                    total_cpfs = len(dossie['ccs_compartilhadas'])

                    if total_cpfs > 0:
                        pontos_ccs = min(total_cpfs * 2, 4)
                        ccs_checks.append({
                            'Indicador': 'CPFs com M√∫ltiplas Contas',
                            'Quantidade': total_cpfs,
                            'Status': '‚úÖ DETECTADOS',
                            'Pontos': pontos_ccs,
                            'Avalia√ß√£o': 'CR√çTICO - Gest√£o financeira comum'
                        })
                        evidencias['ccs_cpf_compartilhado'] = True
                        score_similaridade += pontos_ccs

                        st.write("**CPFs com Acesso a M√∫ltiplas Contas:**")
                        for _, row in dossie['ccs_compartilhadas'].head(10).iterrows():
                            cpf = row.get('nr_cpf', 'N/A')
                            qtd = row.get('qtd_cnpjs_usando_conta', 0)
                            banco = row.get('nm_banco', 'N/A')
                            st.write(f"‚Ä¢ CPF {cpf}: {qtd} CNPJs - Banco: {banco}")
                    else:
                        ccs_checks.append({
                            'Indicador': 'CPFs com M√∫ltiplas Contas',
                            'Quantidade': 0,
                            'Status': '‚ùå N√ÉO DETECTADOS',
                            'Pontos': 0,
                            'Avalia√ß√£o': '-'
                        })

                    # Sobreposi√ß√µes de respons√°veis
                    max_score_possivel += 2
                    if not dossie['ccs_sobreposicoes'].empty:
                        total_sobreposicoes = len(dossie['ccs_sobreposicoes'])
                        pontos_sob = min(total_sobreposicoes, 2)
                        ccs_checks.append({
                            'Indicador': 'Sobreposi√ß√µes de Respons√°veis',
                            'Quantidade': total_sobreposicoes,
                            'Status': '‚úÖ DETECTADOS',
                            'Pontos': pontos_sob,
                            'Avalia√ß√£o': 'Gest√£o simult√¢nea'
                        })
                        score_similaridade += pontos_sob

                    if ccs_checks:
                        df_ccs = pd.DataFrame(ccs_checks)
                        st.dataframe(df_ccs, width='stretch', hide_index=True)

                        pontos_ccs_total = df_ccs['Pontos'].sum()
                        if pontos_ccs_total >= 4:
                            st.error(f"üî¥ CR√çTICO: {pontos_ccs_total:.1f} pontos - Contas fortemente relacionadas")
                        elif pontos_ccs_total >= 2:
                            st.warning(f"üü° ALTO: {pontos_ccs_total:.1f} pontos")
                        else:
                            st.info(f"üü¢ BAIXO: {pontos_ccs_total:.1f} pontos")
                else:
                    st.warning("Dados de contas banc√°rias insuficientes")

            # ===================================================================
            # TAB 7: AN√ÅLISE DE FUNCION√ÅRIOS
            # ===================================================================
            with tabs_similaridade[6]:
                st.subheader("An√°lise de Funcion√°rios - RAIS/CAGED")

                if not dossie['funcionarios'].empty:
                    func_checks = []
                    info_func = dossie['funcionarios'].iloc[0]

                    total_funcionarios = info_func.get('total_funcionarios', 0)
                    cnpjs_com_func = info_func.get('cnpjs_com_funcionarios', 0)

                    col1, col2 = st.columns(2)
                    with col1:
                        st.metric("Total de Funcion√°rios", int(total_funcionarios) if pd.notna(total_funcionarios) else 0)
                    with col2:
                        st.metric("CNPJs com Funcion√°rios", int(cnpjs_com_func) if pd.notna(cnpjs_com_func) else 0)

                    # Verificar propor√ß√£o receita vs funcion√°rios
                    max_score_possivel += 3
                    if not dossie['principal'].empty and pd.notna(total_funcionarios) and total_funcionarios > 0:
                        info_principal = dossie['principal'].iloc[0]
                        receita_max = info_principal.get('valor_max', 0)

                        if pd.notna(receita_max) and receita_max > 0:
                            receita_por_func = receita_max / (total_funcionarios + 1)

                            if receita_por_func > 500000:
                                func_checks.append({
                                    'Indicador': 'Receita por Funcion√°rio',
                                    'Valor': formatar_moeda(receita_por_func),
                                    'Status': '‚ö†Ô∏è DESPROPORCIONAL',
                                    'Pontos': 2,
                                    'Avalia√ß√£o': 'Poss√≠vel terceiriza√ß√£o'
                                })
                                score_similaridade += 2
                            else:
                                func_checks.append({
                                    'Indicador': 'Receita por Funcion√°rio',
                                    'Valor': formatar_moeda(receita_por_func),
                                    'Status': '‚úÖ PROPORCIONAL',
                                    'Pontos': 0,
                                    'Avalia√ß√£o': '-'
                                })

                    if func_checks:
                        df_func = pd.DataFrame(func_checks)
                        st.dataframe(df_func, width='stretch', hide_index=True)
                    else:
                        st.success("‚úÖ Propor√ß√£o receita/funcion√°rios dentro do esperado")
                else:
                    st.warning("Dados de funcion√°rios insuficientes")

            # ===================================================================
            # TAB 8: AN√ÅLISE DE MEIOS DE PAGAMENTO
            # ===================================================================
            with tabs_similaridade[7]:
                st.subheader("An√°lise de Meios de Pagamento")

                if not dossie['pagamentos'].empty:
                    pag_checks = []
                    info_pag = dossie['pagamentos'].iloc[0]

                    valor_empresas = info_pag.get('valor_meios_pagamento_empresas', 0)
                    valor_socios = info_pag.get('valor_meios_pagamento_socios', 0)

                    col1, col2 = st.columns(2)
                    with col1:
                        st.metric("Pagamentos Empresas", formatar_moeda(valor_empresas) if pd.notna(valor_empresas) else "R$ 0,00")
                    with col2:
                        st.metric("Pagamentos S√≥cios", formatar_moeda(valor_socios) if pd.notna(valor_socios) else "R$ 0,00")

                    # Verificar se s√≥cios t√™m meios de pagamento
                    max_score_possivel += 2
                    if pd.notna(valor_socios) and valor_socios > 0:
                        pag_checks.append({
                            'Indicador': 'S√≥cios com Meios Pagamento',
                            'Valor': formatar_moeda(valor_socios),
                            'Status': '‚úÖ DETECTADOS',
                            'Pontos': 2,
                            'Avalia√ß√£o': 'Gest√£o financeira comum'
                        })
                        evidencias['socios_meios_pagamento'] = True
                        score_similaridade += 2
                    else:
                        pag_checks.append({
                            'Indicador': 'S√≥cios com Meios Pagamento',
                            'Valor': 'R$ 0,00',
                            'Status': '‚ùå N√ÉO DETECTADOS',
                            'Pontos': 0,
                            'Avalia√ß√£o': '-'
                        })

                    if pag_checks:
                        df_pag = pd.DataFrame(pag_checks)
                        st.dataframe(df_pag, width='stretch', hide_index=True)
                else:
                    st.warning("Dados de meios de pagamento insuficientes")

            # ===================================================================
            # TAB 9: SCORE FINAL E CONCLUS√ÉO
            # ===================================================================
            with tabs_similaridade[8]:
                st.subheader("üìä Score Final de Similaridade")

                # M√©tricas principais
                col1, col2, col3, col4 = st.columns(4)

                with col1:
                    st.metric("Score Total", f"{score_similaridade:.1f}",
                             help="Pontua√ß√£o total baseada em todas as evid√™ncias")

                with col2:
                    st.metric("Score M√°ximo Poss√≠vel", f"{max_score_possivel:.1f}",
                             help="Pontua√ß√£o m√°xima com base nos dados dispon√≠veis")

                with col3:
                    percentual = (score_similaridade / max_score_possivel * 100) if max_score_possivel > 0 else 0
                    st.metric("Percentual", f"{percentual:.1f}%",
                             help="Percentual do score em rela√ß√£o ao m√°ximo")

                with col4:
                    total_evidencias = len([v for v in evidencias.values() if v])
                    st.metric("Evid√™ncias", total_evidencias,
                             help="N√∫mero de evid√™ncias positivas encontradas")

                # Determina√ß√£o do n√≠vel de risco
                st.divider()

                if score_similaridade >= 15:
                    nivel_risco = "üî¥ CR√çTICO"
                    cor_risco = "error"
                    conclusao = """
                    **FORTE EVID√äNCIA DE GRUPO ECON√îMICO**

                    Os CNPJs analisados apresentam m√∫ltiplas e graves evid√™ncias de pertencerem ao mesmo
                    grupo econ√¥mico. As similaridades detectadas em dados cadastrais, v√≠nculos societ√°rios,
                    padr√µes operacionais e indicadores fiscais sugerem fortemente opera√ß√£o coordenada e
                    gest√£o centralizada.

                    **RECOMENDA√á√ÉO URGENTE:**
                    - An√°lise aprofundada de poss√≠vel planejamento tribut√°rio abusivo
                    - Verifica√ß√£o de fraude √† lei (fracionamento artificial)
                    - Intima√ß√£o dos contribuintes para esclarecimentos
                    - Considerar procedimento fiscal conjunto
                    """
                elif score_similaridade >= 10:
                    nivel_risco = "üü° ALTO"
                    cor_risco = "warning"
                    conclusao = """
                    **EVID√äNCIA SIGNIFICATIVA DE GRUPO ECON√îMICO**

                    Os CNPJs apresentam v√°rias caracter√≠sticas compat√≠veis com grupo econ√¥mico.
                    As evid√™ncias encontradas justificam investiga√ß√£o mais aprofundada.

                    **RECOMENDA√á√ÉO:**
                    - An√°lise complementar com dados adicionais
                    - Solicitar documenta√ß√£o adicional aos contribuintes
                    - Monitoramento refor√ßado nos pr√≥ximos per√≠odos
                    - Verificar hist√≥rico de altera√ß√µes cadastrais
                    """
                elif score_similaridade >= 5:
                    nivel_risco = "üü† MODERADO"
                    cor_risco = "info"
                    conclusao = """
                    **IND√çCIOS MODERADOS DE GRUPO ECON√îMICO**

                    Alguns ind√≠cios sugerem poss√≠vel vincula√ß√£o entre os CNPJs, mas n√£o s√£o conclusivos.
                    Recomenda-se monitoramento e coleta de evid√™ncias adicionais.

                    **RECOMENDA√á√ÉO:**
                    - Monitoramento peri√≥dico dos CNPJs
                    - Aten√ß√£o a novos ind√≠cios que possam surgir
                    - Cruzamento com outras bases de dados
                    - Acompanhar evolu√ß√£o das receitas
                    """
                else:
                    nivel_risco = "üü¢ BAIXO"
                    cor_risco = "success"
                    conclusao = """
                    **BAIXA EVID√äNCIA DE GRUPO ECON√îMICO**

                    Com base nos dados analisados, n√£o foram encontradas evid√™ncias significativas de que
                    os CNPJs perten√ßam ao mesmo grupo econ√¥mico. As similaridades detectadas podem ser
                    coincid√™ncias ou caracter√≠sticas comuns do setor.

                    **RECOMENDA√á√ÉO:**
                    - Monitoramento de rotina conforme procedimentos padr√£o
                    - Aten√ß√£o caso surjam novos ind√≠cios futuramente
                    """

                # Exibir n√≠vel de risco
                if cor_risco == "error":
                    st.error(f"**N√≠vel de Risco: {nivel_risco}**")
                elif cor_risco == "warning":
                    st.warning(f"**N√≠vel de Risco: {nivel_risco}**")
                elif cor_risco == "info":
                    st.info(f"**N√≠vel de Risco: {nivel_risco}**")
                else:
                    st.success(f"**N√≠vel de Risco: {nivel_risco}**")

                # Conclus√£o detalhada
                st.markdown("### üéØ Conclus√£o da An√°lise")
                st.markdown(conclusao)

                # Tabela resumo de evid√™ncias
                if evidencias:
                    st.markdown("### üìã Resumo das Evid√™ncias Encontradas")

                    categorias_evidencias = {
                        'Cadastrais': ['razao_social', 'fantasia', 'cnae', 'contador'],
                        'Societ√°rias': ['socios_compartilhados'],
                        'Fiscais': ['receita_excesso', 'receita_uniforme'],
                        'Operacionais NFe': ['ip_transmissao_incons', 'cliente_incons', 'fornecedor_incons', 'codigo_produto_incons', 'tel_emit_incons', 'email_incons', 'end_emit_incons', 'end_dest_incons'],
                        'C115': ['c115_compartilhamento'],
                        'Financeiras': ['ccs_cpf_compartilhado', 'socios_meios_pagamento']
                    }

                    resumo_evidencias = []
                    for categoria, chaves in categorias_evidencias.items():
                        evidencias_categoria = [k for k in chaves if evidencias.get(k, False)]
                        if evidencias_categoria:
                            resumo_evidencias.append({
                                'Categoria': categoria,
                                'Quantidade': len(evidencias_categoria),
                                'Evid√™ncias': ', '.join([k.replace('_', ' ').title() for k in evidencias_categoria])
                            })

                    if resumo_evidencias:
                        df_resumo = pd.DataFrame(resumo_evidencias)
                        st.dataframe(df_resumo, width='stretch', hide_index=True)

                # Gr√°fico de distribui√ß√£o de pontos
                st.markdown("### üìà Distribui√ß√£o de Pontos por Categoria")

                categorias_pontos = {
                    'Cadastro': sum([2 if evidencias.get('razao_social') else 0,
                                    1 if evidencias.get('fantasia') else 0,
                                    1 if evidencias.get('cnae') else 0,
                                    2 if evidencias.get('contador') else 0]),
                    'S√≥cios': 5 if evidencias.get('socios_compartilhados') else 0,
                    'Receitas': sum([5 if evidencias.get('receita_excesso') else 0,
                                    2 if evidencias.get('receita_uniforme') else 0]),
                    'NFe': sum([3 if evidencias.get('ip_transmissao_incons') else 0,
                               2 if evidencias.get('cliente_incons') else 0,
                               2 if evidencias.get('fornecedor_incons') else 0,
                               1 if evidencias.get('codigo_produto_incons') else 0]),
                    'C115': 3 if evidencias.get('c115_compartilhamento') else 0,
                    'CCS': 4 if evidencias.get('ccs_cpf_compartilhado') else 0
                }

                df_categorias = pd.DataFrame([
                    {'Categoria': k, 'Pontos': v}
                    for k, v in categorias_pontos.items() if v > 0
                ])

                if not df_categorias.empty:
                    fig = px.bar(df_categorias, x='Categoria', y='Pontos',
                                title="Pontos por Categoria de Evid√™ncia",
                                template=filtros['tema'],
                                color='Pontos',
                                color_continuous_scale='Reds')
                    st.plotly_chart(fig, use_container_width=True)

    # =========================================================================
    # TAB 14: EXPORTA√á√ÉO
    # =========================================================================
    with tab14:
        st.subheader("Exporta√ß√£o de Relat√≥rio")
        
        st.write("""
        Clique no bot√£o abaixo para gerar um relat√≥rio em PDF com todas as informa√ß√µes 
        consolidadas deste grupo.
        """)
        
        col1, col2, col3 = st.columns([1, 1, 1])
        
        with col2:
            if st.button("üìÑ Gerar PDF do Dossi√™", type="primary", key="gerar_pdf"):
                # Container para o progresso
                progress_container = st.container()
                
                with progress_container:
                    # Barra de progresso
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    
                    try:
                        status_text.text("Iniciando gera√ß√£o do PDF...")
                        progress_bar.progress(10)
                        
                        status_text.text("Coletando dados do grupo...")
                        progress_bar.progress(30)
                        
                        status_text.text("Organizando informa√ß√µes...")
                        progress_bar.progress(50)
                        
                        status_text.text("Gerando documento PDF...")
                        progress_bar.progress(70)
                        
                        pdf_buffer = gerar_pdf_dossie(dossie, grupo_selecionado)
                        
                        progress_bar.progress(90)
                        status_text.text("Finalizando...")
                        
                        progress_bar.progress(100)
                        status_text.text("PDF gerado com sucesso!")
                        
                        st.success("‚úÖ PDF gerado com sucesso!")
                        
                        # Bot√£o de download autom√°tico
                        st.download_button(
                            label="‚¨áÔ∏è Download PDF",
                            data=pdf_buffer,
                            file_name=f"dossie_grupo_{grupo_selecionado}_{datetime.now().strftime('%Y%m%d_%H%M')}.pdf",
                            mime="application/pdf",
                            key="download_pdf"
                        )
                        
                        # Limpar progresso ap√≥s sucesso
                        import time
                        time.sleep(2)
                        progress_bar.empty()
                        status_text.empty()
                        
                    except Exception as e:
                        st.error(f"Erro ao gerar PDF: {e}")
                        progress_bar.empty()
                        status_text.empty()
        
        st.divider()
        
        # Informa√ß√µes sobre o relat√≥rio
        st.write("**O que inclui o relat√≥rio PDF:**")
        st.write("‚Ä¢ Informa√ß√µes principais e m√©tricas do grupo")
        st.write("‚Ä¢ Lista completa de CNPJs com dados cadastrais")
        st.write("‚Ä¢ V√≠nculos societ√°rios detalhados")
        st.write("‚Ä¢ Todos os ind√≠cios fiscais identificados")
        st.write("‚Ä¢ An√°lise financeira completa")
        st.write("‚Ä¢ Dados de funcion√°rios e meios de pagamento")
        st.write("‚Ä¢ Informa√ß√µes do Conv√™nio 115")
        st.write("‚Ä¢ Informa√ß√µes CCS (Contas Compartilhadas)")
        st.write("‚Ä¢ Inconsist√™ncias de NFe detalhadas com exemplos por tipo")

def menu_analises(engine, dados, filtros):
    """An√°lises avan√ßadas e insights estrat√©gicos"""
    st.markdown("<h1 class='main-header'>An√°lises Avan√ßadas</h1>", unsafe_allow_html=True)
    
    st.info("Consultas anal√≠ticas e insights estrat√©gicos do sistema GEI")
    
    score_col = 'score_final_ccs' if 'score_final_ccs' in dados['percent'].columns else 'score_final_avancado'
    
    # ==========================================================================
    # SE√á√ÉO 1: PANORAMA GERAL DO SISTEMA
    # ==========================================================================
    with st.expander("üìä Panorama Geral do Sistema", expanded=False):
        st.subheader("Panorama Geral do Sistema GEI")
        
        query = f"""
        SELECT 
            'PANORAMA GERAL DO SISTEMA GEI' AS categoria,
            COUNT(DISTINCT num_grupo) AS total_grupos_monitorados,
            COUNT(DISTINCT CASE WHEN qntd_cnpj >= 2 THEN num_grupo END) AS grupos_multiplas_empresas,
            SUM(qntd_cnpj) AS total_cnpjs_monitorados,
            COUNT(DISTINCT CASE WHEN {score_col} >= 20 THEN num_grupo END) AS grupos_risco_critico,
            COUNT(DISTINCT CASE WHEN {score_col} >= 15 AND {score_col} < 20 THEN num_grupo END) AS grupos_risco_alto,
            COUNT(DISTINCT CASE WHEN {score_col} >= 10 AND {score_col} < 15 THEN num_grupo END) AS grupos_risco_medio,
            ROUND(COUNT(DISTINCT CASE WHEN {score_col} >= 15 THEN num_grupo END) * 100.0 / 
                  COUNT(DISTINCT num_grupo), 2) AS perc_grupos_alto_risco,
            SUM(COALESCE(valor_max, 0)) AS receita_bruta_total_monitorada,
            COUNT(DISTINCT CASE WHEN valor_max >= 4800000 THEN num_grupo END) AS grupos_acima_limite_sn,
            AVG(total) AS media_inconsistencias_nfe,
            COUNT(DISTINCT CASE WHEN total >= 5 THEN num_grupo END) AS grupos_alta_inconsistencia,
            AVG(COALESCE(indice_interconexao, 0)) AS indice_interconexao_medio,
            COUNT(DISTINCT CASE WHEN qtd_socios_compartilhados > 0 THEN num_grupo END) AS grupos_socios_compartilhados,
            COUNT(DISTINCT CASE WHEN nivel_risco_grupo_economico IS NOT NULL THEN num_grupo END) AS grupos_com_dados_c115,
            COUNT(DISTINCT CASE WHEN qtd_total_indicios > 0 THEN num_grupo END) AS grupos_com_indicios,
            AVG(COALESCE(qtd_total_indicios, 0)) AS media_indicios_por_grupo,
            COUNT(DISTINCT CASE WHEN indice_risco_ccs > 0 THEN num_grupo END) AS grupos_com_dados_ccs,
            AVG(COALESCE(indice_risco_ccs, 0)) AS media_indice_ccs
        FROM gessimples.gei_percent
        """
        
        df_result = executar_query_analise(engine, "Panorama Geral", query)
        
        if not df_result.empty:
            info = df_result.iloc[0]
            
            # M√©tricas em cards
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("Total Grupos", f"{int(info['total_grupos_monitorados']):,}")
            with col2:
                st.metric("Total CNPJs", f"{int(info['total_cnpjs_monitorados']):,}")
            with col3:
                st.metric("Grupos Cr√≠ticos", f"{int(info['grupos_risco_critico']):,}")
            with col4:
                st.metric("% Alto Risco", f"{info['perc_grupos_alto_risco']:.1f}%")
            
            st.divider()
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Receita Total", formatar_moeda(info['receita_bruta_total_monitorada']))
            with col2:
                st.metric("Acima Limite SN", f"{int(info['grupos_acima_limite_sn']):,}")
            with col3:
                st.metric("M√©dia Ind√≠cios/Grupo", f"{info['media_indicios_por_grupo']:.1f}")
            
            st.divider()
            
            col1, col2 = st.columns(2)
            with col1:
                st.metric("Grupos com Dados CCS", f"{int(info['grupos_com_dados_ccs']):,}")
            with col2:
                st.metric("M√©dia √çndice CCS", f"{info['media_indice_ccs']:.4f}")
            
            # Tabela completa
            st.subheader("Detalhamento Completo")
            
            # Converter para formato transposto
            df_transposto = df_result.T.reset_index()
            df_transposto.columns = ['M√©trica', 'Valor']
            df_transposto = df_transposto[df_transposto['M√©trica'] != 'categoria']
            
            # Formatar nome das m√©tricas
            df_transposto['M√©trica'] = df_transposto['M√©trica'].str.replace('_', ' ').str.title()
            
            st.dataframe(df_transposto, hide_index=True, use_container_width=True)
    
    # ==========================================================================
    # SE√á√ÉO 2: DISTRIBUI√á√ÉO POR FAIXAS DE SCORE
    # ==========================================================================
    with st.expander("üìà Distribui√ß√£o por Faixas de Score", expanded=False):
        st.subheader("Distribui√ß√£o por Faixas de Score")
        
        query = f"""
        SELECT 
            'DISTRIBUI√á√ÉO POR FAIXAS DE SCORE' AS categoria,
            CASE 
                WHEN {score_col} >= 25 THEN '25+ (Cr√≠tico Extremo)'
                WHEN {score_col} >= 20 THEN '20-24.99 (Cr√≠tico)'
                WHEN {score_col} >= 15 THEN '15-19.99 (Alto)'
                WHEN {score_col} >= 10 THEN '10-14.99 (M√©dio)'
                WHEN {score_col} >= 5 THEN '5-9.99 (Baixo)'
                ELSE '0-4.99 (M√≠nimo)'
            END AS faixa_score,
            COUNT(num_grupo) AS quantidade_grupos,
            ROUND(COUNT(num_grupo) * 100.0 / SUM(COUNT(num_grupo)) OVER(), 2) AS percentual,
            SUM(qntd_cnpj) AS total_cnpjs_faixa,
            AVG({score_col}) AS score_medio_faixa,
            MIN({score_col}) AS score_minimo_faixa,
            MAX({score_col}) AS score_maximo_faixa,
            AVG(COALESCE(valor_max, 0)) AS receita_media_faixa,
            COUNT(CASE WHEN valor_max >= 4800000 THEN 1 END) AS grupos_acima_sn_faixa,
            AVG(total) AS media_inconsistencias_faixa
        FROM gessimples.gei_percent
        GROUP BY 
            CASE 
                WHEN {score_col} >= 25 THEN '25+ (Cr√≠tico Extremo)'
                WHEN {score_col} >= 20 THEN '20-24.99 (Cr√≠tico)'
                WHEN {score_col} >= 15 THEN '15-19.99 (Alto)'
                WHEN {score_col} >= 10 THEN '10-14.99 (M√©dio)'
                WHEN {score_col} >= 5 THEN '5-9.99 (Baixo)'
                ELSE '0-4.99 (M√≠nimo)'
            END
        ORDER BY MIN({score_col}) DESC
        """
        
        df_result = executar_query_analise(engine, "Distribui√ß√£o por Faixas", query)
        
        if not df_result.empty:
            col1, col2 = st.columns(2)
            
            with col1:
                fig = px.bar(df_result, x='faixa_score', y='quantidade_grupos',
                           title="Grupos por Faixa de Score",
                           template=filtros['tema'],
                           labels={'quantidade_grupos': 'Quantidade', 'faixa_score': 'Faixa'})
                st.plotly_chart(fig, use_container_width=True)
            
            with col2:
                fig = px.pie(df_result, values='quantidade_grupos', names='faixa_score',
                           title="Distribui√ß√£o Percentual",
                           template=filtros['tema'])
                st.plotly_chart(fig, use_container_width=True)
            
            st.subheader("Tabela Detalhada")
            
            # Formatar receita_media_faixa
            df_display = df_result.copy()
            df_display['receita_media_faixa'] = df_display['receita_media_faixa'].apply(formatar_moeda)
            
            st.dataframe(df_display, width='stretch', hide_index=True)
    
    # ==========================================================================
    # SE√á√ÉO 3: AN√ÅLISE SETORIAL POR CNAE - CORRIGIDA
    # ==========================================================================
    with st.expander("üè¢ An√°lise Setorial por CNAE", expanded=False):
        st.subheader("An√°lise Setorial por CNAE")
        
        query = f"""
        WITH cnae_grupos AS (
            SELECT
                g.num_grupo,
                c.cd_cnae,
                SUBSTR(CAST(c.cd_cnae AS STRING), 1, 2) AS secao_cnae
            FROM gessimples.gei_cnpj g
            JOIN gessimples.gei_cadastro c ON g.cnpj = c.nu_cnpj
            WHERE c.cd_cnae IS NOT NULL
        ),
        grupos_cnae_principal AS (
            SELECT
                num_grupo,
                secao_cnae,
                ROW_NUMBER() OVER (PARTITION BY num_grupo ORDER BY secao_cnae) AS rn
            FROM cnae_grupos
            GROUP BY num_grupo, secao_cnae
        )
        SELECT
            'AN√ÅLISE SETORIAL - CNAE' AS categoria,
            gcp.secao_cnae,
            CASE gcp.secao_cnae
                WHEN '01' THEN 'Agricultura, Pecu√°ria'
                WHEN '10' THEN 'Fabrica√ß√£o de Produtos Aliment√≠cios'
                WHEN '46' THEN 'Com√©rcio Atacadista'
                WHEN '47' THEN 'Com√©rcio Varejista'
                WHEN '68' THEN 'Atividades Imobili√°rias'
                WHEN '70' THEN 'Atividades de Consultoria'
                WHEN '77' THEN 'Aluguel e Leasing'
                WHEN '82' THEN 'Servi√ßos de Apoio'
                ELSE CONCAT('Se√ß√£o ', gcp.secao_cnae)
            END AS descricao_setor,
            COUNT(DISTINCT p.num_grupo) AS grupos_no_setor,
            AVG(p.{score_col}) AS score_medio_setor,
            MIN(p.{score_col}) AS score_minimo_setor,
            MAX(p.{score_col}) AS score_maximo_setor,
            AVG(p.valor_max) AS receita_media_setor,
            AVG(p.qntd_cnpj) AS media_empresas_por_grupo,
            COUNT(CASE WHEN p.{score_col} >= 15 THEN 1 END) AS grupos_alto_risco,
            ROUND(COUNT(CASE WHEN p.{score_col} >= 15 THEN 1 END) * 100.0 / COUNT(DISTINCT p.num_grupo), 2) AS perc_alto_risco_setor
        FROM grupos_cnae_principal gcp
        JOIN gessimples.gei_percent p ON gcp.num_grupo = p.num_grupo
        WHERE gcp.rn = 1
        GROUP BY gcp.secao_cnae
        HAVING COUNT(DISTINCT p.num_grupo) >= 5
        ORDER BY AVG(p.{score_col}) DESC
        LIMIT 20
        """
        
        df_result = executar_query_analise(engine, "An√°lise Setorial", query)
        
        if not df_result.empty:
            # ‚ö†Ô∏è CORRIGIR NaN ANTES DO GR√ÅFICO
            df_result['receita_media_setor'] = df_result['receita_media_setor'].fillna(0)
            
            col1, col2 = st.columns(2)
            
            with col1:
                fig = px.bar(df_result, x='descricao_setor', y='score_medio_setor',
                           title="Score M√©dio por Setor",
                           template=filtros['tema'],
                           labels={'score_medio_setor': 'Score M√©dio', 'descricao_setor': 'Setor'})
                fig.update_xaxes(tickangle=45)
                st.plotly_chart(fig, use_container_width=True)
            
            with col2:
                fig = px.scatter(df_result, x='grupos_no_setor', y='perc_alto_risco_setor',
                               size='receita_media_setor',
                               hover_data=['descricao_setor'],
                               title="Grupos vs % Alto Risco por Setor",
                               template=filtros['tema'],
                               labels={'grupos_no_setor': 'Quantidade de Grupos', 
                                      'perc_alto_risco_setor': '% Alto Risco'})
                st.plotly_chart(fig, use_container_width=True)
            
            st.subheader("Tabela Detalhada")
            
            # Formatar receita_media_setor
            df_display = df_result.copy()
            df_display['receita_media_setor'] = df_display['receita_media_setor'].apply(formatar_moeda)
            
            st.dataframe(df_display, width='stretch', hide_index=True)

# =============================================================================
# DICION√ÅRIO DE COORDENADAS DOS MUNIC√çPIOS DE SC
# =============================================================================

COORDENADAS_MUNICIPIOS_SC = {
    'FLORIANOPOLIS': (-27.5954, -48.5480),
    'JOINVILLE': (-26.3045, -48.8487),
    'BLUMENAU': (-26.9194, -49.0661),
    'SAO JOSE': (-27.6136, -48.6366),
    'CHAPECO': (-27.1006, -52.6156),
    'CRICIUMA': (-28.6775, -49.3697),
    'ITAJAI': (-26.9078, -48.6619),
    'JARAGUA DO SUL': (-26.4853, -49.0689),
    'LAGES': (-27.8157, -50.3264),
    'PALHOCA': (-27.6456, -48.6682),
    'BRUSQUE': (-27.0979, -48.9173),
    'TUBARAO': (-28.4669, -49.0068),
    'SAO BENTO DO SUL': (-26.2503, -49.3786),
    'CACADOR': (-26.7753, -51.0150),
    'CONCORDIA': (-27.2339, -52.0278),
    'CAMBORIU': (-27.0253, -48.6542),
    'BALNEARIO CAMBORIU': (-26.9906, -48.6347),
    'RIO DO SUL': (-27.2142, -49.6431),
    'BIGUACU': (-27.4942, -48.6558),
    'NAVEGANTES': (-26.8986, -48.6544),
    'GASPAR': (-26.9314, -49.1158),
    'CANOINHAS': (-26.1769, -50.3908),
    'MAFRA': (-26.1117, -49.8053),
    'INDAIAL': (-26.8978, -49.2317),
    'ICARA': (-28.7136, -49.2994),
    'ARARANGUA': (-28.9353, -49.4858),
    'TIJUCAS': (-27.2411, -48.6336),
    'XANXERE': (-26.8764, -52.4039),
    'IMBITUBA': (-28.2400, -48.6700),
    'VIDEIRA': (-27.0078, -51.1517),
    'CURITIBANOS': (-27.2831, -50.5847),
    'SAO FRANCISCO DO SUL': (-26.2428, -48.6389),
    'PORTO UNIAO': (-26.2372, -51.0742),
    'LAGUNA': (-28.4828, -48.7819),
    'SAO MIGUEL DO OESTE': (-26.7250, -53.5153),
    'PENHA': (-26.7706, -48.6464),
    'TIMB√ì': (-26.8236, -49.2731),
    'TIMBO': (-26.8236, -49.2731),
    'POMERODE': (-26.7408, -49.1764),
    'JOACABA': (-27.1781, -51.5022),
    'ORLEANS': (-28.3578, -49.2917),
    'URUSSANGA': (-28.5189, -49.3208),
    'SOMBRIO': (-29.1050, -49.6317),
    'TURVO': (-28.9256, -49.6769),
    'FORQUILHINHA': (-28.7464, -49.4728),
    'COCAL DO SUL': (-28.6006, -49.3283),
    'MORRO DA FUMACA': (-28.6533, -49.2186),
    'NOVA VENEZA': (-28.6336, -49.5000),
    'SIDEROPOLIS': (-28.5939, -49.4258),
    'CAPIVARI DE BAIXO': (-28.4500, -48.9583),
    'GRAVATAL': (-28.3222, -49.0444),
    'BRACO DO NORTE': (-28.2750, -49.1658),
    'SAO LUDGERO': (-28.3306, -49.1764),
    'GR√ÉO PARA': (-28.1833, -49.2250),
    'GRAO PARA': (-28.1833, -49.2250),
    'SANTA ROSA DO SUL': (-29.1333, -49.7167),
    'PRAIA GRANDE': (-29.1917, -49.9500),
    'SAO JOAO DO SUL': (-29.2167, -49.8000),
    'PASSO DE TORRES': (-29.3083, -49.7250),
    'BALNEARIO ARROIO DO SILVA': (-28.9833, -49.4167),
    'BALNEARIO GAIVOTA': (-29.1500, -49.5833),
    'ERMO': (-28.9833, -49.6333),
    'MELEIRO': (-28.8250, -49.6333),
    'MORRO GRANDE': (-28.8000, -49.7167),
    'TREVISO': (-28.5167, -49.4667),
    'LAURO MULLER': (-28.3917, -49.4000),
    'BOM JARDIM DA SERRA': (-28.3333, -49.6333),
    'SAO JOAQUIM': (-28.2944, -49.9319),
    'URUBICI': (-28.0150, -49.5917),
    'URUPEMA': (-28.2917, -49.8750),
    'PAINEL': (-27.9250, -50.1000),
    'BOCAINA DO SUL': (-27.7500, -49.9417),
    'OTACILIO COSTA': (-27.4833, -50.1250),
    'CORREIA PINTO': (-27.5833, -50.3583),
    'PONTE ALTA': (-27.4833, -50.3833),
    'SAO JOSE DO CERRITO': (-27.6583, -50.5750),
    'CAMPO BELO DO SUL': (-27.8917, -50.7583),
    'CERRO NEGRO': (-27.7917, -50.8667),
    'CAPAO ALTO': (-28.2333, -50.5083),
    'ANITA GARIBALDI': (-27.6917, -51.1250),
    'CELSO RAMOS': (-27.6333, -51.3417),
    'ABDON BATISTA': (-27.6083, -51.0250),
    'CAMPOS NOVOS': (-27.4014, -51.2258),
    'MONTE CARLO': (-27.2167, -50.9833),
    'BRUNOPOLIS': (-27.3000, -50.8667),
    'VARGEM': (-27.4833, -50.5500),
    'FRAIBURGO': (-27.0250, -50.9208),
    'TANGARA': (-27.0917, -51.2500),
    'IBICARE': (-27.0917, -51.3750),
    'PIRATUBA': (-27.4250, -51.7667),
    'CAPINZAL': (-27.3500, -51.6083),
    'OURO': (-27.3333, -51.6167),
    'LACERDOPOLIS': (-27.2583, -51.5583),
    'HERVAL DO OESTE': (-27.1917, -51.4917),
    'CATANDUVAS': (-27.0667, -51.6667),
    'AGUA DOCE': (-26.9983, -51.5525),
    'IRANI': (-27.0333, -51.9000),
    'PONTE SERRADA': (-26.8750, -52.0083),
    'VARGEAO': (-26.8583, -52.1583),
    'FAXINAL DOS GUEDES': (-26.8417, -52.2667),
    'OURO VERDE': (-26.6917, -52.3083),
    'BOM JESUS': (-26.7333, -52.3917),
    'IPUACU': (-26.6333, -52.4500),
    'ENTRE RIOS': (-26.7167, -52.5417),
    'ABELARDO LUZ': (-26.5667, -52.3333),
    'SAO DOMINGOS': (-26.5583, -52.5333),
    'GALVAO': (-26.4583, -52.6917),
    'JUPIA': (-26.3917, -52.7333),
    'CORONEL MARTINS': (-26.5083, -52.6750),
    'LAJEADO GRANDE': (-26.8583, -52.5750),
    'PASSOS MAIA': (-26.7833, -52.0583),
    'LUZERNA': (-27.1333, -51.4667),
    'IBIAM': (-27.1833, -51.2333),
    'ZORTEA': (-27.4500, -51.5500),
    'TREZE TILIAS': (-26.9583, -51.4083),
    'SALTO VELOSO': (-26.9000, -51.4000),
    'MACIEIRA': (-26.8583, -51.3667),
    'CALMON': (-26.5917, -51.0917),
    'MATOS COSTA': (-26.4667, -51.1500),
    'TIMB√ì GRANDE': (-26.6167, -50.6583),
    'TIMBO GRANDE': (-26.6167, -50.6583),
    'SANTA CECILIA': (-26.9583, -50.4250),
    'LEBON REGIS': (-26.9250, -50.6917),
    'MONTE CASTELO': (-26.4583, -50.2333),
    'PAPANDUVA': (-26.4333, -50.1417),
    'IRINE√ìPOLIS': (-26.2417, -50.7917),
    'IRINEOPOLIS': (-26.2417, -50.7917),
    'TRES BARRAS': (-26.1083, -50.3167),
    'MAJOR VIEIRA': (-26.3667, -50.3250),
    'BELA VISTA DO TOLDO': (-26.2833, -50.4667),
    'ITAI√ìPOLIS': (-26.3383, -49.9081),
    'ITAIOPOLIS': (-26.3383, -49.9081),
    'RIO NEGRINHO': (-26.2586, -49.5181),
    'CAMPO ALEGRE': (-26.1928, -49.2661),
    'CORUP√Å': (-26.4247, -49.2447),
    'CORUPA': (-26.4247, -49.2447),
    'SCHROEDER': (-26.4133, -49.0728),
    'GUARAMIRIM': (-26.4692, -49.0011),
    'MASSARANDUBA': (-26.6125, -49.0086),
    'LUIZ ALVES': (-26.7150, -48.9317),
    'ILHOTA': (-26.9028, -48.8247),
    'PENHA': (-26.7706, -48.6464),
    'PICARRAS': (-26.7539, -48.6767),
    'BALNEARIO BARRA DO SUL': (-26.4589, -48.6119),
    'ARAQUARI': (-26.3728, -48.7172),
    'GARUVA': (-26.0247, -48.8539),
    'GUARUVA': (-26.0247, -48.8539),
    'ITAPOA': (-26.1167, -48.6167),
    'BOMBINHAS': (-27.1383, -48.5147),
    'PORTO BELO': (-27.1592, -48.5531),
    'GOVERNADOR CELSO RAMOS': (-27.3167, -48.5583),
    'ANTONIO CARLOS': (-27.5158, -48.7689),
    'ANGELINA': (-27.5708, -48.9883),
    'RANCHO QUEIMADO': (-27.6708, -49.0192),
    'ANITAPOLIS': (-27.9017, -49.1308),
    'ALFREDO WAGNER': (-27.7000, -49.3333),
    'LEOBERTO LEAL': (-27.5083, -49.2750),
    'MAJOR GERCINO': (-27.4167, -49.0333),
    'NOVA TRENTO': (-27.2861, -49.0786),
    'CANELINHA': (-27.2636, -48.7650),
    'SAO JOAO BATISTA': (-27.2761, -48.8489),
    'AGUAS MORNAS': (-27.6958, -48.8236),
    'SANTO AMARO DA IMPERATRIZ': (-27.6897, -48.7797),
    'PAULO LOPES': (-27.9608, -48.6869),
    'GAROPABA': (-28.0269, -48.6183),
    'IMARUI': (-28.3333, -48.8167),
    'SAO MARTINHO': (-28.1667, -48.9833),
    'ARMAZEM': (-28.2417, -49.0167),
    'RIO FORTUNA': (-28.1250, -49.1083),
    'SANTA ROSA DE LIMA': (-28.0333, -49.1333),
    'SANGAO': (-28.6333, -49.1333),
    'JAGUARUNA': (-28.6147, -49.0256),
    'TREZE DE MAIO': (-28.5500, -49.1500),
    'PEDRAS GRANDES': (-28.4333, -49.1917),
    'IBIRAMA': (-27.0567, -49.5175),
    'PRESIDENTE GETULIO': (-27.0500, -49.6250),
    'DONA EMMA': (-26.9833, -49.7167),
    'WITMARSUM': (-26.9250, -49.7917),
    'JOSE BOITEUX': (-26.9583, -49.6250),
    'VITOR MEIRELES': (-26.8833, -49.8333),
    'SALETE': (-26.9750, -49.9917),
    'TAIO': (-27.1167, -49.9917),
    'POUSO REDONDO': (-27.2583, -49.9333),
    'TROMBUDO CENTRAL': (-27.2917, -49.7917),
    'AGRONOMICA': (-27.2667, -49.7083),
    'AURORA': (-27.3083, -49.6333),
    'ATALANTA': (-27.4250, -49.7750),
    'IMBUIA': (-27.4917, -49.4250),
    'VIDAL RAMOS': (-27.3917, -49.3667),
    'LONTRAS': (-27.1667, -49.5333),
    'APIUNA': (-27.0333, -49.3917),
    'ASCURRA': (-26.9500, -49.3667),
    'RODEIO': (-26.9222, -49.3650),
    'BENEDITO NOVO': (-26.7833, -49.3583),
    'DOUTOR PEDRINHO': (-26.7167, -49.4833),
    'RIO DOS CEDROS': (-26.7417, -49.2750),
    'APIUNA': (-27.0333, -49.3917),
    'BOTUVER√Å': (-27.2000, -49.0667),
    'BOTUVERA': (-27.2000, -49.0667),
    'GUABIRUBA': (-27.0833, -48.9833),
    'AGROL√ÇNDIA': (-27.4083, -49.8250),
    'AGROLANDIA': (-27.4083, -49.8250),
    'PETROL√ÇNDIA': (-27.5333, -49.6917),
    'PETROLANDIA': (-27.5333, -49.6917),
    'ITUPORANGA': (-27.4106, -49.6031),
    'CHAPAD√ÉO DO LAGEADO': (-27.5917, -49.5500),
    'CHAPADAO DO LAGEADO': (-27.5917, -49.5500),
    'PRESIDENTE NEREU': (-27.2750, -49.3917),
    'LAURENTINO': (-27.2167, -49.7333),
    'MIRIM DOCE': (-27.1917, -50.0583),
    'SANTA TEREZINHA': (-26.7833, -50.0167),
    'MODELO': (-26.7750, -53.0417),
    'SERRA ALTA': (-26.7250, -53.0417),
    'CAIBI': (-27.0750, -53.2500),
    'PALMITOS': (-27.0667, -53.1583),
    'CUNHA PORA': (-26.8917, -53.1667),
    'MARAVILHA': (-26.7639, -53.1714),
    'SAUDADES': (-26.9250, -53.0083),
    'PINHALZINHO': (-26.8500, -52.9917),
    'NOVA ERECHIM': (-26.8917, -52.9083),
    'UNIAO DO OESTE': (-26.7583, -52.8583),
    'JARDINOPOLIS': (-26.7167, -52.8583),
    'CORDILHEIRA ALTA': (-26.9833, -52.6083),
    'GUATAMBU': (-27.1333, -52.7917),
    'PLANALTO ALEGRE': (-27.0667, -52.8667),
    'NOVA ITABERABA': (-26.9417, -52.8083),
    'CAXAMBU DO SUL': (-27.1583, -52.8833),
    'AGUASDECHAPECO': (-27.0750, -52.9833),
    'AGUAS DE CHAPECO': (-27.0750, -52.9833),
    'SAO CARLOS': (-27.0833, -53.0083),
    'QUILOMBO': (-26.7250, -52.7250),
    'FORMOSA DO SUL': (-26.6417, -52.7917),
    'SANTIAGO DO SUL': (-26.6417, -52.6833),
    'IRATI': (-26.6583, -52.8917),
    'ARVOREDO': (-27.0750, -52.4583),
    'SEARA': (-27.1500, -52.3083),
    'XAVANTINA': (-27.0667, -52.3417),
    'LINDOIA DO SUL': (-27.0500, -52.0667),
    'IPUMIRIM': (-27.0750, -52.1333),
    'ITA': (-27.2833, -52.3250),
    'ARABUTA': (-27.1583, -52.3000),
    'ALTO BELA VISTA': (-27.4333, -51.9000),
    'PERITIBA': (-27.3750, -51.9083),
    'IPIRA': (-27.4000, -51.7750),
    'PRESIDENTE CASTELLO BRANCO': (-27.2250, -51.8083),
    'JABOR√Å': (-27.1750, -51.7333),
    'JABORA': (-27.1750, -51.7333),
    'ERVAL VELHO': (-27.2750, -51.4417),
    'PINHEIRO PRETO': (-27.0500, -51.2250),
    'IOMERE': (-27.0000, -51.2417),
    'ARROIO TRINTA': (-26.9250, -51.3417),
    'CACADOR': (-26.7753, -51.0150),
    'RIO DAS ANTAS': (-26.8917, -51.0750),
    'CA√áADOR': (-26.7753, -51.0150),
    'SAO LOURENCO DO OESTE': (-26.3583, -52.8500),
    'NOVO HORIZONTE': (-26.4417, -52.8250),
    'CAMPO ER√ä': (-26.3917, -53.0833),
    'CAMPO ERE': (-26.3917, -53.0833),
    'SALTINHO': (-26.6083, -53.0583),
    'SAO BERNARDINO': (-26.4750, -52.9667),
    'CORONEL FREITAS': (-26.9083, -52.7000),
    'AGUAS FRIAS': (-26.8750, -52.8583),
    'SUL BRASIL': (-26.7333, -52.9667),
    'ITAPIRANGA': (-27.1697, -53.7117),
    'SAO JOAO DO OESTE': (-27.0917, -53.5917),
    'TUNAPOLIS': (-26.9667, -53.6417),
    'IPORA DO OESTE': (-26.9833, -53.5333),
    'SANTA HELENA': (-26.9333, -53.6167),
    'MONDAI': (-27.1000, -53.4000),
    'RIQUEZA': (-27.0667, -53.3250),
    'ROMELANDIA': (-26.9250, -53.3167),
    'SAO MIGUEL DA BOA VISTA': (-26.6917, -53.2500),
    'BARRA BONITA': (-26.6500, -53.4417),
    'GUARACIABA': (-26.6000, -53.5250),
    'SAO JOSE DO CEDRO': (-26.4583, -53.4917),
    'PRINCESA': (-26.4417, -53.6000),
    'PARAISO': (-26.6167, -53.6750),
    'ANCHIETA': (-26.5333, -53.3333),
    'BANDEIRANTE': (-26.7667, -53.6417),
    'DESCANSO': (-26.8250, -53.5000),
    'BOM JESUS DO OESTE': (-26.6917, -53.1000),
    'TIGRINHOS': (-26.6833, -53.1583),
    'DIONISIO CERQUEIRA': (-26.2583, -53.6333),
    'GUARUJA DO SUL': (-26.3833, -53.5333),
    'PALMA SOLA': (-26.3500, -53.2750),
    'FLOR DO SERTAO': (-26.7833, -53.3500),
    'IRACEMINHA': (-26.8167, -53.2750),
    'ROMEL√ÇNDIA': (-26.9250, -53.3167),
}

# =============================================================================
# FUN√á√ÉO MENU MAPA - VISUALIZA√á√ÉO GEOGR√ÅFICA DAS EMPRESAS
# =============================================================================

def menu_mapa(engine, dados, filtros):
    """Exibe mapa interativo com localiza√ß√£o das empresas por grupo econ√¥mico"""

    st.title("Mapa de Empresas por Grupo Econ√¥mico")
    st.markdown("""
    Visualize a distribui√ß√£o geogr√°fica das empresas em Santa Catarina.
    Voc√™ pode ver todas as empresas ou filtrar por um grupo econ√¥mico espec√≠fico.
    """)

    # Op√ß√µes de visualiza√ß√£o
    col1, col2 = st.columns([1, 2])

    with col1:
        modo_visualizacao = st.radio(
            "Modo de visualiza√ß√£o:",
            ["Todos os Grupos", "Grupo Espec√≠fico"],
            help="Escolha se quer ver todas as empresas ou apenas de um grupo"
        )

    # Carregar dados de empresas com localiza√ß√£o
    @st.cache_data(ttl=3600)
    def carregar_empresas_mapa(_engine, num_grupo=None):
        """Carrega empresas com munic√≠pio para o mapa"""
        if num_grupo:
            query = f"""
            SELECT
                g.num_grupo,
                g.cnpj,
                c.nm_razao_social,
                c.nm_fantasia,
                c.nm_munic as municipio,
                c.cd_cnae
            FROM {DATABASE}.gei_cnpj g
            LEFT JOIN usr_sat_ods.vw_ods_contrib c ON g.cnpj = c.nu_cnpj
            WHERE g.num_grupo = '{num_grupo}'
            """
        else:
            # Limitar para performance
            query = f"""
            SELECT
                g.num_grupo,
                g.cnpj,
                c.nm_razao_social,
                c.nm_fantasia,
                c.nm_munic as municipio,
                c.cd_cnae
            FROM {DATABASE}.gei_cnpj g
            LEFT JOIN usr_sat_ods.vw_ods_contrib c ON g.cnpj = c.nu_cnpj
            LIMIT 10000
            """

        try:
            df = pd.read_sql(query, _engine)
            df.columns = [col.lower() for col in df.columns]
            return df
        except Exception as e:
            st.error(f"Erro ao carregar dados: {e}")
            return pd.DataFrame()

    # Fun√ß√£o para obter coordenadas do munic√≠pio
    def obter_coordenadas(municipio):
        """Retorna latitude e longitude do munic√≠pio"""
        if pd.isna(municipio):
            return None, None

        # Normalizar nome do munic√≠pio (remover acentos, upper)
        import unicodedata
        municipio_norm = unicodedata.normalize('NFKD', str(municipio).upper())
        municipio_norm = ''.join(c for c in municipio_norm if not unicodedata.combining(c))
        municipio_norm = municipio_norm.strip()

        # Buscar no dicion√°rio
        if municipio_norm in COORDENADAS_MUNICIPIOS_SC:
            return COORDENADAS_MUNICIPIOS_SC[municipio_norm]

        # Tentar varia√ß√µes
        for key in COORDENADAS_MUNICIPIOS_SC:
            if key in municipio_norm or municipio_norm in key:
                return COORDENADAS_MUNICIPIOS_SC[key]

        return None, None

    # Gerar cores distintas para grupos
    def gerar_cor_grupo(num_grupo):
        """Gera uma cor distinta baseada no n√∫mero do grupo"""
        cores = [
            'red', 'blue', 'green', 'purple', 'orange', 'darkred',
            'lightred', 'beige', 'darkblue', 'darkgreen', 'cadetblue',
            'darkpurple', 'pink', 'lightblue', 'lightgreen', 'gray',
            'black', 'lightgray'
        ]
        try:
            idx = hash(str(num_grupo)) % len(cores)
            return cores[idx]
        except:
            return 'blue'

    # L√≥gica principal baseada no modo de visualiza√ß√£o
    if modo_visualizacao == "Grupo Espec√≠fico":
        with col2:
            # Obter lista de grupos dispon√≠veis
            grupos_disponiveis = sorted(dados['percent']['num_grupo'].unique().tolist())

            grupo_selecionado = st.selectbox(
                "Selecione o Grupo Econ√¥mico:",
                grupos_disponiveis,
                format_func=lambda x: f"Grupo {x}"
            )

        if grupo_selecionado:
            with st.spinner(f"Carregando empresas do Grupo {grupo_selecionado}..."):
                df_empresas = carregar_empresas_mapa(engine, grupo_selecionado)
    else:
        with col2:
            st.info("Exibindo at√© 10.000 empresas para melhor performance")

        with st.spinner("Carregando empresas..."):
            df_empresas = carregar_empresas_mapa(engine)

    if df_empresas.empty:
        st.warning("Nenhuma empresa encontrada com os filtros selecionados.")
        return

    # Adicionar coordenadas
    df_empresas['lat'] = df_empresas['municipio'].apply(lambda x: obter_coordenadas(x)[0])
    df_empresas['lon'] = df_empresas['municipio'].apply(lambda x: obter_coordenadas(x)[1])

    # Filtrar apenas empresas com coordenadas v√°lidas
    df_com_coords = df_empresas.dropna(subset=['lat', 'lon'])

    # Estat√≠sticas
    col_stat1, col_stat2, col_stat3, col_stat4 = st.columns(4)

    with col_stat1:
        st.metric("Total de Empresas", f"{len(df_empresas):,}")

    with col_stat2:
        st.metric("Com Localiza√ß√£o", f"{len(df_com_coords):,}")

    with col_stat3:
        st.metric("Munic√≠pios", f"{df_com_coords['municipio'].nunique():,}")

    with col_stat4:
        if modo_visualizacao == "Todos os Grupos":
            st.metric("Grupos", f"{df_com_coords['num_grupo'].nunique():,}")
        else:
            st.metric("Grupo", f"{grupo_selecionado}")

    if df_com_coords.empty:
        st.warning("Nenhuma empresa possui localiza√ß√£o v√°lida para exibir no mapa.")
        return

    # Criar mapa centrado em SC
    mapa = folium.Map(
        location=[-27.5954, -49.0000],  # Centro de SC
        zoom_start=7,
        tiles='cartodbpositron'
    )

    # Adicionar marcadores
    if modo_visualizacao == "Grupo Espec√≠fico":
        # Todos da mesma cor para o grupo espec√≠fico
        for _, row in df_com_coords.iterrows():
            popup_html = f"""
            <div style='width: 250px'>
                <b>CNPJ:</b> {row['cnpj']}<br>
                <b>Raz√£o Social:</b> {row.get('nm_razao_social', 'N/A')}<br>
                <b>Fantasia:</b> {row.get('nm_fantasia', 'N/A')}<br>
                <b>Munic√≠pio:</b> {row['municipio']}<br>
                <b>CNAE:</b> {row.get('cd_cnae', 'N/A')}<br>
                <b>Grupo:</b> {row['num_grupo']}
            </div>
            """

            folium.Marker(
                location=[row['lat'], row['lon']],
                popup=folium.Popup(popup_html, max_width=300),
                tooltip=f"{row.get('nm_fantasia', row['cnpj'])}",
                icon=folium.Icon(color='red', icon='building', prefix='fa')
            ).add_to(mapa)
    else:
        # Cores diferentes por grupo
        # Usar MarkerCluster para melhor performance
        from folium.plugins import MarkerCluster
        marker_cluster = MarkerCluster().add_to(mapa)

        for _, row in df_com_coords.iterrows():
            popup_html = f"""
            <div style='width: 250px'>
                <b>CNPJ:</b> {row['cnpj']}<br>
                <b>Raz√£o Social:</b> {row.get('nm_razao_social', 'N/A')}<br>
                <b>Fantasia:</b> {row.get('nm_fantasia', 'N/A')}<br>
                <b>Munic√≠pio:</b> {row['municipio']}<br>
                <b>CNAE:</b> {row.get('cd_cnae', 'N/A')}<br>
                <b>Grupo:</b> {row['num_grupo']}
            </div>
            """

            cor = gerar_cor_grupo(row['num_grupo'])

            folium.Marker(
                location=[row['lat'], row['lon']],
                popup=folium.Popup(popup_html, max_width=300),
                tooltip=f"Grupo {row['num_grupo']} - {row.get('nm_fantasia', row['cnpj'])}",
                icon=folium.Icon(color=cor, icon='building', prefix='fa')
            ).add_to(marker_cluster)

    # Exibir mapa
    st.subheader("Mapa de Localiza√ß√£o")
    st_folium(mapa, width=None, height=600, use_container_width=True)

    # Tabela de empresas por munic√≠pio
    st.subheader("Distribui√ß√£o por Munic√≠pio")

    df_municipios = df_com_coords.groupby('municipio').agg({
        'cnpj': 'count',
        'num_grupo': 'nunique'
    }).reset_index()
    df_municipios.columns = ['Munic√≠pio', 'Qtd Empresas', 'Qtd Grupos']
    df_municipios = df_municipios.sort_values('Qtd Empresas', ascending=False)

    col_chart, col_table = st.columns([1, 1])

    with col_chart:
        # Gr√°fico de barras dos top munic√≠pios
        fig = px.bar(
            df_municipios.head(15),
            x='Munic√≠pio',
            y='Qtd Empresas',
            color='Qtd Grupos',
            title='Top 15 Munic√≠pios por N√∫mero de Empresas',
            template=filtros.get('tema', 'plotly_white')
        )
        fig.update_layout(xaxis_tickangle=-45)
        st.plotly_chart(fig, use_container_width=True)

    with col_table:
        st.dataframe(
            df_municipios,
            use_container_width=True,
            hide_index=True,
            height=400
        )

    # Lista de empresas (opcional, expand√≠vel)
    with st.expander("Ver Lista de Empresas"):
        df_display = df_com_coords[['cnpj', 'nm_razao_social', 'nm_fantasia', 'municipio', 'num_grupo']].copy()
        df_display.columns = ['CNPJ', 'Raz√£o Social', 'Nome Fantasia', 'Munic√≠pio', 'Grupo']
        st.dataframe(df_display, use_container_width=True, hide_index=True)


# =============================================================================
# FUN√á√ÉO PRINCIPAL
# =============================================================================

def main():
    """Fun√ß√£o principal do sistema"""
    
    # Sidebar com navega√ß√£o
    st.sidebar.title("Sistema GEI v3.0")
    
    paginas = [
        "Dashboard Executivo",
        "Ranking",
        "An√°lise Pontual",
        "Contadores",
        "Meios de Pagamento",
        "Funcion√°rios",
        "Conv√™nio 115",
        "Procura√ß√£o Banc√°ria (CCS)",
        "Financeiro",
        "Inconsist√™ncias NFe",
        "Ind√≠cios Fiscais",
        "V√≠nculos Societ√°rios",
        "Dossi√™ do Grupo",
        "üó∫Ô∏è Mapa",
        "ü§ñ Machine Learning",
        "An√°lises"
    ]
    
    pag = st.sidebar.radio("Navega√ß√£o:", paginas)  # USE APENAS UMA VARI√ÅVEL
    
    # Filtros
    filtros = criar_filtros_sidebar()
    
    # Conex√£o com o banco
    engine = get_impala_engine()
    
    if engine is None:
        st.stop()
    
    st.sidebar.success("‚úÖ Conectado ao Impala")
    
    # Carregamento dos dados
    dados = carregar_todos_os_dados(engine)
    
    if not dados or dados['percent'].empty:
        st.error("Erro ao carregar dados principais")
        return
    
    st.sidebar.info(f"üìä {len(dados['percent']):,} grupos carregados")
    
    # Roteamento das p√°ginas
    if pag == "Dashboard Executivo":
        dashboard_executivo(dados, filtros)
    elif pag == "Ranking":
        ranking_grupos(dados, filtros)
    elif pag == "An√°lise Pontual":
        analise_pontual(engine, dados, filtros)    
    elif pag == "Contadores":
        menu_contadores(engine, dados, filtros)
    elif pag == "Meios de Pagamento":
        menu_pagamentos(engine, dados, filtros)
    elif pag == "Funcion√°rios":
        menu_funcionarios(engine, dados, filtros)
    elif pag == "Conv√™nio 115":
        menu_c115(engine, dados, filtros)
    elif pag == "Procura√ß√£o Banc√°ria (CCS)":
        menu_ccs(engine, dados, filtros)
    elif pag == "Financeiro":
        menu_financeiro(engine, dados, filtros)
    elif pag == "Inconsist√™ncias NFe":
        inconsistencias_nfe(engine, dados, filtros)
    elif pag == "Ind√≠cios Fiscais":
        indicios_fiscais(dados, filtros)
    elif pag == "V√≠nculos Societ√°rios":
        vinculos_societarios(dados, filtros)
    elif pag == "Dossi√™ do Grupo":
        dossie_grupo(engine, dados, filtros)
    elif pag == "üó∫Ô∏è Mapa":
        menu_mapa(engine, dados, filtros)
    elif pag == "ü§ñ Machine Learning":
        analise_machine_learning(engine, dados, filtros)
    elif pag == "An√°lises":
        menu_analises(engine, dados, filtros)
    
    # Rodap√©
    st.markdown("---")
    st.markdown(f"""
    <div style='text-align: center; color: #666; font-size: 0.8em;'>
        Sistema GEI v3.0 | Receita Estadual SC | {datetime.now().strftime('%d/%m/%Y %H:%M')}
    </div>
    """, unsafe_allow_html=True)


# =============================================================================
# EXECU√á√ÉO DO PROGRAMA
# =============================================================================
if __name__ == "__main__":
    main()